{
  MockTokenizer tokenizer=whitespaceMockTokenizer("lucene is awesome");
  tokenizer.setEnableChecks(true);
  Hunspell2StemFilter filter=new Hunspell2StemFilter(tokenizer,dictionary,TestUtil.nextInt(random(),1,3));
  assertTokenStreamContents(filter,new String[]{"lucene","lucen","is","awesome"},new int[]{1,0,1,1});
  tokenizer=whitespaceMockTokenizer("lucene is awesome");
  CharArraySet set=new CharArraySet(TEST_VERSION_CURRENT,Arrays.asList("Lucene"),true);
  filter=new Hunspell2StemFilter(new SetKeywordMarkerFilter(tokenizer,set),dictionary,TestUtil.nextInt(random(),1,3));
  assertTokenStreamContents(filter,new String[]{"lucene","is","awesome"},new int[]{1,1,1});
}
