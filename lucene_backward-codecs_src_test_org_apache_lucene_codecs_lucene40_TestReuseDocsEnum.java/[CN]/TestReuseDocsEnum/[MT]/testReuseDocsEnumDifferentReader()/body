{
  Directory dir=newDirectory();
  Codec cp=TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());
  MockAnalyzer analyzer=new MockAnalyzer(random());
  analyzer.setMaxTokenLength(TestUtil.nextInt(random(),1,IndexWriter.MAX_TERM_LENGTH));
  RandomIndexWriter writer=new RandomIndexWriter(random(),dir,newIndexWriterConfig(analyzer).setCodec(cp));
  int numdocs=atLeast(20);
  createRandomIndex(numdocs,writer,random());
  writer.commit();
  DirectoryReader firstReader=DirectoryReader.open(dir);
  DirectoryReader secondReader=DirectoryReader.open(dir);
  List<AtomicReaderContext> leaves=firstReader.leaves();
  List<AtomicReaderContext> leaves2=secondReader.leaves();
  for (  AtomicReaderContext ctx : leaves) {
    Terms terms=ctx.reader().terms("body");
    TermsEnum iterator=terms.iterator(null);
    IdentityHashMap<DocsEnum,Boolean> enums=new IdentityHashMap<>();
    MatchNoBits bits=new Bits.MatchNoBits(firstReader.maxDoc());
    iterator=terms.iterator(null);
    DocsEnum docs=null;
    BytesRef term=null;
    while ((term=iterator.next()) != null) {
      docs=iterator.docs(null,randomDocsEnum("body",term,leaves2,bits),random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);
      enums.put(docs,true);
    }
    assertEquals(terms.size(),enums.size());
    iterator=terms.iterator(null);
    enums.clear();
    docs=null;
    while ((term=iterator.next()) != null) {
      docs=iterator.docs(bits,randomDocsEnum("body",term,leaves2,bits),random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);
      enums.put(docs,true);
    }
    assertEquals(terms.size(),enums.size());
  }
  writer.close();
  IOUtils.close(firstReader,secondReader,dir);
}
