{
  if ("PreFlex".equals(CodecProvider.getDefaultCodec())) {
    throw new RuntimeException("thist test cannot run with PreFlex codec");
  }
  long TERM_COUNT=((long)Integer.MAX_VALUE) + 100000000;
  int TERMS_PER_DOC=1000000;
  Directory dir=FSDirectory.open(_TestUtil.getTempDir("2BTerms"));
  IndexWriter w=new IndexWriter(dir,newIndexWriterConfig(TEST_VERSION_CURRENT,new MockAnalyzer()).setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH).setRAMBufferSizeMB(256.0).setMergeScheduler(new ConcurrentMergeScheduler()));
  ((LogMergePolicy)w.getConfig().getMergePolicy()).setUseCompoundFile(false);
  ((LogMergePolicy)w.getConfig().getMergePolicy()).setUseCompoundDocStore(false);
  ((LogMergePolicy)w.getConfig().getMergePolicy()).setMergeFactor(10);
  Document doc=new Document();
  Field field=new Field("field",new MyTokenStream(TERMS_PER_DOC));
  field.setOmitTermFreqAndPositions(true);
  field.setOmitNorms(true);
  doc.add(field);
  final int numDocs=(int)(TERM_COUNT / TERMS_PER_DOC);
  for (int i=0; i < numDocs; i++) {
    w.addDocument(doc);
    System.out.println(i + " of " + numDocs);
  }
  System.out.println("now optimize...");
  w.optimize();
  w.close();
  _TestUtil.checkIndex(dir);
  dir.close();
}
