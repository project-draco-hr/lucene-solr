{
  ensureOpen();
  int numDocs=0;
  try {
    if (infoStream.isEnabled("IW")) {
      infoStream.message("IW","flush at addIndexes(IndexReader...)");
    }
    flush(false,true);
    String mergedName=newSegmentName();
    for (    IndexReader indexReader : readers) {
      numDocs+=indexReader.numDocs();
    }
    final IOContext context=new IOContext(new MergeInfo(numDocs,-1,true,-1));
    SegmentMerger merger=new SegmentMerger(infoStream,directory,config.getTermIndexInterval(),mergedName,MergeState.CheckAbort.NONE,payloadProcessorProvider,new FieldInfos.Builder(globalFieldNumberMap),codec,context);
    for (    IndexReader reader : readers) {
      merger.add(reader);
    }
    MergeState mergeState=merger.merge();
    int docCount=mergeState.mergedDocCount;
    SegmentInfo info=new SegmentInfo(directory,Constants.LUCENE_MAIN_VERSION,mergedName,docCount,-1,mergedName,false,null,false,0,codec,null);
    setDiagnostics(info,"addIndexes(IndexReader...)");
    boolean useCompoundFile;
synchronized (this) {
      if (stopMerges) {
        deleter.deleteNewFiles(info.files());
        return;
      }
      ensureOpen();
      useCompoundFile=mergePolicy.useCompoundFile(segmentInfos,info);
    }
    if (useCompoundFile) {
      createCompoundFile(infoStream,directory,IndexFileNames.segmentFileName(mergedName,"",IndexFileNames.COMPOUND_FILE_EXTENSION),MergeState.CheckAbort.NONE,info,context);
synchronized (this) {
        deleter.deleteNewFiles(info.files());
      }
      info.setUseCompoundFile(true);
    }
    codec.segmentInfosFormat().getSegmentInfosWriter().write(directory,info,mergeState.fieldInfos,context);
    info.clearFilesCache();
synchronized (this) {
      if (stopMerges) {
        deleter.deleteNewFiles(info.files());
        return;
      }
      ensureOpen();
      segmentInfos.add(info);
      checkpoint();
    }
  }
 catch (  OutOfMemoryError oom) {
    handleOOM(oom,"addIndexes(IndexReader...)");
  }
}
