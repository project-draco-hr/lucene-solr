{
  boolean replayed=false;
  boolean successfulRecovery=false;
  UpdateLog ulog;
  ulog=core.getUpdateHandler().getUpdateLog();
  if (ulog == null) {
    SolrException.log(LOG,"No UpdateLog found - cannot recover.");
    recoveryFailed(core,zkController,baseUrl,coreZkNodeName,core.getCoreDescriptor());
    return;
  }
  boolean firstTime=true;
  List<Long> recentVersions;
  try (UpdateLog.RecentUpdates recentUpdates=ulog.getRecentUpdates()){
    recentVersions=recentUpdates.getVersions(ulog.getNumRecordsToKeep());
  }
 catch (  Exception e) {
    SolrException.log(LOG,"Corrupt tlog - ignoring.",e);
    recentVersions=new ArrayList<>(0);
  }
  List<Long> startingVersions=ulog.getStartingVersions();
  if (startingVersions != null && recoveringAfterStartup) {
    try {
      int oldIdx=0;
      long firstStartingVersion=startingVersions.size() > 0 ? startingVersions.get(0) : 0;
      for (; oldIdx < recentVersions.size(); oldIdx++) {
        if (recentVersions.get(oldIdx) == firstStartingVersion)         break;
      }
      if (oldIdx > 0) {
        LOG.info("####### Found new versions added after startup: num=[{}]",oldIdx);
        LOG.info("###### currentVersions=[{}]",recentVersions);
      }
      LOG.info("###### startupVersions=[{}]",startingVersions);
    }
 catch (    Exception e) {
      SolrException.log(LOG,"Error getting recent versions.",e);
      recentVersions=new ArrayList<>(0);
    }
  }
  if (recoveringAfterStartup) {
    recentVersions=startingVersions;
    try {
      if ((ulog.getStartingOperation() & UpdateLog.FLAG_GAP) != 0) {
        LOG.info("Looks like a previous replication recovery did not complete - skipping peer sync.");
        firstTime=false;
      }
    }
 catch (    Exception e) {
      SolrException.log(LOG,"Error trying to get ulog starting operation.",e);
      firstTime=false;
    }
  }
  Future<RecoveryInfo> replayFuture=null;
  while (!successfulRecovery && !isInterrupted() && !isClosed()) {
    try {
      CloudDescriptor cloudDesc=core.getCoreDescriptor().getCloudDescriptor();
      ZkNodeProps leaderprops=zkStateReader.getLeaderRetry(cloudDesc.getCollectionName(),cloudDesc.getShardId());
      final String leaderBaseUrl=leaderprops.getStr(ZkStateReader.BASE_URL_PROP);
      final String leaderCoreName=leaderprops.getStr(ZkStateReader.CORE_NAME_PROP);
      String leaderUrl=ZkCoreNodeProps.getCoreUrl(leaderBaseUrl,leaderCoreName);
      String ourUrl=ZkCoreNodeProps.getCoreUrl(baseUrl,coreName);
      boolean isLeader=leaderUrl.equals(ourUrl);
      if (isLeader && !cloudDesc.isLeader()) {
        throw new SolrException(ErrorCode.SERVER_ERROR,"Cloud state still says we are leader.");
      }
      if (cloudDesc.isLeader()) {
        LOG.warn("We have not yet recovered - but we are now the leader!");
        LOG.info("Finished recovery process.");
        zkController.publish(core.getCoreDescriptor(),Replica.State.ACTIVE);
        return;
      }
      LOG.info("Begin buffering updates. core=[{}]",coreName);
      ulog.bufferUpdates();
      replayed=false;
      LOG.info("Publishing state of core [{}] as recovering, leader is [{}] and I am [{}]",core.getName(),leaderUrl,ourUrl);
      zkController.publish(core.getCoreDescriptor(),Replica.State.RECOVERING);
      final Slice slice=zkStateReader.getClusterState().getSlice(cloudDesc.getCollectionName(),cloudDesc.getShardId());
      try {
        prevSendPreRecoveryHttpUriRequest.abort();
      }
 catch (      NullPointerException e) {
      }
      if (isClosed()) {
        LOG.info("RecoveryStrategy has been closed");
        break;
      }
      sendPrepRecoveryCmd(leaderBaseUrl,leaderCoreName,slice);
      if (isClosed()) {
        LOG.info("RecoveryStrategy has been closed");
        break;
      }
      try {
        Thread.sleep(WAIT_FOR_UPDATES_WITH_STALE_STATE_PAUSE);
      }
 catch (      InterruptedException e) {
        Thread.currentThread().interrupt();
      }
      if (firstTime) {
        firstTime=false;
        LOG.info("Attempting to PeerSync from [{}] - recoveringAfterStartup=[{}]",leaderUrl,recoveringAfterStartup);
        PeerSync peerSync=new PeerSync(core,Collections.singletonList(leaderUrl),ulog.getNumRecordsToKeep(),false,false);
        peerSync.setStartingVersions(recentVersions);
        boolean syncSuccess=peerSync.sync().isSuccess();
        if (syncSuccess) {
          SolrQueryRequest req=new LocalSolrQueryRequest(core,new ModifiableSolrParams());
          core.getUpdateHandler().commit(new CommitUpdateCommand(req,false));
          LOG.info("PeerSync stage of recovery was successful.");
          cloudDebugLog(core,"synced");
          LOG.info("Replaying updates buffered during PeerSync.");
          replay(core);
          replayed=true;
          successfulRecovery=true;
          return;
        }
        LOG.info("PeerSync Recovery was not successful - trying replication.");
      }
      if (isClosed()) {
        LOG.info("RecoveryStrategy has been closed");
        break;
      }
      LOG.info("Starting Replication Recovery.");
      try {
        replicate(zkController.getNodeName(),core,leaderprops);
        if (isClosed()) {
          LOG.info("RecoveryStrategy has been closed");
          break;
        }
        replayFuture=replay(core);
        replayed=true;
        if (isClosed()) {
          LOG.info("RecoveryStrategy has been closed");
          break;
        }
        LOG.info("Replication Recovery was successful.");
        successfulRecovery=true;
      }
 catch (      InterruptedException e) {
        Thread.currentThread().interrupt();
        LOG.warn("Recovery was interrupted",e);
        close=true;
      }
catch (      Exception e) {
        SolrException.log(LOG,"Error while trying to recover",e);
      }
    }
 catch (    Exception e) {
      SolrException.log(LOG,"Error while trying to recover. core=" + coreName,e);
    }
 finally {
      if (!replayed) {
        LOG.info("Replay not started, or was not successful... still buffering updates.");
      }
      if (successfulRecovery) {
        LOG.info("Registering as Active after recovery.");
        try {
          zkController.publish(core.getCoreDescriptor(),Replica.State.ACTIVE);
        }
 catch (        Exception e) {
          LOG.error("Could not publish as ACTIVE after succesful recovery",e);
          successfulRecovery=false;
        }
        if (successfulRecovery) {
          close=true;
          recoveryListener.recovered();
        }
      }
    }
    if (!successfulRecovery) {
      try {
        if (isClosed()) {
          LOG.info("RecoveryStrategy has been closed");
          break;
        }
        LOG.error("Recovery failed - trying again... (" + retries + ")");
        retries++;
        if (retries >= MAX_RETRIES) {
          SolrException.log(LOG,"Recovery failed - max retries exceeded (" + retries + ").");
          try {
            recoveryFailed(core,zkController,baseUrl,coreZkNodeName,core.getCoreDescriptor());
          }
 catch (          Exception e) {
            SolrException.log(LOG,"Could not publish that recovery failed",e);
          }
          break;
        }
      }
 catch (      Exception e) {
        SolrException.log(LOG,"An error has occurred during recovery",e);
      }
      try {
        double loopCount=retries < 4 ? Math.min(Math.pow(2,retries),12) : 12;
        LOG.info("Wait [{}] seconds before trying to recover again (attempt={})",loopCount,retries);
        for (int i=0; i < loopCount; i++) {
          if (isClosed()) {
            LOG.info("RecoveryStrategy has been closed");
            break;
          }
          Thread.sleep(STARTING_RECOVERY_DELAY);
        }
      }
 catch (      InterruptedException e) {
        Thread.currentThread().interrupt();
        LOG.warn("Recovery was interrupted.",e);
        close=true;
      }
    }
  }
  if (successfulRecovery && replayFuture == null) {
    LOG.info("Updating version bucket highest from index after successful recovery.");
    core.seedVersionBuckets();
  }
  LOG.info("Finished recovery process, successful=[{}]",Boolean.toString(successfulRecovery));
}
