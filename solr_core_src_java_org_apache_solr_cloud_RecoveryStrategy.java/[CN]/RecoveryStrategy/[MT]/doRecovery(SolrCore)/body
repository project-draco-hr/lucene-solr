{
  boolean replayed=false;
  boolean successfulRecovery=false;
  UpdateLog ulog;
  ulog=core.getUpdateHandler().getUpdateLog();
  if (ulog == null) {
    SolrException.log(log,"No UpdateLog found - cannot recover. core=" + coreName);
    recoveryFailed(core,zkController,baseUrl,coreZkNodeName,core.getCoreDescriptor());
    return;
  }
  boolean firstTime=true;
  List<Long> recentVersions;
  UpdateLog.RecentUpdates recentUpdates=null;
  try {
    recentUpdates=ulog.getRecentUpdates();
    recentVersions=recentUpdates.getVersions(ulog.numRecordsToKeep);
  }
 catch (  Exception e) {
    SolrException.log(log,"Corrupt tlog - ignoring. core=" + coreName,e);
    recentVersions=new ArrayList<>(0);
  }
 finally {
    if (recentUpdates != null) {
      recentUpdates.close();
    }
  }
  List<Long> startingVersions=ulog.getStartingVersions();
  if (startingVersions != null && recoveringAfterStartup) {
    try {
      int oldIdx=0;
      long firstStartingVersion=startingVersions.size() > 0 ? startingVersions.get(0) : 0;
      for (; oldIdx < recentVersions.size(); oldIdx++) {
        if (recentVersions.get(oldIdx) == firstStartingVersion)         break;
      }
      if (oldIdx > 0) {
        log.info("####### Found new versions added after startup: num=" + oldIdx);
        log.info("###### currentVersions=" + recentVersions);
      }
      log.info("###### startupVersions=" + startingVersions);
    }
 catch (    Exception e) {
      SolrException.log(log,"Error getting recent versions. core=" + coreName,e);
      recentVersions=new ArrayList<>(0);
    }
  }
  if (recoveringAfterStartup) {
    recentVersions=startingVersions;
    try {
      if ((ulog.getStartingOperation() & UpdateLog.FLAG_GAP) != 0) {
        log.info("Looks like a previous replication recovery did not complete - skipping peer sync. core=" + coreName);
        firstTime=false;
      }
    }
 catch (    Exception e) {
      SolrException.log(log,"Error trying to get ulog starting operation. core=" + coreName,e);
      firstTime=false;
    }
  }
  while (!successfulRecovery && !isInterrupted() && !isClosed()) {
    try {
      CloudDescriptor cloudDesc=core.getCoreDescriptor().getCloudDescriptor();
      ZkNodeProps leaderprops=zkStateReader.getLeaderRetry(cloudDesc.getCollectionName(),cloudDesc.getShardId());
      final String leaderBaseUrl=leaderprops.getStr(ZkStateReader.BASE_URL_PROP);
      final String leaderCoreName=leaderprops.getStr(ZkStateReader.CORE_NAME_PROP);
      String leaderUrl=ZkCoreNodeProps.getCoreUrl(leaderBaseUrl,leaderCoreName);
      String ourUrl=ZkCoreNodeProps.getCoreUrl(baseUrl,coreName);
      boolean isLeader=leaderUrl.equals(ourUrl);
      if (isLeader && !cloudDesc.isLeader()) {
        throw new SolrException(ErrorCode.SERVER_ERROR,"Cloud state still says we are leader.");
      }
      if (cloudDesc.isLeader()) {
        log.warn("We have not yet recovered - but we are now the leader! core=" + coreName);
        log.info("Finished recovery process. core=" + coreName);
        zkController.publish(core.getCoreDescriptor(),ZkStateReader.ACTIVE);
        return;
      }
      log.info("Publishing state of core " + core.getName() + " as recovering, leader is "+ leaderUrl+ " and I am "+ ourUrl);
      zkController.publish(core.getCoreDescriptor(),ZkStateReader.RECOVERING);
      final Slice slice=zkStateReader.getClusterState().getSlice(cloudDesc.getCollectionName(),cloudDesc.getShardId());
      try {
        prevSendPreRecoveryHttpUriRequest.abort();
      }
 catch (      NullPointerException e) {
      }
      if (isClosed()) {
        log.info("Recovery was cancelled");
        break;
      }
      sendPrepRecoveryCmd(leaderBaseUrl,leaderCoreName,slice);
      if (isClosed()) {
        log.info("Recovery was cancelled");
        break;
      }
      try {
        Thread.sleep(2000);
      }
 catch (      InterruptedException e) {
        Thread.currentThread().interrupt();
      }
      if (firstTime) {
        firstTime=false;
        log.info("Attempting to PeerSync from " + leaderUrl + " core="+ coreName+ " - recoveringAfterStartup="+ recoveringAfterStartup);
        PeerSync peerSync=new PeerSync(core,Collections.singletonList(leaderUrl),ulog.numRecordsToKeep,false,false);
        peerSync.setStartingVersions(recentVersions);
        boolean syncSuccess=peerSync.sync();
        if (syncSuccess) {
          SolrQueryRequest req=new LocalSolrQueryRequest(core,new ModifiableSolrParams());
          core.getUpdateHandler().commit(new CommitUpdateCommand(req,false));
          log.info("PeerSync Recovery was successful - registering as Active. core=" + coreName);
          if (log.isDebugEnabled()) {
            try {
              RefCounted<SolrIndexSearcher> searchHolder=core.getNewestSearcher(false);
              SolrIndexSearcher searcher=searchHolder.get();
              try {
                log.debug(core.getCoreDescriptor().getCoreContainer().getZkController().getNodeName() + " synched " + searcher.search(new MatchAllDocsQuery(),1).totalHits);
              }
  finally {
                searchHolder.decref();
              }
            }
 catch (            Exception e) {
              throw new SolrException(ErrorCode.SERVER_ERROR,null,e);
            }
          }
          zkController.publish(core.getCoreDescriptor(),ZkStateReader.ACTIVE);
          successfulRecovery=true;
          close=true;
          return;
        }
        log.info("PeerSync Recovery was not successful - trying replication. core=" + coreName);
      }
      if (isClosed()) {
        log.info("Recovery was cancelled");
        break;
      }
      log.info("Starting Replication Recovery. core=" + coreName);
      log.info("Begin buffering updates. core=" + coreName);
      ulog.bufferUpdates();
      replayed=false;
      try {
        replicate(zkController.getNodeName(),core,leaderprops);
        if (isClosed()) {
          log.info("Recovery was cancelled");
          break;
        }
        replay(core);
        replayed=true;
        if (isClosed()) {
          log.info("Recovery was cancelled");
          break;
        }
        log.info("Replication Recovery was successful - registering as Active. core=" + coreName);
        zkController.publish(core.getCoreDescriptor(),ZkStateReader.ACTIVE);
        close=true;
        successfulRecovery=true;
        recoveryListener.recovered();
      }
 catch (      InterruptedException e) {
        Thread.currentThread().interrupt();
        log.warn("Recovery was interrupted",e);
        retries=INTERRUPTED;
      }
catch (      Exception e) {
        SolrException.log(log,"Error while trying to recover",e);
      }
 finally {
        if (!replayed) {
          try {
            ulog.dropBufferedUpdates();
          }
 catch (          Exception e) {
            SolrException.log(log,"",e);
          }
        }
      }
    }
 catch (    Exception e) {
      SolrException.log(log,"Error while trying to recover. core=" + coreName,e);
    }
    if (!successfulRecovery) {
      try {
        log.error("Recovery failed - trying again... (" + retries + ") core="+ coreName);
        if (isClosed()) {
          retries=INTERRUPTED;
        }
        retries++;
        if (retries >= MAX_RETRIES) {
          if (retries >= INTERRUPTED) {
            SolrException.log(log,"Recovery failed - interrupted. core=" + coreName);
            try {
              recoveryFailed(core,zkController,baseUrl,coreZkNodeName,core.getCoreDescriptor());
            }
 catch (            Exception e) {
              SolrException.log(log,"Could not publish that recovery failed",e);
            }
          }
 else {
            SolrException.log(log,"Recovery failed - max retries exceeded (" + retries + "). core="+ coreName);
            try {
              recoveryFailed(core,zkController,baseUrl,coreZkNodeName,core.getCoreDescriptor());
            }
 catch (            Exception e) {
              SolrException.log(log,"Could not publish that recovery failed",e);
            }
          }
          break;
        }
      }
 catch (      Exception e) {
        SolrException.log(log,"core=" + coreName,e);
      }
      try {
        double loopCount=Math.min(Math.pow(2,retries),600);
        log.info("Wait {} seconds before trying to recover again ({})",loopCount,retries);
        for (int i=0; i < loopCount; i++) {
          if (isClosed())           break;
          Thread.sleep(STARTING_RECOVERY_DELAY);
        }
      }
 catch (      InterruptedException e) {
        Thread.currentThread().interrupt();
        log.warn("Recovery was interrupted. core=" + coreName,e);
        retries=INTERRUPTED;
      }
    }
  }
  log.info("Finished recovery process. core=" + coreName);
}
