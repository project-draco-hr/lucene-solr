{
  boolean replayed=false;
  boolean successfulRecovery=false;
  UpdateLog ulog;
  ulog=core.getUpdateHandler().getUpdateLog();
  if (ulog == null) {
    SolrException.log(log,"No UpdateLog found - cannot recover.");
    recoveryFailed(core,zkController,baseUrl,coreZkNodeName,core.getCoreDescriptor());
    return;
  }
  boolean firstTime=true;
  List<Long> recentVersions;
  UpdateLog.RecentUpdates recentUpdates=null;
  try {
    recentUpdates=ulog.getRecentUpdates();
    recentVersions=recentUpdates.getVersions(ulog.getNumRecordsToKeep());
  }
 catch (  Exception e) {
    SolrException.log(log,"Corrupt tlog - ignoring.",e);
    recentVersions=new ArrayList<>(0);
  }
 finally {
    if (recentUpdates != null) {
      recentUpdates.close();
    }
  }
  List<Long> startingVersions=ulog.getStartingVersions();
  if (startingVersions != null && recoveringAfterStartup) {
    try {
      int oldIdx=0;
      long firstStartingVersion=startingVersions.size() > 0 ? startingVersions.get(0) : 0;
      for (; oldIdx < recentVersions.size(); oldIdx++) {
        if (recentVersions.get(oldIdx) == firstStartingVersion)         break;
      }
      if (oldIdx > 0) {
        log.info("####### Found new versions added after startup: num=" + oldIdx);
        log.info("###### currentVersions=" + recentVersions);
      }
      log.info("###### startupVersions=" + startingVersions);
    }
 catch (    Exception e) {
      SolrException.log(log,"Error getting recent versions.",e);
      recentVersions=new ArrayList<>(0);
    }
  }
  if (recoveringAfterStartup) {
    recentVersions=startingVersions;
    try {
      if ((ulog.getStartingOperation() & UpdateLog.FLAG_GAP) != 0) {
        log.info("Looks like a previous replication recovery did not complete - skipping peer sync.");
        firstTime=false;
      }
    }
 catch (    Exception e) {
      SolrException.log(log,"Error trying to get ulog starting operation.",e);
      firstTime=false;
    }
  }
  Future<RecoveryInfo> replayFuture=null;
  while (!successfulRecovery && !isInterrupted() && !isClosed()) {
    try {
      CloudDescriptor cloudDesc=core.getCoreDescriptor().getCloudDescriptor();
      ZkNodeProps leaderprops=zkStateReader.getLeaderRetry(cloudDesc.getCollectionName(),cloudDesc.getShardId());
      final String leaderBaseUrl=leaderprops.getStr(ZkStateReader.BASE_URL_PROP);
      final String leaderCoreName=leaderprops.getStr(ZkStateReader.CORE_NAME_PROP);
      String leaderUrl=ZkCoreNodeProps.getCoreUrl(leaderBaseUrl,leaderCoreName);
      String ourUrl=ZkCoreNodeProps.getCoreUrl(baseUrl,coreName);
      boolean isLeader=leaderUrl.equals(ourUrl);
      if (isLeader && !cloudDesc.isLeader()) {
        throw new SolrException(ErrorCode.SERVER_ERROR,"Cloud state still says we are leader.");
      }
      if (cloudDesc.isLeader()) {
        log.warn("We have not yet recovered - but we are now the leader!");
        log.info("Finished recovery process.");
        zkController.publish(core.getCoreDescriptor(),Replica.State.ACTIVE);
        return;
      }
      log.info("Begin buffering updates. core=" + coreName);
      ulog.bufferUpdates();
      replayed=false;
      log.info("Publishing state of core " + core.getName() + " as recovering, leader is "+ leaderUrl+ " and I am "+ ourUrl);
      zkController.publish(core.getCoreDescriptor(),Replica.State.RECOVERING);
      final Slice slice=zkStateReader.getClusterState().getSlice(cloudDesc.getCollectionName(),cloudDesc.getShardId());
      try {
        prevSendPreRecoveryHttpUriRequest.abort();
      }
 catch (      NullPointerException e) {
      }
      if (isClosed()) {
        log.info("Recovery was cancelled");
        break;
      }
      sendPrepRecoveryCmd(leaderBaseUrl,leaderCoreName,slice);
      if (isClosed()) {
        log.info("Recovery was cancelled");
        break;
      }
      try {
        Thread.sleep(WAIT_FOR_UPDATES_WITH_STALE_STATE_PAUSE);
      }
 catch (      InterruptedException e) {
        Thread.currentThread().interrupt();
      }
      if (firstTime) {
        firstTime=false;
        log.info("Attempting to PeerSync from " + leaderUrl + " - recoveringAfterStartup="+ recoveringAfterStartup);
        PeerSync peerSync=new PeerSync(core,Collections.singletonList(leaderUrl),ulog.getNumRecordsToKeep(),false,false);
        peerSync.setStartingVersions(recentVersions);
        boolean syncSuccess=peerSync.sync();
        if (syncSuccess) {
          SolrQueryRequest req=new LocalSolrQueryRequest(core,new ModifiableSolrParams());
          core.getUpdateHandler().commit(new CommitUpdateCommand(req,false));
          log.info("PeerSync stage of recovery was successful.");
          if (log.isDebugEnabled()) {
            try {
              RefCounted<SolrIndexSearcher> searchHolder=core.getNewestSearcher(false);
              SolrIndexSearcher searcher=searchHolder.get();
              try {
                log.debug(core.getCoreDescriptor().getCoreContainer().getZkController().getNodeName() + " synched " + searcher.search(new MatchAllDocsQuery(),1).totalHits);
              }
  finally {
                searchHolder.decref();
              }
            }
 catch (            Exception e) {
              log.debug("Error in solrcloud_debug block",e);
            }
          }
          log.info("Replaying updates buffered during PeerSync.");
          replay(core);
          replayed=true;
          successfulRecovery=true;
          return;
        }
        log.info("PeerSync Recovery was not successful - trying replication.");
      }
      if (isClosed()) {
        log.info("Recovery was cancelled");
        break;
      }
      log.info("Starting Replication Recovery.");
      try {
        replicate(zkController.getNodeName(),core,leaderprops);
        if (isClosed()) {
          log.info("Recovery was cancelled");
          break;
        }
        replayFuture=replay(core);
        replayed=true;
        if (isClosed()) {
          log.info("Recovery was cancelled");
          break;
        }
        log.info("Replication Recovery was successful.");
        successfulRecovery=true;
      }
 catch (      InterruptedException e) {
        Thread.currentThread().interrupt();
        log.warn("Recovery was interrupted",e);
        close=true;
      }
catch (      Exception e) {
        SolrException.log(log,"Error while trying to recover",e);
      }
    }
 catch (    Exception e) {
      SolrException.log(log,"Error while trying to recover. core=" + coreName,e);
    }
 finally {
      if (!replayed) {
        try {
          ulog.dropBufferedUpdates();
        }
 catch (        Exception e) {
          SolrException.log(log,"",e);
        }
      }
      if (successfulRecovery) {
        log.info("Registering as Active after recovery.");
        try {
          zkController.publish(core.getCoreDescriptor(),Replica.State.ACTIVE);
        }
 catch (        Exception e) {
          log.error("Could not publish as ACTIVE after succesful recovery",e);
          successfulRecovery=false;
        }
        if (successfulRecovery) {
          close=true;
          recoveryListener.recovered();
        }
      }
    }
    if (!successfulRecovery) {
      try {
        if (isClosed()) {
          break;
        }
        log.error("Recovery failed - trying again... (" + retries + ")");
        retries++;
        if (retries >= MAX_RETRIES) {
          SolrException.log(log,"Recovery failed - max retries exceeded (" + retries + ").");
          try {
            recoveryFailed(core,zkController,baseUrl,coreZkNodeName,core.getCoreDescriptor());
          }
 catch (          Exception e) {
            SolrException.log(log,"Could not publish that recovery failed",e);
          }
          break;
        }
      }
 catch (      Exception e) {
        SolrException.log(log,"",e);
      }
      try {
        double loopCount=Math.min(Math.pow(2,retries),60);
        log.info("Wait {} seconds before trying to recover again ({})",loopCount,retries);
        for (int i=0; i < loopCount; i++) {
          if (isClosed())           break;
          Thread.sleep(STARTING_RECOVERY_DELAY);
        }
      }
 catch (      InterruptedException e) {
        Thread.currentThread().interrupt();
        log.warn("Recovery was interrupted.",e);
        close=true;
      }
    }
  }
  if (successfulRecovery && replayFuture == null) {
    log.info("Updating version bucket highest from index after successful recovery.");
    core.seedVersionBuckets();
  }
  log.info("Finished recovery process.");
}
