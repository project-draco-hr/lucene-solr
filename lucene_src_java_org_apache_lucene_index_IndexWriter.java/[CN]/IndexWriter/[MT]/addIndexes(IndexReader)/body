{
  ensureOpen();
  int numDocs=0;
  try {
    infoStream.message("IW","flush at addIndexes(IndexReader...)");
    flush(false,true);
    String mergedName=newSegmentName();
    for (    IndexReader indexReader : readers) {
      numDocs+=indexReader.numDocs();
    }
    final IOContext context=new IOContext(new MergeInfo(numDocs,-1,true,-1));
    SegmentMerger merger=new SegmentMerger(infoStream,directory,config.getTermIndexInterval(),mergedName,MergeState.CheckAbort.NONE,payloadProcessorProvider,new FieldInfos(globalFieldNumberMap),codec,context);
    for (    IndexReader reader : readers)     merger.add(reader);
    MergeState mergeState=merger.merge();
    int docCount=mergeState.mergedDocCount;
    final FieldInfos fieldInfos=mergeState.fieldInfos;
    SegmentInfo info=new SegmentInfo(mergedName,docCount,directory,false,codec,fieldInfos);
    setDiagnostics(info,"addIndexes(IndexReader...)");
    boolean useCompoundFile;
synchronized (this) {
      if (stopMerges) {
        deleter.deleteNewFiles(info.files());
        return;
      }
      ensureOpen();
      useCompoundFile=mergePolicy.useCompoundFile(segmentInfos,info);
    }
    if (useCompoundFile) {
      createCompoundFile(directory,IndexFileNames.segmentFileName(mergedName,"",IndexFileNames.COMPOUND_FILE_EXTENSION),MergeState.CheckAbort.NONE,info,context);
synchronized (this) {
        deleter.deleteNewFiles(info.files());
      }
      info.setUseCompoundFile(true);
    }
synchronized (this) {
      if (stopMerges) {
        deleter.deleteNewFiles(info.files());
        return;
      }
      ensureOpen();
      segmentInfos.add(info);
      checkpoint();
    }
  }
 catch (  OutOfMemoryError oom) {
    handleOOM(oom,"addIndexes(IndexReader...)");
  }
}
