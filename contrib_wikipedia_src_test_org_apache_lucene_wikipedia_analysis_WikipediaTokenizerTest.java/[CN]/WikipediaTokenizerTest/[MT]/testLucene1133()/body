{
  Set untoks=new HashSet();
  untoks.add(WikipediaTokenizer.CATEGORY);
  untoks.add(WikipediaTokenizer.ITALICS);
  WikipediaTokenizer tf=new WikipediaTokenizer(new StringReader(LINK_PHRASES),WikipediaTokenizer.TOKENS_ONLY,untoks);
  checkLinkPhrases(tf);
  String test="[[Category:a b c d]] [[Category:e f g]] [[link here]] [[link there]] ''italics here'' something ''more italics'' [[Category:h   i   j]]";
  tf=new WikipediaTokenizer(new StringReader(test),WikipediaTokenizer.UNTOKENIZED_ONLY,untoks);
  Token token;
  token=tf.next();
  assertTrue("token is null and it shouldn't be",token != null);
  assertTrue(new String(token.termBuffer(),0,token.termLength()) + " is not equal to " + "a b c d",new String(token.termBuffer(),0,token.termLength()).equals("a b c d") == true);
  assertTrue(token.getPositionIncrement() + " does not equal: " + 1,token.getPositionIncrement() == 1);
  assertTrue(token.startOffset() + " does not equal: " + 11,token.startOffset() == 11);
  assertTrue(token.endOffset() + " does not equal: " + 18,token.endOffset() == 18);
  token=tf.next();
  assertTrue("token is null and it shouldn't be",token != null);
  assertTrue(new String(token.termBuffer(),0,token.termLength()) + " is not equal to " + "e f g",new String(token.termBuffer(),0,token.termLength()).equals("e f g") == true);
  assertTrue(token.startOffset() + " does not equal: " + 32,token.startOffset() == 32);
  assertTrue(token.endOffset() + " does not equal: " + 37,token.endOffset() == 37);
  token=tf.next();
  assertTrue("token is null and it shouldn't be",token != null);
  assertTrue(new String(token.termBuffer(),0,token.termLength()) + " is not equal to " + "link",new String(token.termBuffer(),0,token.termLength()).equals("link") == true);
  assertTrue(token.startOffset() + " does not equal: " + 42,token.startOffset() == 42);
  assertTrue(token.endOffset() + " does not equal: " + 46,token.endOffset() == 46);
  token=tf.next();
  assertTrue("token is null and it shouldn't be",token != null);
  assertTrue(new String(token.termBuffer(),0,token.termLength()) + " is not equal to " + "here",new String(token.termBuffer(),0,token.termLength()).equals("here") == true);
  assertTrue(token.startOffset() + " does not equal: " + 47,token.startOffset() == 47);
  assertTrue(token.endOffset() + " does not equal: " + 51,token.endOffset() == 51);
  token=tf.next();
  assertTrue("token is null and it shouldn't be",token != null);
  assertTrue(new String(token.termBuffer(),0,token.termLength()) + " is not equal to " + "link",new String(token.termBuffer(),0,token.termLength()).equals("link") == true);
  assertTrue(token.startOffset() + " does not equal: " + 56,token.startOffset() == 56);
  assertTrue(token.endOffset() + " does not equal: " + 60,token.endOffset() == 60);
  token=tf.next();
  assertTrue("token is null and it shouldn't be",token != null);
  assertTrue(new String(token.termBuffer(),0,token.termLength()) + " is not equal to " + "there",new String(token.termBuffer(),0,token.termLength()).equals("there") == true);
  assertTrue(token.startOffset() + " does not equal: " + 61,token.startOffset() == 61);
  assertTrue(token.endOffset() + " does not equal: " + 66,token.endOffset() == 66);
  token=tf.next();
  assertTrue("token is null and it shouldn't be",token != null);
  assertTrue(new String(token.termBuffer(),0,token.termLength()) + " is not equal to " + "italics here",new String(token.termBuffer(),0,token.termLength()).equals("italics here") == true);
  assertTrue(token.startOffset() + " does not equal: " + 71,token.startOffset() == 71);
  assertTrue(token.endOffset() + " does not equal: " + 83,token.endOffset() == 83);
  token=tf.next();
  assertTrue("token is null and it shouldn't be",token != null);
  assertTrue(new String(token.termBuffer(),0,token.termLength()) + " is not equal to " + "something",new String(token.termBuffer(),0,token.termLength()).equals("something") == true);
  assertTrue(token.startOffset() + " does not equal: " + 86,token.startOffset() == 86);
  assertTrue(token.endOffset() + " does not equal: " + 95,token.endOffset() == 95);
  token=tf.next();
  assertTrue("token is null and it shouldn't be",token != null);
  assertTrue(new String(token.termBuffer(),0,token.termLength()) + " is not equal to " + "more italics",new String(token.termBuffer(),0,token.termLength()).equals("more italics") == true);
  assertTrue(token.startOffset() + " does not equal: " + 98,token.startOffset() == 98);
  assertTrue(token.endOffset() + " does not equal: " + 110,token.endOffset() == 110);
  token=tf.next();
  assertTrue("token is null and it shouldn't be",token != null);
  assertTrue(new String(token.termBuffer(),0,token.termLength()) + " is not equal to " + "h   i   j",new String(token.termBuffer(),0,token.termLength()).equals("h   i   j") == true);
  assertTrue(token.startOffset() + " does not equal: " + 124,token.startOffset() == 124);
  assertTrue(token.endOffset() + " does not equal: " + 133,token.endOffset() == 133);
  token=tf.next();
  assertTrue("token is not null and it should be",token == null);
}
