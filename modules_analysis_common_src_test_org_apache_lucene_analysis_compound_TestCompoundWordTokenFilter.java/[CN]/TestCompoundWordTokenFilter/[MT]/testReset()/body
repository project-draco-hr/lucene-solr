{
  String[] dict={"Rind","Fleisch","Draht","Schere","Gesetz","Aufgabe","??berwachung"};
  Tokenizer wsTokenizer=new WhitespaceTokenizer(TEST_VERSION_CURRENT,new StringReader("Rindfleisch??berwachungsgesetz"));
  DictionaryCompoundWordTokenFilter tf=new DictionaryCompoundWordTokenFilter(TEST_VERSION_CURRENT,wsTokenizer,dict,CompoundWordTokenFilterBase.DEFAULT_MIN_WORD_SIZE,CompoundWordTokenFilterBase.DEFAULT_MIN_SUBWORD_SIZE,CompoundWordTokenFilterBase.DEFAULT_MAX_SUBWORD_SIZE,false);
  CharTermAttribute termAtt=tf.getAttribute(CharTermAttribute.class);
  assertTrue(tf.incrementToken());
  assertEquals("Rindfleisch??berwachungsgesetz",termAtt.toString());
  assertTrue(tf.incrementToken());
  assertEquals("Rind",termAtt.toString());
  wsTokenizer.reset(new StringReader("Rindfleisch??berwachungsgesetz"));
  tf.reset();
  assertTrue(tf.incrementToken());
  assertEquals("Rindfleisch??berwachungsgesetz",termAtt.toString());
}
