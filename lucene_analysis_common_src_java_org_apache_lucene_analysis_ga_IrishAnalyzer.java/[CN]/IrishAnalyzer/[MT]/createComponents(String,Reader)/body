{
  final Tokenizer source=new StandardTokenizer(matchVersion,reader);
  TokenStream result=new StandardFilter(matchVersion,source);
  StopFilter s=new StopFilter(matchVersion,result,HYPHENATIONS);
  s.setEnablePositionIncrements(false);
  result=s;
  result=new ElisionFilter(matchVersion,result,DEFAULT_ARTICLES);
  result=new IrishLowerCaseFilter(result);
  result=new StopFilter(matchVersion,result,stopwords);
  if (!stemExclusionSet.isEmpty())   result=new KeywordMarkerFilter(result,stemExclusionSet);
  result=new SnowballFilter(result,new IrishStemmer());
  return new TokenStreamComponents(source,result);
}
