{
  final String groupField="author";
  Directory dir=newDirectory();
  RandomIndexWriter w=new RandomIndexWriter(random,dir,newIndexWriterConfig(TEST_VERSION_CURRENT,new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));
  Document doc=new Document();
  doc.add(new Field(groupField,"author1",Field.Store.YES,Field.Index.ANALYZED));
  doc.add(new Field("content","random text",Field.Store.YES,Field.Index.ANALYZED));
  doc.add(new Field("id","1",Field.Store.YES,Field.Index.NO));
  w.addDocument(doc);
  doc=new Document();
  doc.add(new Field(groupField,"author1",Field.Store.YES,Field.Index.ANALYZED));
  doc.add(new Field("content","some more random text",Field.Store.YES,Field.Index.ANALYZED));
  doc.add(new Field("id","2",Field.Store.YES,Field.Index.NO));
  w.addDocument(doc);
  doc=new Document();
  doc.add(new Field(groupField,"author1",Field.Store.YES,Field.Index.ANALYZED));
  doc.add(new Field("content","some more random textual data",Field.Store.YES,Field.Index.ANALYZED));
  doc.add(new Field("id","3",Field.Store.YES,Field.Index.NO));
  w.addDocument(doc);
  doc=new Document();
  doc.add(new Field(groupField,"author2",Field.Store.YES,Field.Index.ANALYZED));
  doc.add(new Field("content","some random text",Field.Store.YES,Field.Index.ANALYZED));
  doc.add(new Field("id","4",Field.Store.YES,Field.Index.NO));
  w.addDocument(doc);
  doc=new Document();
  doc.add(new Field(groupField,"author3",Field.Store.YES,Field.Index.ANALYZED));
  doc.add(new Field("content","some more random text",Field.Store.YES,Field.Index.ANALYZED));
  doc.add(new Field("id","5",Field.Store.YES,Field.Index.NO));
  w.addDocument(doc);
  doc=new Document();
  doc.add(new Field(groupField,"author3",Field.Store.YES,Field.Index.ANALYZED));
  doc.add(new Field("content","random",Field.Store.YES,Field.Index.ANALYZED));
  doc.add(new Field("id","6",Field.Store.YES,Field.Index.NO));
  w.addDocument(doc);
  doc=new Document();
  doc.add(new Field("content","random word stuck in alot of other text",Field.Store.YES,Field.Index.ANALYZED));
  doc.add(new Field("id","6",Field.Store.YES,Field.Index.NO));
  w.addDocument(doc);
  IndexSearcher indexSearcher=new IndexSearcher(w.getReader());
  w.close();
  final Sort groupSort=Sort.RELEVANCE;
  final FirstPassGroupingCollector c1=new FirstPassGroupingCollector(groupField,groupSort,10);
  indexSearcher.search(new TermQuery(new Term("content","random")),c1);
  final SecondPassGroupingCollector c2=new SecondPassGroupingCollector(groupField,c1.getTopGroups(0,true),groupSort,null,5,true,false,true);
  indexSearcher.search(new TermQuery(new Term("content","random")),c2);
  final TopGroups groups=c2.getTopGroups(0);
  assertEquals(7,groups.totalHitCount);
  assertEquals(7,groups.totalGroupedHitCount);
  assertEquals(4,groups.groups.length);
  GroupDocs group=groups.groups[0];
  assertEquals(new BytesRef("author3"),group.groupValue);
  assertEquals(2,group.scoreDocs.length);
  assertEquals(5,group.scoreDocs[0].doc);
  assertEquals(4,group.scoreDocs[1].doc);
  assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);
  group=groups.groups[1];
  assertEquals(new BytesRef("author1"),group.groupValue);
  assertEquals(3,group.scoreDocs.length);
  assertEquals(0,group.scoreDocs[0].doc);
  assertEquals(1,group.scoreDocs[1].doc);
  assertEquals(2,group.scoreDocs[2].doc);
  assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);
  assertTrue(group.scoreDocs[1].score > group.scoreDocs[2].score);
  group=groups.groups[2];
  assertEquals(new BytesRef("author2"),group.groupValue);
  assertEquals(1,group.scoreDocs.length);
  assertEquals(3,group.scoreDocs[0].doc);
  group=groups.groups[3];
  assertNull(group.groupValue);
  assertEquals(1,group.scoreDocs.length);
  assertEquals(6,group.scoreDocs[0].doc);
  indexSearcher.getIndexReader().close();
  dir.close();
}
