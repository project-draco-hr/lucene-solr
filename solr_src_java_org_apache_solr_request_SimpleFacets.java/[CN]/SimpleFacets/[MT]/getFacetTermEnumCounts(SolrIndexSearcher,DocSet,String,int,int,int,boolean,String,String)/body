{
  int minDfFilterCache=params.getFieldInt(field,FacetParams.FACET_ENUM_CACHE_MINDF,0);
  IndexSchema schema=searcher.getSchema();
  IndexReader r=searcher.getReader();
  FieldType ft=schema.getFieldType(field);
  boolean sortByCount=sort.equals("count") || sort.equals("true");
  final int maxsize=limit >= 0 ? offset + limit : Integer.MAX_VALUE - 1;
  final BoundedTreeSet<CountPair<BytesRef,Integer>> queue=sortByCount ? new BoundedTreeSet<CountPair<BytesRef,Integer>>(maxsize) : null;
  final NamedList res=new NamedList();
  int min=mincount - 1;
  int off=offset;
  int lim=limit >= 0 ? limit : Integer.MAX_VALUE;
  BytesRef startTermBytes=null;
  if (prefix != null) {
    String indexedPrefix=ft.toInternal(prefix);
    startTermBytes=new BytesRef(indexedPrefix);
  }
  Fields fields=MultiFields.getFields(r);
  Terms terms=fields == null ? null : fields.terms(field);
  TermsEnum termsEnum=null;
  if (terms != null) {
    termsEnum=terms.iterator();
    if (startTermBytes != null) {
      if (termsEnum.seek(startTermBytes,true) == TermsEnum.SeekStatus.END) {
        termsEnum=null;
      }
    }
 else {
      termsEnum.next();
    }
  }
  Term template=new Term(field);
  DocsEnum docsEnum=null;
  if (termsEnum != null && docs.size() >= mincount) {
    for (; ; ) {
      BytesRef term=termsEnum.term();
      if (term == null)       break;
      if (startTermBytes != null && !term.startsWith(startTermBytes))       break;
      int df=termsEnum.docFreq();
      if (df > 0 && df > min) {
        int c;
        if (df >= minDfFilterCache) {
          Term t=template.createTerm(new String(term.utf8ToString()));
          c=searcher.numDocs(new TermQuery(t),docs);
        }
 else {
          docsEnum=termsEnum.docs(null,docsEnum);
          DocsEnum.BulkReadResult bulk=docsEnum.getBulkResult();
          c=0;
          for (; ; ) {
            int nDocs=docsEnum.read();
            if (nDocs == 0)             break;
            int[] docArr=bulk.docs.ints;
            int end=bulk.docs.offset + nDocs;
            for (int i=bulk.docs.offset; i < end; i++) {
              if (docs.exists(docArr[i]))               c++;
            }
          }
        }
        if (sortByCount) {
          if (c > min) {
            BytesRef termCopy=new BytesRef(term);
            queue.add(new CountPair<BytesRef,Integer>(termCopy,c));
            if (queue.size() >= maxsize)             min=queue.last().val;
          }
        }
 else {
          if (c >= mincount && --off < 0) {
            if (--lim < 0)             break;
            BytesRef termCopy=new BytesRef(term);
            String s=term.utf8ToString();
            res.add(ft.indexedToReadable(s),c);
          }
        }
      }
      termsEnum.next();
    }
  }
  if (sortByCount) {
    for (    CountPair<BytesRef,Integer> p : queue) {
      if (--off >= 0)       continue;
      if (--lim < 0)       break;
      String s=p.key.utf8ToString();
      res.add(ft.indexedToReadable(s),p.val);
    }
  }
  if (missing) {
    res.add(null,getFieldMissingCount(searcher,docs,field));
  }
  return res;
}
