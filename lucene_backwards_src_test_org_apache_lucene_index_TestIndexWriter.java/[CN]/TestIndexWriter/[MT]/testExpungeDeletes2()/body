{
  Directory dir=new MockRAMDirectory();
  IndexWriter writer=new IndexWriter(dir,new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT),IndexWriter.MaxFieldLength.LIMITED);
  writer.setMaxBufferedDocs(2);
  writer.setMergeFactor(50);
  writer.setRAMBufferSizeMB(IndexWriter.DISABLE_AUTO_FLUSH);
  Document document=new Document();
  document=new Document();
  Field storedField=new Field("stored","stored",Field.Store.YES,Field.Index.NO);
  document.add(storedField);
  Field termVectorField=new Field("termVector","termVector",Field.Store.NO,Field.Index.NOT_ANALYZED,Field.TermVector.WITH_POSITIONS_OFFSETS);
  document.add(termVectorField);
  for (int i=0; i < 98; i++)   writer.addDocument(document);
  writer.close();
  IndexReader ir=IndexReader.open(dir,false);
  assertEquals(98,ir.maxDoc());
  assertEquals(98,ir.numDocs());
  for (int i=0; i < 98; i+=2)   ir.deleteDocument(i);
  assertEquals(49,ir.numDocs());
  ir.close();
  writer=new IndexWriter(dir,new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT),IndexWriter.MaxFieldLength.LIMITED);
  writer.setMergeFactor(3);
  assertEquals(49,writer.numDocs());
  writer.expungeDeletes();
  writer.close();
  ir=IndexReader.open(dir,true);
  assertEquals(49,ir.maxDoc());
  assertEquals(49,ir.numDocs());
  ir.close();
  dir.close();
}
