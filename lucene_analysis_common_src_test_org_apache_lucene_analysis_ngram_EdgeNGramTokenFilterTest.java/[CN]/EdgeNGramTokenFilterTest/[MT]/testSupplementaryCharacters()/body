{
  final String s=TestUtil.randomUnicodeString(random(),10);
  final int codePointCount=s.codePointCount(0,s.length());
  final int minGram=TestUtil.nextInt(random(),1,3);
  final int maxGram=TestUtil.nextInt(random(),minGram,10);
  TokenStream tk=new KeywordTokenizer();
  ((Tokenizer)tk).setReader(new StringReader(s));
  tk=new EdgeNGramTokenFilter(tk,minGram,maxGram);
  final CharTermAttribute termAtt=tk.addAttribute(CharTermAttribute.class);
  final OffsetAttribute offsetAtt=tk.addAttribute(OffsetAttribute.class);
  tk.reset();
  for (int i=minGram; i <= Math.min(codePointCount,maxGram); ++i) {
    assertTrue(tk.incrementToken());
    assertEquals(0,offsetAtt.startOffset());
    assertEquals(s.length(),offsetAtt.endOffset());
    final int end=Character.offsetByCodePoints(s,0,i);
    assertEquals(s.substring(0,end),termAtt.toString());
  }
  assertFalse(tk.incrementToken());
}
