{
  final Tokenizer source=new StandardTokenizer(matchVersion,reader);
  TokenStream result=new StandardFilter(source);
  result=new LowerCaseFilter(matchVersion,result);
  result=new StopFilter(matchVersion,result,stopwords);
  result=new KeywordMarkerTokenFilter(result,exclusionSet);
  if (matchVersion.onOrAfter(Version.LUCENE_31))   result=new SnowballFilter(result,new German2Stemmer());
 else   result=new GermanStemFilter(result);
  return new TokenStreamComponents(source,result);
}
