{
  Codec codec=getCodec();
  SegmentInfo segmentInfo=new SegmentInfo(dir,Constants.LUCENE_MAIN_VERSION,"_0",1 + maxDocID,false,codec,null,null);
  int maxIndexOption=Arrays.asList(IndexOptions.values()).indexOf(maxAllowed);
  if (VERBOSE) {
    System.out.println("\nTEST: now build index");
  }
  int maxIndexOptionNoOffsets=Arrays.asList(IndexOptions.values()).indexOf(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);
  FieldInfo[] newFieldInfoArray=new FieldInfo[fields.size()];
  for (int fieldUpto=0; fieldUpto < fields.size(); fieldUpto++) {
    FieldInfo oldFieldInfo=fieldInfos.fieldInfo(fieldUpto);
    String pf=_TestUtil.getPostingsFormat(codec,oldFieldInfo.name);
    int fieldMaxIndexOption;
    if (doesntSupportOffsets.contains(pf)) {
      fieldMaxIndexOption=Math.min(maxIndexOptionNoOffsets,maxIndexOption);
    }
 else {
      fieldMaxIndexOption=maxIndexOption;
    }
    IndexOptions indexOptions=IndexOptions.values()[alwaysTestMax ? fieldMaxIndexOption : random().nextInt(1 + fieldMaxIndexOption)];
    boolean doPayloads=indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0 && allowPayloads;
    newFieldInfoArray[fieldUpto]=new FieldInfo(oldFieldInfo.name,true,fieldUpto,false,false,doPayloads,indexOptions,null,DocValues.Type.FIXED_INTS_8,null);
  }
  FieldInfos newFieldInfos=new FieldInfos(newFieldInfoArray);
  long bytes=totalPostings * 8 + totalPayloadBytes;
  SegmentWriteState writeState=new SegmentWriteState(null,dir,segmentInfo,newFieldInfos,32,null,new IOContext(new FlushInfo(1 + maxDocID,bytes)));
  FieldsConsumer fieldsConsumer=codec.postingsFormat().fieldsConsumer(writeState);
  for (  Map.Entry<String,Map<BytesRef,List<Posting>>> fieldEnt : fields.entrySet()) {
    String field=fieldEnt.getKey();
    Map<BytesRef,List<Posting>> terms=fieldEnt.getValue();
    FieldInfo fieldInfo=newFieldInfos.fieldInfo(field);
    IndexOptions indexOptions=fieldInfo.getIndexOptions();
    if (VERBOSE) {
      System.out.println("field=" + field + " indexOtions="+ indexOptions);
    }
    boolean doFreq=indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS) >= 0;
    boolean doPos=indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;
    boolean doPayloads=indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0 && allowPayloads;
    boolean doOffsets=indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;
    TermsConsumer termsConsumer=fieldsConsumer.addField(fieldInfo);
    long sumTotalTF=0;
    long sumDF=0;
    FixedBitSet seenDocs=new FixedBitSet(maxDocID + 1);
    for (    Map.Entry<BytesRef,List<Posting>> termEnt : terms.entrySet()) {
      BytesRef term=termEnt.getKey();
      List<Posting> postings=termEnt.getValue();
      if (VERBOSE) {
        System.out.println("  term=" + field + ":"+ term.utf8ToString()+ " docFreq="+ postings.size());
      }
      PostingsConsumer postingsConsumer=termsConsumer.startTerm(term);
      long totalTF=0;
      int docCount=0;
      for (      Posting posting : postings) {
        if (VERBOSE) {
          System.out.println("    " + docCount + ": docID="+ posting.docID+ " freq="+ posting.positions.size());
        }
        postingsConsumer.startDoc(posting.docID,doFreq ? posting.positions.size() : -1);
        seenDocs.set(posting.docID);
        if (doPos) {
          totalTF+=posting.positions.size();
          for (          Position pos : posting.positions) {
            if (VERBOSE) {
              if (doPayloads) {
                System.out.println("      pos=" + pos.position + " payload="+ (pos.payload == null ? "null" : pos.payload.length + " bytes"));
              }
 else {
                System.out.println("      pos=" + pos.position);
              }
            }
            postingsConsumer.addPosition(pos.position,(doPayloads && pos.payload != null) ? new BytesRef(pos.payload) : null,doOffsets ? pos.startOffset : -1,doOffsets ? pos.endOffset : -1);
          }
        }
 else         if (doFreq) {
          totalTF+=posting.positions.size();
        }
 else {
          totalTF++;
        }
        postingsConsumer.finishDoc();
        docCount++;
      }
      termsConsumer.finishTerm(term,new TermStats(postings.size(),doFreq ? totalTF : -1));
      sumTotalTF+=totalTF;
      sumDF+=postings.size();
    }
    termsConsumer.finish(doFreq ? sumTotalTF : -1,sumDF,seenDocs.cardinality());
  }
  fieldsConsumer.close();
  if (VERBOSE) {
    System.out.println("TEST: after indexing: files=");
    for (    String file : dir.listAll()) {
      System.out.println("  " + file + ": "+ dir.fileLength(file)+ " bytes");
    }
  }
  currentFieldInfos=newFieldInfos;
  SegmentReadState readState=new SegmentReadState(dir,segmentInfo,newFieldInfos,IOContext.DEFAULT,1);
  return codec.postingsFormat().fieldsProducer(readState);
}
