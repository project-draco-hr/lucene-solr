{
  BaseDirectoryWrapper dir=newDirectory();
  dir.setCheckIndexOnClose(false);
  IndexWriter writer=null;
  writer=new IndexWriter(dir,newIndexWriterConfig(new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy(true)).setUseCompoundFile(true));
  MergePolicy lmp=writer.getConfig().getMergePolicy();
  lmp.setNoCFSRatio(1.0);
  lmp.setMaxCFSSegmentSizeMB(Double.POSITIVE_INFINITY);
  for (int i=0; i < 100; i++) {
    addDoc(writer);
  }
  writer.close();
  long gen=SegmentInfos.getLastCommitGeneration(dir);
  assertTrue("segment generation should be > 0 but got " + gen,gen > 0);
  boolean corrupted=false;
  SegmentInfos sis=SegmentInfos.readLatestCommit(dir);
  for (  SegmentCommitInfo si : sis) {
    assertTrue(si.info.getUseCompoundFile());
    List<String> victims=new ArrayList<String>(si.info.files());
    Collections.shuffle(victims,random());
    dir.deleteFiles(Collections.singleton(victims.get(0)));
    corrupted=true;
    break;
  }
  assertTrue("failed to find cfs file to remove: ",corrupted);
  IndexReader reader=null;
  try {
    reader=DirectoryReader.open(dir);
    fail("reader did not hit IOException on opening a corrupt index");
  }
 catch (  Exception e) {
  }
  if (reader != null) {
    reader.close();
  }
  dir.close();
}
