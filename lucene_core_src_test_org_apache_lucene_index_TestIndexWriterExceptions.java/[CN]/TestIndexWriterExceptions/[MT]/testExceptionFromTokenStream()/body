{
  Directory dir=newDirectory();
  IndexWriterConfig conf=newIndexWriterConfig(new Analyzer(){
    @Override public TokenStreamComponents createComponents(    String fieldName){
      MockTokenizer tokenizer=new MockTokenizer(MockTokenizer.SIMPLE,true);
      tokenizer.setEnableChecks(false);
      return new TokenStreamComponents(tokenizer,new TokenFilter(tokenizer){
        private int count=0;
        @Override public boolean incrementToken() throws IOException {
          if (count++ == 5) {
            throw new IOException();
          }
          return input.incrementToken();
        }
        @Override public void reset() throws IOException {
          super.reset();
          this.count=0;
        }
      }
);
    }
  }
);
  conf.setMaxBufferedDocs(Math.max(3,conf.getMaxBufferedDocs()));
  IndexWriter writer=new IndexWriter(dir,conf);
  Document doc=new Document();
  String contents="aa bb cc dd ee ff gg hh ii jj kk";
  doc.add(newTextField("content",contents,Field.Store.NO));
  try {
    writer.addDocument(doc);
    fail("did not hit expected exception");
  }
 catch (  Exception e) {
  }
  doc=new Document();
  doc.add(newTextField("content","aa bb cc dd",Field.Store.NO));
  writer.addDocument(doc);
  doc=new Document();
  doc.add(newTextField("content","aa bb cc dd",Field.Store.NO));
  writer.addDocument(doc);
  writer.close();
  IndexReader reader=DirectoryReader.open(dir);
  final Term t=new Term("content","aa");
  assertEquals(3,reader.docFreq(t));
  PostingsEnum tdocs=TestUtil.docs(random(),reader,t.field(),new BytesRef(t.text()),null,0);
  final Bits liveDocs=MultiFields.getLiveDocs(reader);
  int count=0;
  while (tdocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
    if (liveDocs == null || liveDocs.get(tdocs.docID())) {
      count++;
    }
  }
  assertEquals(2,count);
  assertEquals(reader.docFreq(new Term("content","gg")),0);
  reader.close();
  dir.close();
}
