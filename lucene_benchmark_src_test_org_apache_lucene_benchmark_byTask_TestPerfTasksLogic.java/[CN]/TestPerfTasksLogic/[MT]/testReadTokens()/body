{
  final int NUM_DOCS=20;
  String algLines1[]={"# ----- properties ","analyzer=org.apache.lucene.analysis.core.WhitespaceAnalyzer","content.source=org.apache.lucene.benchmark.byTask.feeds.LineDocSource","docs.file=" + getReuters20LinesFile(),"# ----- alg ","{ReadTokens}: " + NUM_DOCS,"ResetSystemErase","CreateIndex","{AddDoc}: " + NUM_DOCS,"CloseIndex"};
  Benchmark benchmark=execBenchmark(algLines1);
  List<TaskStats> stats=benchmark.getRunData().getPoints().taskStats();
  int totalTokenCount1=0;
  for (  final TaskStats stat : stats) {
    if (stat.getTask().getName().equals("ReadTokens")) {
      totalTokenCount1+=stat.getCount();
    }
  }
  IndexReader reader=DirectoryReader.open(benchmark.getRunData().getDirectory());
  assertEquals(NUM_DOCS,reader.numDocs());
  int totalTokenCount2=0;
  Fields fields=MultiFields.getFields(reader);
  for (  String fieldName : fields) {
    if (fieldName.equals(DocMaker.ID_FIELD) || fieldName.equals(DocMaker.DATE_MSEC_FIELD) || fieldName.equals(DocMaker.TIME_SEC_FIELD)) {
      continue;
    }
    Terms terms=fields.terms(fieldName);
    if (terms == null) {
      continue;
    }
    TermsEnum termsEnum=terms.iterator();
    PostingsEnum docs=null;
    while (termsEnum.next() != null) {
      docs=TestUtil.docs(random(),termsEnum,docs,PostingsEnum.FREQS);
      while (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
        totalTokenCount2+=docs.freq();
      }
    }
  }
  reader.close();
  assertEquals(totalTokenCount1,totalTokenCount2);
}
