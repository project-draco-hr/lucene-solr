{
  Analyzer a=new Analyzer(){
    @Override public TokenStreamComponents createComponents(    String field){
      Tokenizer tokenizer=new MockTokenizer(MockTokenizer.WHITESPACE,false);
      return new TokenStreamComponents(tokenizer,new CommonGramsQueryFilter(new CommonGramsFilter(TEST_VERSION_CURRENT,tokenizer,commonWords)));
    }
  }
;
  assertAnalyzesTo(a,"brown fox",new String[]{"brown","fox"});
  assertAnalyzesTo(a,"the fox",new String[]{"the_fox"});
  assertAnalyzesTo(a,"fox of",new String[]{"fox_of"});
  assertAnalyzesTo(a,"of the",new String[]{"of_the"});
  assertAnalyzesTo(a,"the",new String[]{"the"});
  assertAnalyzesTo(a,"foo",new String[]{"foo"});
  assertAnalyzesTo(a,"n n n",new String[]{"n","n","n"});
  assertAnalyzesTo(a,"quick brown fox",new String[]{"quick","brown","fox"});
  assertAnalyzesTo(a,"n n s",new String[]{"n","n_s"});
  assertAnalyzesTo(a,"quick brown the",new String[]{"quick","brown_the"});
  assertAnalyzesTo(a,"n s n",new String[]{"n_s","s_n"});
  assertAnalyzesTo(a,"quick the brown",new String[]{"quick_the","the_brown"});
  assertAnalyzesTo(a,"n s s",new String[]{"n_s","s_s"});
  assertAnalyzesTo(a,"fox of the",new String[]{"fox_of","of_the"});
  assertAnalyzesTo(a,"s n n",new String[]{"s_n","n","n"});
  assertAnalyzesTo(a,"the quick brown",new String[]{"the_quick","quick","brown"});
  assertAnalyzesTo(a,"s n s",new String[]{"s_n","n_s"});
  assertAnalyzesTo(a,"the fox of",new String[]{"the_fox","fox_of"});
  assertAnalyzesTo(a,"s s n",new String[]{"s_s","s_n"});
  assertAnalyzesTo(a,"of the fox",new String[]{"of_the","the_fox"});
  assertAnalyzesTo(a,"s s s",new String[]{"s_s","s_s"});
  assertAnalyzesTo(a,"of the of",new String[]{"of_the","the_of"});
}
