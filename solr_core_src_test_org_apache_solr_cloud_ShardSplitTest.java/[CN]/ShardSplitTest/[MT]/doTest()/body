{
  waitForThingsToLevelOut(15);
  ClusterState clusterState=cloudClient.getZkStateReader().getClusterState();
  final DocRouter router=clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();
  Slice shard1=clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION,SHARD1);
  DocRouter.Range shard1Range=shard1.getRange() != null ? shard1.getRange() : router.fullRange();
  final List<DocRouter.Range> ranges=router.partitionRange(2,shard1Range);
  final int[] docCounts=new int[ranges.size()];
  int numReplicas=shard1.getReplicas().size();
  del("*:*");
  for (int id=0; id <= 100; id++) {
    String shardKey="" + (char)('a' + (id % 26));
    indexAndUpdateCount(router,ranges,docCounts,shardKey + "!" + String.valueOf(id),id);
  }
  commit();
  Thread indexThread=new Thread(){
    @Override public void run(){
      Random random=random();
      int max=atLeast(random,401);
      int sleep=atLeast(random,25);
      log.info("SHARDSPLITTEST: Going to add " + max + " number of docs at 1 doc per "+ sleep+ "ms");
      Set<String> deleted=new HashSet<String>();
      for (int id=101; id < max; id++) {
        try {
          indexAndUpdateCount(router,ranges,docCounts,String.valueOf(id),id);
          Thread.sleep(sleep);
          if (usually(random)) {
            String delId=String.valueOf(random.nextInt(id - 101 + 1) + 101);
            if (deleted.contains(delId))             continue;
            try {
              deleteAndUpdateCount(router,ranges,docCounts,delId);
              deleted.add(delId);
            }
 catch (            Exception e) {
              log.error("Exception while deleting docs",e);
            }
          }
        }
 catch (        Exception e) {
          log.error("Exception while adding docs",e);
        }
      }
    }
  }
;
  indexThread.start();
  try {
    splitShard(SHARD1);
    log.info("Layout after split: \n");
    printLayout();
  }
  finally {
    try {
      indexThread.join();
    }
 catch (    InterruptedException e) {
      log.error("Indexing thread interrupted",e);
    }
  }
  commit();
  try {
    checkDocCountsAndShardStates(docCounts,numReplicas);
  }
 catch (  HttpSolrServer.RemoteSolrException e) {
    if (e.code() != 500) {
      throw e;
    }
    Slice slice1_0=null, slice1_1=null;
    int i=0;
    for (i=0; i < 60; i++) {
      ZkStateReader zkStateReader=cloudClient.getZkStateReader();
      zkStateReader.updateClusterState(true);
      clusterState=zkStateReader.getClusterState();
      slice1_0=clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION,"shard1_0");
      slice1_1=clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION,"shard1_1");
      if (slice1_0 != null && slice1_1 != null) {
        break;
      }
      Thread.sleep(500);
    }
    if (slice1_0 == null || slice1_1 == null) {
      throw e;
    }
  }
  waitForRecoveriesToFinish(true);
}
