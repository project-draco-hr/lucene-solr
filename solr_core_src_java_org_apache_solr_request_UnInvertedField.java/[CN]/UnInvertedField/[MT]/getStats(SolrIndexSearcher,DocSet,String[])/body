{
  use.incrementAndGet();
  SchemaField sf=searcher.getSchema().getField(field);
  StatsValues allstats=StatsValuesFactory.createStatsValues(sf);
  DocSet docs=baseDocs;
  int baseSize=docs.size();
  int maxDoc=searcher.maxDoc();
  if (baseSize <= 0)   return allstats;
  DocSet missing=docs.andNot(searcher.getDocSet(new TermRangeQuery(field,null,null,false,false)));
  int i=0;
  final FieldFacetStats[] finfo=new FieldFacetStats[facet.length];
  FieldCache.DocTermsIndex si;
  for (  String f : facet) {
    SchemaField facet_sf=searcher.getSchema().getField(f);
    try {
      si=FieldCache.DEFAULT.getTermsIndex(searcher.getAtomicReader(),f);
    }
 catch (    IOException e) {
      throw new RuntimeException("failed to open field cache for: " + f,e);
    }
    finfo[i]=new FieldFacetStats(f,si,sf,facet_sf,numTermsInField);
    i++;
  }
  final int[] index=this.index;
  final int[] counts=new int[numTermsInField];
  TermsEnum te=getOrdTermsEnum(searcher.getAtomicReader());
  boolean doNegative=false;
  if (finfo.length == 0) {
    doNegative=baseSize > maxDoc >> 1 && termInstances > 0 && docs instanceof BitDocSet;
  }
  if (doNegative) {
    OpenBitSet bs=(OpenBitSet)((BitDocSet)docs).getBits().clone();
    bs.flip(0,maxDoc);
    docs=new BitDocSet(bs,maxDoc - baseSize);
  }
  for (  TopTerm tt : bigTerms.values()) {
    if (tt.termNum >= 0 && tt.termNum < numTermsInField) {
      final Term t=new Term(field,tt.term);
      if (finfo.length == 0) {
        counts[tt.termNum]=searcher.numDocs(new TermQuery(t),docs);
      }
 else {
        DocSet bigTermDocSet=searcher.getDocSet(new TermQuery(t)).intersection(docs);
        DocIterator iter=bigTermDocSet.iterator();
        while (iter.hasNext()) {
          int doc=iter.nextDoc();
          counts[tt.termNum]++;
          for (          FieldFacetStats f : finfo) {
            f.facetTermNum(doc,tt.termNum);
          }
        }
      }
    }
  }
  if (termInstances > 0) {
    DocIterator iter=docs.iterator();
    while (iter.hasNext()) {
      int doc=iter.nextDoc();
      int code=index[doc];
      if ((code & 0xff) == 1) {
        int pos=code >>> 8;
        int whichArray=(doc >>> 16) & 0xff;
        byte[] arr=tnums[whichArray];
        int tnum=0;
        for (; ; ) {
          int delta=0;
          for (; ; ) {
            byte b=arr[pos++];
            delta=(delta << 7) | (b & 0x7f);
            if ((b & 0x80) == 0)             break;
          }
          if (delta == 0)           break;
          tnum+=delta - TNUM_OFFSET;
          counts[tnum]++;
          for (          FieldFacetStats f : finfo) {
            f.facetTermNum(doc,tnum);
          }
        }
      }
 else {
        int tnum=0;
        int delta=0;
        for (; ; ) {
          delta=(delta << 7) | (code & 0x7f);
          if ((code & 0x80) == 0) {
            if (delta == 0)             break;
            tnum+=delta - TNUM_OFFSET;
            counts[tnum]++;
            for (            FieldFacetStats f : finfo) {
              f.facetTermNum(doc,tnum);
            }
            delta=0;
          }
          code>>>=8;
        }
      }
    }
  }
  for (i=0; i < numTermsInField; i++) {
    int c=doNegative ? maxTermCounts[i] - counts[i] : counts[i];
    if (c == 0)     continue;
    BytesRef value=getTermValue(te,i);
    allstats.accumulate(value,c);
    for (    FieldFacetStats f : finfo) {
      f.accumulateTermNum(i,value);
    }
  }
  int c=missing.size();
  allstats.addMissing(c);
  if (finfo.length > 0) {
    for (    FieldFacetStats f : finfo) {
      Map<String,StatsValues> facetStatsValues=f.facetStatsValues;
      FieldType facetType=searcher.getSchema().getFieldType(f.name);
      for (      Map.Entry<String,StatsValues> entry : facetStatsValues.entrySet()) {
        String termLabel=entry.getKey();
        int missingCount=searcher.numDocs(new TermQuery(new Term(f.name,facetType.toInternal(termLabel))),missing);
        entry.getValue().addMissing(missingCount);
      }
      allstats.addFacet(f.name,facetStatsValues);
    }
  }
  return allstats;
}
