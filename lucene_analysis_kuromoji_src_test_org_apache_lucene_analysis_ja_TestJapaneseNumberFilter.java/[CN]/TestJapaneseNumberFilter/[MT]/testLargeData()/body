{
  Path input=Paths.get("/tmp/test.txt");
  Path tokenizedOutput=Paths.get("/tmp/test.tok.txt");
  Path normalizedOutput=Paths.get("/tmp/test.norm.txt");
  Analyzer plainAnalyzer=new Analyzer(){
    @Override protected TokenStreamComponents createComponents(    String fieldName){
      Tokenizer tokenizer=new JapaneseTokenizer(newAttributeFactory(),null,false,JapaneseTokenizer.Mode.SEARCH);
      return new TokenStreamComponents(tokenizer);
    }
  }
;
  analyze(plainAnalyzer,Files.newBufferedReader(input,StandardCharsets.UTF_8),Files.newBufferedWriter(tokenizedOutput,StandardCharsets.UTF_8));
  analyze(analyzer,Files.newBufferedReader(input,StandardCharsets.UTF_8),Files.newBufferedWriter(normalizedOutput,StandardCharsets.UTF_8));
  plainAnalyzer.close();
}
