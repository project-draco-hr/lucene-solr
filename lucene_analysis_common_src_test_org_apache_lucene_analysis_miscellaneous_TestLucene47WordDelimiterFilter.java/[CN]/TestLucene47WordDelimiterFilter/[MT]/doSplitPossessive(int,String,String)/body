{
  int flags=GENERATE_WORD_PARTS | GENERATE_NUMBER_PARTS | SPLIT_ON_CASE_CHANGE| SPLIT_ON_NUMERICS;
  flags|=(stemPossessive == 1) ? STEM_ENGLISH_POSSESSIVE : 0;
  TokenFilter wdf=new Lucene47WordDelimiterFilter(keywordMockTokenizer(input),flags,null);
  assertTokenStreamContents(wdf,output);
}
