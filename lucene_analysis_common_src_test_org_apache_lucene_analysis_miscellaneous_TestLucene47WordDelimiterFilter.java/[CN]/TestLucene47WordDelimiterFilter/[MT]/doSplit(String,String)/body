{
  int flags=GENERATE_WORD_PARTS | GENERATE_NUMBER_PARTS | SPLIT_ON_CASE_CHANGE| SPLIT_ON_NUMERICS| STEM_ENGLISH_POSSESSIVE;
  TokenFilter wdf=new Lucene47WordDelimiterFilter(keywordMockTokenizer(input),WordDelimiterIterator.DEFAULT_WORD_DELIM_TABLE,flags,null);
  assertTokenStreamContents(wdf,output);
}
