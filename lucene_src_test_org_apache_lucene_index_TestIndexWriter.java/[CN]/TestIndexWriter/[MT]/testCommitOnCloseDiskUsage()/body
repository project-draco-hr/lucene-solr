{
  MockDirectoryWrapper dir=newDirectory();
  Analyzer analyzer;
  if (random.nextBoolean()) {
    analyzer=new Analyzer(){
      @Override public TokenStream tokenStream(      String fieldName,      Reader reader){
        return new MockTokenizer(reader,MockTokenizer.WHITESPACE,true);
      }
    }
;
  }
 else {
    final int length=random.nextInt(200);
    analyzer=new Analyzer(){
      @Override public TokenStream tokenStream(      String fieldName,      Reader reader){
        return new MockFixedLengthPayloadFilter(random,new MockTokenizer(reader,MockTokenizer.WHITESPACE,true),length);
      }
    }
;
  }
  IndexWriter writer=new IndexWriter(dir,newIndexWriterConfig(TEST_VERSION_CURRENT,analyzer).setMaxBufferedDocs(10).setReaderPooling(false).setMergePolicy(newLogMergePolicy(10)));
  for (int j=0; j < 30; j++) {
    addDocWithIndex(writer,j);
  }
  writer.close();
  dir.resetMaxUsedSizeInBytes();
  dir.setTrackDiskUsage(true);
  long startDiskUsage=dir.getMaxUsedSizeInBytes();
  writer=new IndexWriter(dir,newIndexWriterConfig(TEST_VERSION_CURRENT,analyzer).setOpenMode(OpenMode.APPEND).setMaxBufferedDocs(10).setMergeScheduler(new SerialMergeScheduler()).setReaderPooling(false).setMergePolicy(newLogMergePolicy(10)));
  for (int j=0; j < 1470; j++) {
    addDocWithIndex(writer,j);
  }
  long midDiskUsage=dir.getMaxUsedSizeInBytes();
  dir.resetMaxUsedSizeInBytes();
  writer.optimize();
  writer.close();
  IndexReader.open(dir,true).close();
  long endDiskUsage=dir.getMaxUsedSizeInBytes();
  assertTrue("writer used too much space while adding documents: mid=" + midDiskUsage + " start="+ startDiskUsage+ " end="+ endDiskUsage+ " max="+ (startDiskUsage * 150),midDiskUsage < 150 * startDiskUsage);
  assertTrue("writer used too much space after close: endDiskUsage=" + endDiskUsage + " startDiskUsage="+ startDiskUsage+ " max="+ (startDiskUsage * 150),endDiskUsage < 150 * startDiskUsage);
  dir.close();
}
