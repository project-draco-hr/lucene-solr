{
  Directory dir=newDirectory(random);
  IndexWriter writer=new IndexWriter(dir,newIndexWriterConfig(random,TEST_VERSION_CURRENT,new MockAnalyzer()).setMaxBufferedDocs(2).setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH).setMergeScheduler(new SerialMergeScheduler()).setMergePolicy(new LogDocMergePolicy()));
  Document document=new Document();
  document=new Document();
  Field storedField=new Field("stored","stored",Field.Store.YES,Field.Index.NO);
  document.add(storedField);
  Field termVectorField=new Field("termVector","termVector",Field.Store.NO,Field.Index.NOT_ANALYZED,Field.TermVector.WITH_POSITIONS_OFFSETS);
  document.add(termVectorField);
  for (int i=0; i < 10; i++)   writer.addDocument(document);
  writer.close();
  writer=new IndexWriter(dir,newIndexWriterConfig(random,TEST_VERSION_CURRENT,new MockAnalyzer()).setMaxBufferedDocs(2).setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH).setMergeScheduler(new SerialMergeScheduler()).setMergePolicy(new LogDocMergePolicy()));
  for (int i=0; i < 6; i++)   writer.addDocument(document);
  writer.optimize();
  writer.close();
  IndexReader reader=IndexReader.open(dir,true);
  for (int i=0; i < 10; i++) {
    reader.getTermFreqVectors(i);
    reader.document(i);
  }
  reader.close();
  dir.close();
}
