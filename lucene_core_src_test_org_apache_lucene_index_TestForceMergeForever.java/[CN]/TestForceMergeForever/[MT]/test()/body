{
  final Directory d=newDirectory();
  MockAnalyzer analyzer=new MockAnalyzer(random());
  analyzer.setMaxTokenLength(TestUtil.nextInt(random(),1,IndexWriter.MAX_TERM_LENGTH));
  final MyIndexWriter w=new MyIndexWriter(d,newIndexWriterConfig(analyzer));
  w.getConfig().setMaxBufferedDocs(TestUtil.nextInt(random(),2,11));
  final int numStartDocs=atLeast(20);
  final LineFileDocs docs=new LineFileDocs(random(),true);
  for (int docIDX=0; docIDX < numStartDocs; docIDX++) {
    w.addDocument(docs.nextDoc());
  }
  MergePolicy mp=w.getConfig().getMergePolicy();
  final int mergeAtOnce=1 + w.segmentInfos.size();
  if (mp instanceof TieredMergePolicy) {
    ((TieredMergePolicy)mp).setMaxMergeAtOnce(mergeAtOnce);
  }
 else   if (mp instanceof LogMergePolicy) {
    ((LogMergePolicy)mp).setMergeFactor(mergeAtOnce);
  }
 else {
    w.close();
    d.close();
    return;
  }
  final AtomicBoolean doStop=new AtomicBoolean();
  w.getConfig().setMaxBufferedDocs(2);
  Thread t=new Thread(){
    @Override public void run(){
      try {
        while (!doStop.get()) {
          w.updateDocument(new Term("docid","" + random().nextInt(numStartDocs)),docs.nextDoc());
          w.getReader().close();
        }
      }
 catch (      Throwable t) {
        throw new RuntimeException(t);
      }
    }
  }
;
  t.start();
  w.forceMerge(1);
  doStop.set(true);
  t.join();
  assertTrue("merge count is " + w.mergeCount.get(),w.mergeCount.get() <= 1);
  w.close();
  d.close();
  docs.close();
}
