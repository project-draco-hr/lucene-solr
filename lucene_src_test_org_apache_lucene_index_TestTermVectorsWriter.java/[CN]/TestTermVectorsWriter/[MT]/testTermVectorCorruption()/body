{
  Directory dir=newDirectory();
  for (int iter=0; iter < 2; iter++) {
    IndexWriter writer=new IndexWriter(dir,newIndexWriterConfig(TEST_VERSION_CURRENT,new MockAnalyzer(random)).setMaxBufferedDocs(2).setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH).setMergeScheduler(new SerialMergeScheduler()).setMergePolicy(new LogDocMergePolicy()));
    Document document=new Document();
    Field storedField=newField("stored","stored",Field.Store.YES,Field.Index.NO);
    document.add(storedField);
    writer.addDocument(document);
    writer.addDocument(document);
    document=new Document();
    document.add(storedField);
    Field termVectorField=newField("termVector","termVector",Field.Store.NO,Field.Index.NOT_ANALYZED,Field.TermVector.WITH_POSITIONS_OFFSETS);
    document.add(termVectorField);
    writer.addDocument(document);
    writer.optimize();
    writer.close();
    IndexReader reader=IndexReader.open(dir,true);
    for (int i=0; i < reader.numDocs(); i++) {
      reader.document(i);
      reader.getTermFreqVectors(i);
    }
    reader.close();
    writer=new IndexWriter(dir,newIndexWriterConfig(TEST_VERSION_CURRENT,new MockAnalyzer(random)).setMaxBufferedDocs(2).setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH).setMergeScheduler(new SerialMergeScheduler()).setMergePolicy(new LogDocMergePolicy()));
    Directory[] indexDirs={new MockDirectoryWrapper(random,new RAMDirectory(dir,newIOContext(random)))};
    writer.addIndexes(indexDirs);
    writer.optimize();
    writer.close();
  }
  dir.close();
}
