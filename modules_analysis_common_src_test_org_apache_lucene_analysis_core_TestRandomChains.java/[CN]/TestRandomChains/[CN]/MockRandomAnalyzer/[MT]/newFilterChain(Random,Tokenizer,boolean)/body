{
  TokenFilterSpec spec=new TokenFilterSpec();
  spec.offsetsAreCorrect=offsetsAreCorrect;
  spec.stream=tokenizer;
  StringBuilder descr=new StringBuilder();
  int numFilters=random.nextInt(5);
  for (int i=0; i < numFilters; i++) {
    spec.stream=new ValidatingTokenFilter(spec.stream,"stage " + i,spec.offsetsAreCorrect);
    while (true) {
      final Constructor<? extends TokenFilter> ctor=tokenfilters.get(random.nextInt(tokenfilters.size()));
      if (ctor.getDeclaringClass().equals(MockGraphTokenFilter.class) && !spec.offsetsAreCorrect) {
        continue;
      }
      final Object args[]=newFilterArgs(random,spec.stream,ctor.getParameterTypes());
      final TokenFilter flt=createComponent(ctor,args,descr);
      if (flt != null) {
        if (brokenOffsetsComponents.contains(ctor.getDeclaringClass())) {
          spec.offsetsAreCorrect=false;
        }
        spec.stream=flt;
        break;
      }
    }
  }
  spec.stream=new ValidatingTokenFilter(spec.stream,"last stage",spec.offsetsAreCorrect);
  spec.toString=descr.toString();
  return spec;
}
