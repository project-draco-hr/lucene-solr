def crawl(downloadedFiles, urlString, targetDir, exclusions=set()):
    for (text, subURL) in getDirEntries(urlString):
        if (text not in exclusions):
            path = os.path.join(targetDir, text)
            if text.endswith('/'):
                if (not os.path.exists(path)):
                    os.makedirs(path)
                crawl(downloadedFiles, subURL, path, exclusions)
            else:
                if ((not os.path.exists(path)) or (not DEBUG)):
                    download(text, subURL, targetDir, quiet=True)
                downloadedFiles.append(path)
                sys.stdout.write('.')
