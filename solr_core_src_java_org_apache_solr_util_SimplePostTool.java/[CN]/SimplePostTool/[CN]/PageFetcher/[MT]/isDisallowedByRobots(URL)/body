{
  String host=url.getHost();
  String strRobot=url.getProtocol() + "://" + host+ "/robots.txt";
  List<String> disallows=robotsCache.get(host);
  if (disallows == null) {
    disallows=new ArrayList<String>();
    URL urlRobot;
    try {
      urlRobot=new URL(strRobot);
      disallows=parseRobotsTxt(urlRobot.openStream());
    }
 catch (    MalformedURLException e) {
      return true;
    }
catch (    IOException e) {
    }
  }
  robotsCache.put(host,disallows);
  String strURL=url.getFile();
  for (  String path : disallows) {
    if (path.equals("/") || strURL.indexOf(path) == 0)     return true;
  }
  return false;
}
