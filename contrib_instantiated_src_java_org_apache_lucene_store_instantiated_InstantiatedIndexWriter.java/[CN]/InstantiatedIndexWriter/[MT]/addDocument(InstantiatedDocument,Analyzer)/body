{
  if (document.getDocumentNumber() != null) {
    throw new RuntimeException("Document number already set! Are you trying to add a document that already is bound to this or another index?");
  }
  Map<String,FieldSetting> fieldSettingsByFieldName=new HashMap<String,FieldSetting>();
  for (  Fieldable field : (List<Fieldable>)document.getDocument().getFields()) {
    FieldSetting fieldSetting=fieldSettingsByFieldName.get(field.name());
    if (fieldSetting == null) {
      fieldSetting=new FieldSetting();
      fieldSetting.fieldName=StringHelper.intern(field.name());
      fieldSettingsByFieldName.put(fieldSetting.fieldName,fieldSetting);
      fieldNameBuffer.add(fieldSetting.fieldName);
    }
    fieldSetting.boost*=field.getBoost();
    if (field.getOmitNorms()) {
      fieldSetting.omitNorms=true;
    }
    if (field.isIndexed()) {
      fieldSetting.indexed=true;
    }
    if (field.isTokenized()) {
      fieldSetting.tokenized=true;
    }
    if (field.isStored()) {
      fieldSetting.stored=true;
    }
    if (field.isBinary()) {
      fieldSetting.isBinary=true;
    }
    if (field.isTermVectorStored()) {
      fieldSetting.storeTermVector=true;
    }
    if (field.isStorePositionWithTermVector()) {
      fieldSetting.storePositionWithTermVector=true;
    }
    if (field.isStoreOffsetWithTermVector()) {
      fieldSetting.storeOffsetWithTermVector=true;
    }
  }
  Map<Fieldable,LinkedList<Token>> tokensByField=new LinkedHashMap<Fieldable,LinkedList<Token>>(20);
  for (Iterator<Fieldable> it=(Iterator<Fieldable>)document.getDocument().getFields().iterator(); it.hasNext(); ) {
    Fieldable field=it.next();
    FieldSetting fieldSetting=fieldSettingsByFieldName.get(field.name());
    if (field.isIndexed()) {
      LinkedList<Token> tokens=new LinkedList<Token>();
      tokensByField.put(field,tokens);
      if (field.isTokenized()) {
        int termCounter=0;
        final TokenStream tokenStream;
        if (field.tokenStreamValue() != null) {
          tokenStream=field.tokenStreamValue();
        }
 else {
          tokenStream=analyzer.tokenStream(field.name(),new StringReader(field.stringValue()));
        }
        tokenStream.reset();
        final Token reusableToken=new Token();
        for (Token nextToken=tokenStream.next(reusableToken); nextToken != null; nextToken=tokenStream.next(reusableToken)) {
          tokens.add((Token)nextToken.clone());
          fieldSetting.fieldLength++;
          if (fieldSetting.fieldLength > maxFieldLength) {
            break;
          }
        }
      }
 else {
        String fieldVal=field.stringValue();
        Token token=new Token(0,fieldVal.length(),"untokenized");
        token.setTermBuffer(fieldVal);
        tokens.add(token);
        fieldSetting.fieldLength++;
      }
    }
    if (!field.isStored()) {
      it.remove();
    }
  }
  Map<FieldSetting,Map<String,TermDocumentInformationFactory>> termDocumentInformationFactoryByTermTextAndFieldSetting=new HashMap<FieldSetting,Map<String,TermDocumentInformationFactory>>();
  termDocumentInformationFactoryByDocument.put(document,termDocumentInformationFactoryByTermTextAndFieldSetting);
  for (  Map.Entry<Fieldable,LinkedList<Token>> eField_Tokens : tokensByField.entrySet()) {
    FieldSetting fieldSetting=fieldSettingsByFieldName.get(eField_Tokens.getKey().name());
    Map<String,TermDocumentInformationFactory> termDocumentInformationFactoryByTermText=termDocumentInformationFactoryByTermTextAndFieldSetting.get(fieldSettingsByFieldName.get(eField_Tokens.getKey().name()));
    if (termDocumentInformationFactoryByTermText == null) {
      termDocumentInformationFactoryByTermText=new HashMap<String,TermDocumentInformationFactory>();
      termDocumentInformationFactoryByTermTextAndFieldSetting.put(fieldSettingsByFieldName.get(eField_Tokens.getKey().name()),termDocumentInformationFactoryByTermText);
    }
    int lastOffset=0;
    if (fieldSetting.position > 0) {
      fieldSetting.position+=analyzer.getPositionIncrementGap(fieldSetting.fieldName);
    }
    for (    Token token : eField_Tokens.getValue()) {
      TermDocumentInformationFactory termDocumentInformationFactory=termDocumentInformationFactoryByTermText.get(token.term());
      if (termDocumentInformationFactory == null) {
        termDocumentInformationFactory=new TermDocumentInformationFactory();
        termDocumentInformationFactoryByTermText.put(token.term(),termDocumentInformationFactory);
      }
      fieldSetting.position+=(token.getPositionIncrement() - 1);
      termDocumentInformationFactory.termPositions.add(fieldSetting.position++);
      if (token.getPayload() != null && token.getPayload().length() > 0) {
        termDocumentInformationFactory.payloads.add(token.getPayload().toByteArray());
        fieldSetting.storePayloads=true;
      }
 else {
        termDocumentInformationFactory.payloads.add(null);
      }
      if (eField_Tokens.getKey().isStoreOffsetWithTermVector()) {
        termDocumentInformationFactory.termOffsets.add(new TermVectorOffsetInfo(fieldSetting.offset + token.startOffset(),fieldSetting.offset + token.endOffset()));
        lastOffset=fieldSetting.offset + token.endOffset();
      }
    }
    if (eField_Tokens.getKey().isStoreOffsetWithTermVector()) {
      fieldSetting.offset=lastOffset + 1;
    }
  }
  unflushedDocuments.add(document);
  if (unflushedDocuments.size() >= getMergeFactor()) {
    commit();
  }
}
