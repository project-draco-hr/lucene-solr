{
  int NUM_THREADS=3;
  int numIterations=TEST_NIGHTLY ? 7 : 3;
  for (int iter=0; iter < numIterations; iter++) {
    if (VERBOSE) {
      System.out.println("\nTEST: iter=" + iter);
    }
    Directory dir=newDirectory();
    IndexWriter writer=new IndexWriter(dir,newIndexWriterConfig(new MockAnalyzer(random())).setMaxBufferedDocs(10).setMergeScheduler(new ConcurrentMergeScheduler()).setMergePolicy(newLogMergePolicy(4)).setCommitOnClose(false));
    ((ConcurrentMergeScheduler)writer.getConfig().getMergeScheduler()).setSuppressExceptions();
    IndexerThread[] threads=new IndexerThread[NUM_THREADS];
    for (int i=0; i < NUM_THREADS; i++)     threads[i]=new IndexerThread(writer,false);
    for (int i=0; i < NUM_THREADS; i++)     threads[i].start();
    boolean done=false;
    while (!done) {
      Thread.sleep(100);
      for (int i=0; i < NUM_THREADS; i++)       if (threads[i].addCount > 0) {
        done=true;
        break;
      }
 else       if (!threads[i].isAlive()) {
        fail("thread failed before indexing a single document");
      }
    }
    if (VERBOSE) {
      System.out.println("\nTEST: now close");
    }
    try {
      writer.commit();
    }
  finally {
      writer.close();
    }
    for (int i=0; i < NUM_THREADS; i++) {
      threads[i].join();
      if (threads[i].isAlive())       fail("thread seems to be hung");
    }
    IndexReader reader=DirectoryReader.open(dir);
    PostingsEnum tdocs=TestUtil.docs(random(),reader,"field",new BytesRef("aaa"),MultiFields.getLiveDocs(reader),null,0);
    int count=0;
    while (tdocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
      count++;
    }
    assertTrue(count > 0);
    reader.close();
    dir.close();
  }
}
