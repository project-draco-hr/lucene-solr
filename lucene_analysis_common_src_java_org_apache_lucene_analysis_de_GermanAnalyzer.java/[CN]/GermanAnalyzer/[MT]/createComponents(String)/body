{
  final Tokenizer source=new StandardTokenizer(matchVersion);
  TokenStream result=new StandardFilter(matchVersion,source);
  result=new LowerCaseFilter(matchVersion,result);
  result=new StopFilter(matchVersion,result,stopwords);
  result=new SetKeywordMarkerFilter(result,exclusionSet);
  result=new GermanNormalizationFilter(result);
  result=new GermanLightStemFilter(result);
  return new TokenStreamComponents(source,result);
}
