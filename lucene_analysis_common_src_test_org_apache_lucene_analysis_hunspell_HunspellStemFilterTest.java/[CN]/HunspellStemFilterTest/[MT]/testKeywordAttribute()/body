{
  MockTokenizer tokenizer=whitespaceMockTokenizer("lucene is awesome");
  tokenizer.setEnableChecks(true);
  HunspellStemFilter filter=new HunspellStemFilter(tokenizer,DICTIONARY,_TestUtil.nextInt(random(),1,3));
  assertTokenStreamContents(filter,new String[]{"lucene","lucen","is","awesome"},new int[]{1,0,1,1});
  tokenizer=whitespaceMockTokenizer("lucene is awesome");
  CharArraySet set=new CharArraySet(TEST_VERSION_CURRENT,Arrays.asList("Lucene"),true);
  filter=new HunspellStemFilter(new SetKeywordMarkerFilter(tokenizer,set),DICTIONARY,_TestUtil.nextInt(random(),1,3));
  assertTokenStreamContents(filter,new String[]{"lucene","is","awesome"},new int[]{1,1,1});
}
