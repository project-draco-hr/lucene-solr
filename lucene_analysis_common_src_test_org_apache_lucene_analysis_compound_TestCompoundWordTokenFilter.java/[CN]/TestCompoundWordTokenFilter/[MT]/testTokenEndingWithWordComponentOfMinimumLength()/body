{
  CharArraySet dict=makeDictionary("ab","cd","ef");
  Tokenizer tokenizer=new MockTokenizer(MockTokenizer.WHITESPACE,false);
  tokenizer.setReader(new StringReader("abcdef"));
  DictionaryCompoundWordTokenFilter tf=new DictionaryCompoundWordTokenFilter(TEST_VERSION_CURRENT,tokenizer,dict,CompoundWordTokenFilterBase.DEFAULT_MIN_WORD_SIZE,CompoundWordTokenFilterBase.DEFAULT_MIN_SUBWORD_SIZE,CompoundWordTokenFilterBase.DEFAULT_MAX_SUBWORD_SIZE,false);
  assertTokenStreamContents(tf,new String[]{"abcdef","ab","cd","ef"},new int[]{0,0,0,0},new int[]{6,6,6,6},new int[]{1,0,0,0});
}
