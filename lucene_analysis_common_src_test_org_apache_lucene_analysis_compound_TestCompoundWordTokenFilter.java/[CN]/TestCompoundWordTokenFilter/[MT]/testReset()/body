{
  CharArraySet dict=makeDictionary("Rind","Fleisch","Draht","Schere","Gesetz","Aufgabe","??berwachung");
  MockTokenizer wsTokenizer=new MockTokenizer(MockTokenizer.WHITESPACE,false);
  wsTokenizer.setEnableChecks(false);
  wsTokenizer.setReader(new StringReader("Rindfleisch??berwachungsgesetz"));
  DictionaryCompoundWordTokenFilter tf=new DictionaryCompoundWordTokenFilter(wsTokenizer,dict,CompoundWordTokenFilterBase.DEFAULT_MIN_WORD_SIZE,CompoundWordTokenFilterBase.DEFAULT_MIN_SUBWORD_SIZE,CompoundWordTokenFilterBase.DEFAULT_MAX_SUBWORD_SIZE,false);
  CharTermAttribute termAtt=tf.getAttribute(CharTermAttribute.class);
  tf.reset();
  assertTrue(tf.incrementToken());
  assertEquals("Rindfleisch??berwachungsgesetz",termAtt.toString());
  assertTrue(tf.incrementToken());
  assertEquals("Rind",termAtt.toString());
  tf.end();
  tf.close();
  wsTokenizer.setReader(new StringReader("Rindfleisch??berwachungsgesetz"));
  tf.reset();
  assertTrue(tf.incrementToken());
  assertEquals("Rindfleisch??berwachungsgesetz",termAtt.toString());
}
