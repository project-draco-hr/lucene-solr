{
  CharArraySet dict=makeDictionary("Rind","Fleisch","Draht","Schere","Gesetz","Aufgabe","??berwachung");
  Tokenizer wsTokenizer=new WhitespaceTokenizer(TEST_VERSION_CURRENT,new StringReader("Rindfleisch??berwachungsgesetz"));
  DictionaryCompoundWordTokenFilter tf=new DictionaryCompoundWordTokenFilter(TEST_VERSION_CURRENT,wsTokenizer,dict,CompoundWordTokenFilterBase.DEFAULT_MIN_WORD_SIZE,CompoundWordTokenFilterBase.DEFAULT_MIN_SUBWORD_SIZE,CompoundWordTokenFilterBase.DEFAULT_MAX_SUBWORD_SIZE,false);
  CharTermAttribute termAtt=tf.getAttribute(CharTermAttribute.class);
  tf.reset();
  assertTrue(tf.incrementToken());
  assertEquals("Rindfleisch??berwachungsgesetz",termAtt.toString());
  assertTrue(tf.incrementToken());
  assertEquals("Rind",termAtt.toString());
  tf.end();
  tf.close();
  wsTokenizer.setReader(new StringReader("Rindfleisch??berwachungsgesetz"));
  tf.reset();
  assertTrue(tf.incrementToken());
  assertEquals("Rindfleisch??berwachungsgesetz",termAtt.toString());
}
