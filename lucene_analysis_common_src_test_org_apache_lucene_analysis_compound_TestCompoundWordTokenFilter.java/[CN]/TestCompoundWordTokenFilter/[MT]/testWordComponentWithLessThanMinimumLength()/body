{
  CharArraySet dict=makeDictionary("abc","d","efg");
  Tokenizer tokenizer=new MockTokenizer(MockTokenizer.WHITESPACE,false);
  tokenizer.setReader(new StringReader("abcdefg"));
  DictionaryCompoundWordTokenFilter tf=new DictionaryCompoundWordTokenFilter(TEST_VERSION_CURRENT,tokenizer,dict,CompoundWordTokenFilterBase.DEFAULT_MIN_WORD_SIZE,CompoundWordTokenFilterBase.DEFAULT_MIN_SUBWORD_SIZE,CompoundWordTokenFilterBase.DEFAULT_MAX_SUBWORD_SIZE,false);
  assertTokenStreamContents(tf,new String[]{"abcdefg","abc","efg"},new int[]{0,0,0},new int[]{7,7,7},new int[]{1,0,0});
}
