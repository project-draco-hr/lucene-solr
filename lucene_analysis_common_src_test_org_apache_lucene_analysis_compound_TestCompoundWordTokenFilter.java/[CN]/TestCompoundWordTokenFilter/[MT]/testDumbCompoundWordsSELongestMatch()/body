{
  CharArraySet dict=makeDictionary("Bil","D??rr","Motor","Tak","Borr","Slag","Hammar","Pelar","Glas","??gon","Fodral","Bas","Fiols","Makare","Ges??ll","Sko","Vind","Rute","Torkare","Blad","Fiolsfodral");
  DictionaryCompoundWordTokenFilter tf=new DictionaryCompoundWordTokenFilter(TEST_VERSION_CURRENT,whitespaceMockTokenizer("Basfiolsfodralmakareges??ll"),dict,CompoundWordTokenFilterBase.DEFAULT_MIN_WORD_SIZE,CompoundWordTokenFilterBase.DEFAULT_MIN_SUBWORD_SIZE,CompoundWordTokenFilterBase.DEFAULT_MAX_SUBWORD_SIZE,true);
  assertTokenStreamContents(tf,new String[]{"Basfiolsfodralmakareges??ll","Bas","fiolsfodral","fodral","makare","ges??ll"},new int[]{0,0,0,0,0,0},new int[]{26,26,26,26,26,26},new int[]{1,0,0,0,0,0});
}
