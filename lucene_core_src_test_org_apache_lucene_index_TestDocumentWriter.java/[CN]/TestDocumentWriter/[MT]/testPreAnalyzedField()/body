{
  IndexWriter writer=new IndexWriter(dir,newIndexWriterConfig(new MockAnalyzer(random())));
  Document doc=new Document();
  doc.add(new TextField("preanalyzed",new TokenStream(){
    private String[] tokens=new String[]{"term1","term2","term3","term2"};
    private int index=0;
    private CharTermAttribute termAtt=addAttribute(CharTermAttribute.class);
    @Override public boolean incrementToken(){
      if (index == tokens.length) {
        return false;
      }
 else {
        clearAttributes();
        termAtt.setEmpty().append(tokens[index++]);
        return true;
      }
    }
  }
));
  writer.addDocument(doc);
  writer.commit();
  SegmentCommitInfo info=writer.newestSegment();
  writer.close();
  SegmentReader reader=new SegmentReader(info,newIOContext(random()));
  PostingsEnum termPositions=reader.termDocsEnum(new Term("preanalyzed","term1"),PostingsEnum.FLAG_ALL);
  assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
  assertEquals(1,termPositions.freq());
  assertEquals(0,termPositions.nextPosition());
  termPositions=reader.termDocsEnum(new Term("preanalyzed","term2"),PostingsEnum.FLAG_ALL);
  assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
  assertEquals(2,termPositions.freq());
  assertEquals(1,termPositions.nextPosition());
  assertEquals(3,termPositions.nextPosition());
  termPositions=reader.termDocsEnum(new Term("preanalyzed","term3"),PostingsEnum.FLAG_ALL);
  assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
  assertEquals(1,termPositions.freq());
  assertEquals(2,termPositions.nextPosition());
  reader.close();
}
