{
  assertFalse(SimplePostTool.pageFetcher.isDisallowedByRobots(new URL("http://[ff01::114]/")));
  assertTrue(SimplePostTool.pageFetcher.isDisallowedByRobots(new URL("http://[ff01::114]/disallowed")));
  assertTrue("There should be two entries parsed from robots.txt",SimplePostTool.pageFetcher.robotsCache.get("[ff01::114]").size() == 2);
}
