{
  assertFalse(SimplePostTool.pageFetcher.isDisallowedByRobots(new URL("http://example.com/")));
  assertTrue(SimplePostTool.pageFetcher.isDisallowedByRobots(new URL("http://example.com/disallowed")));
  assertTrue("There should be two entries parsed from robots.txt",SimplePostTool.pageFetcher.robotsCache.get("example.com").size() == 2);
}
