{
  int numDocs=500;
  final Analyzer analyzer=new Analyzer(){
    @Override public TokenStream tokenStream(    String fieldName,    Reader reader){
      return new MockTokenizer(reader,MockTokenizer.WHITESPACE,true);
    }
  }
;
  Directory directory=new SeekCountingDirectory(new RAMDirectory());
  IndexWriter writer=new IndexWriter(directory,newIndexWriterConfig(TEST_VERSION_CURRENT,analyzer).setMaxBufferedDocs(10).setMergePolicy(newLogMergePolicy(false)));
  for (int i=0; i < numDocs; i++) {
    Document doc=new Document();
    String content;
    if (i % (numDocs / numHits) == 0) {
      content=this.term1 + " " + this.term2;
    }
 else     if (i % 15 == 0) {
      content=this.term1 + " " + this.term1;
    }
 else {
      content=this.term3 + " " + this.term2;
    }
    doc.add(newField(this.field,content,Field.Store.YES,Field.Index.ANALYZED));
    writer.addDocument(doc);
  }
  writer.optimize();
  writer.close();
  SegmentReader reader=getOnlySegmentReader(IndexReader.open(directory,false));
  this.searcher=newSearcher(reader);
}
