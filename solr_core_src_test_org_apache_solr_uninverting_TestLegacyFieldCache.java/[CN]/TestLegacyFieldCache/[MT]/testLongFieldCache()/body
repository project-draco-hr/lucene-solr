{
  Directory dir=newDirectory();
  IndexWriterConfig cfg=newIndexWriterConfig(new MockAnalyzer(random()));
  cfg.setMergePolicy(newLogMergePolicy());
  RandomIndexWriter iw=new RandomIndexWriter(random(),dir,cfg);
  Document doc=new Document();
  LegacyLongField field=new LegacyLongField("f",0L,Store.YES);
  doc.add(field);
  final long[] values=new long[TestUtil.nextInt(random(),1,10)];
  Set<Integer> missing=new HashSet<>();
  for (int i=0; i < values.length; ++i) {
    final long v;
switch (random().nextInt(10)) {
case 0:
      v=Long.MIN_VALUE;
    break;
case 1:
  v=0;
break;
case 2:
v=Long.MAX_VALUE;
break;
default :
v=TestUtil.nextLong(random(),-10,10);
break;
}
values[i]=v;
if (v == 0 && random().nextBoolean()) {
iw.addDocument(new Document());
missing.add(i);
}
 else {
field.setLongValue(v);
iw.addDocument(doc);
}
}
iw.forceMerge(1);
final DirectoryReader reader=iw.getReader();
final NumericDocValues longs=FieldCache.DEFAULT.getNumerics(getOnlyLeafReader(reader),"f",FieldCache.LEGACY_LONG_PARSER);
for (int i=0; i < values.length; ++i) {
if (missing.contains(i) == false) {
assertEquals(i,longs.nextDoc());
assertEquals(values[i],longs.longValue());
}
}
assertEquals(NO_MORE_DOCS,longs.nextDoc());
reader.close();
iw.close();
dir.close();
}
