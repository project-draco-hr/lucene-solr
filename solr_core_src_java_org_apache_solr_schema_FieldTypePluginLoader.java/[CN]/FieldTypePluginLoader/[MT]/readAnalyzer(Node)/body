{
  final SolrResourceLoader loader=schema.getResourceLoader();
  if (node == null)   return null;
  NamedNodeMap attrs=node.getAttributes();
  String analyzerName=DOMUtil.getAttr(attrs,"class");
  NodeList charFilterNodes=(NodeList)xpath.evaluate("./charFilter",node,XPathConstants.NODESET);
  NodeList tokenizerNodes=(NodeList)xpath.evaluate("./tokenizer",node,XPathConstants.NODESET);
  NodeList tokenFilterNodes=(NodeList)xpath.evaluate("./filter",node,XPathConstants.NODESET);
  if (analyzerName != null) {
    if (0 != charFilterNodes.getLength() || 0 != tokenizerNodes.getLength() || 0 != tokenFilterNodes.getLength()) {
      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,"Configuration Error: Analyzer class='" + analyzerName + "' can not be combined with nested analysis factories");
    }
    try {
      final Class<? extends Analyzer> clazz=loader.findClass(analyzerName,Analyzer.class);
      try {
        Constructor<? extends Analyzer> cnstr=clazz.getConstructor(Version.class);
        final String matchVersionStr=DOMUtil.getAttr(attrs,LUCENE_MATCH_VERSION_PARAM);
        final Version luceneMatchVersion=(matchVersionStr == null) ? schema.getDefaultLuceneMatchVersion() : Config.parseLuceneVersionString(matchVersionStr);
        if (luceneMatchVersion == null) {
          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,"Configuration Error: Analyzer '" + clazz.getName() + "' needs a 'luceneMatchVersion' parameter");
        }
        return cnstr.newInstance(luceneMatchVersion);
      }
 catch (      NoSuchMethodException nsme) {
        return clazz.newInstance();
      }
    }
 catch (    Exception e) {
      log.error("Cannot load analyzer: " + analyzerName,e);
      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,"Cannot load analyzer: " + analyzerName,e);
    }
  }
  final ArrayList<CharFilterFactory> charFilters=new ArrayList<CharFilterFactory>();
  AbstractPluginLoader<CharFilterFactory> charFilterLoader=new AbstractPluginLoader<CharFilterFactory>("[schema.xml] analyzer/charFilter",CharFilterFactory.class,false,false){
    @Override protected void init(    CharFilterFactory plugin,    Node node) throws Exception {
      if (plugin != null) {
        final Map<String,String> params=DOMUtil.toMapExcept(node.getAttributes(),"class");
        String configuredVersion=params.remove(LUCENE_MATCH_VERSION_PARAM);
        plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion,plugin.getClass().getSimpleName()));
        plugin.init(params);
        charFilters.add(plugin);
      }
    }
    @Override protected CharFilterFactory register(    String name,    CharFilterFactory plugin){
      return null;
    }
  }
;
  charFilterLoader.load(loader,charFilterNodes);
  final ArrayList<TokenizerFactory> tokenizers=new ArrayList<TokenizerFactory>(1);
  AbstractPluginLoader<TokenizerFactory> tokenizerLoader=new AbstractPluginLoader<TokenizerFactory>("[schema.xml] analyzer/tokenizer",TokenizerFactory.class,false,false){
    @Override protected void init(    TokenizerFactory plugin,    Node node) throws Exception {
      if (!tokenizers.isEmpty()) {
        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,"The schema defines multiple tokenizers for: " + node);
      }
      final Map<String,String> params=DOMUtil.toMapExcept(node.getAttributes(),"class");
      String configuredVersion=params.remove(LUCENE_MATCH_VERSION_PARAM);
      plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion,plugin.getClass().getSimpleName()));
      plugin.init(params);
      tokenizers.add(plugin);
    }
    @Override protected TokenizerFactory register(    String name,    TokenizerFactory plugin){
      return null;
    }
  }
;
  tokenizerLoader.load(loader,tokenizerNodes);
  if (tokenizers.isEmpty()) {
    throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,"analyzer without class or tokenizer");
  }
  final ArrayList<TokenFilterFactory> filters=new ArrayList<TokenFilterFactory>();
  AbstractPluginLoader<TokenFilterFactory> filterLoader=new AbstractPluginLoader<TokenFilterFactory>("[schema.xml] analyzer/filter",TokenFilterFactory.class,false,false){
    @Override protected void init(    TokenFilterFactory plugin,    Node node) throws Exception {
      if (plugin != null) {
        final Map<String,String> params=DOMUtil.toMapExcept(node.getAttributes(),"class");
        String configuredVersion=params.remove(LUCENE_MATCH_VERSION_PARAM);
        plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion,plugin.getClass().getSimpleName()));
        plugin.init(params);
        filters.add(plugin);
      }
    }
    @Override protected TokenFilterFactory register(    String name,    TokenFilterFactory plugin) throws Exception {
      return null;
    }
  }
;
  filterLoader.load(loader,tokenFilterNodes);
  return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),tokenizers.get(0),filters.toArray(new TokenFilterFactory[filters.size()]));
}
