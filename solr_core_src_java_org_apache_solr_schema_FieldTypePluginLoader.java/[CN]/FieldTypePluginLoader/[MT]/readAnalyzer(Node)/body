{
  final SolrResourceLoader loader=schema.getResourceLoader();
  if (node == null)   return null;
  NamedNodeMap attrs=node.getAttributes();
  String analyzerName=DOMUtil.getAttr(attrs,"class");
  NodeList charFilterNodes=(NodeList)xpath.evaluate("./charFilter",node,XPathConstants.NODESET);
  NodeList tokenizerNodes=(NodeList)xpath.evaluate("./tokenizer",node,XPathConstants.NODESET);
  NodeList tokenFilterNodes=(NodeList)xpath.evaluate("./filter",node,XPathConstants.NODESET);
  if (analyzerName != null) {
    if (0 != charFilterNodes.getLength() || 0 != tokenizerNodes.getLength() || 0 != tokenFilterNodes.getLength()) {
      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,"Configuration Error: Analyzer class='" + analyzerName + "' can not be combined with nested analysis factories");
    }
    try {
      final Class<? extends Analyzer> clazz=loader.findClass(analyzerName,Analyzer.class);
      Analyzer analyzer=clazz.newInstance();
      final String matchVersionStr=DOMUtil.getAttr(attrs,LUCENE_MATCH_VERSION_PARAM);
      final Version luceneMatchVersion=(matchVersionStr == null) ? schema.getDefaultLuceneMatchVersion() : Config.parseLuceneVersionString(matchVersionStr);
      if (luceneMatchVersion == null) {
        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,"Configuration Error: Analyzer '" + clazz.getName() + "' needs a 'luceneMatchVersion' parameter");
      }
      analyzer.setVersion(luceneMatchVersion);
      return analyzer;
    }
 catch (    Exception e) {
      log.error("Cannot load analyzer: " + analyzerName,e);
      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,"Cannot load analyzer: " + analyzerName,e);
    }
  }
  final ArrayList<CharFilterFactory> charFilters=new ArrayList<>();
  AbstractPluginLoader<CharFilterFactory> charFilterLoader=new AbstractPluginLoader<CharFilterFactory>("[schema.xml] analyzer/charFilter",CharFilterFactory.class,false,false){
    @Override protected CharFilterFactory create(    SolrResourceLoader loader,    String name,    String className,    Node node) throws Exception {
      final Map<String,String> params=DOMUtil.toMap(node.getAttributes());
      String configuredVersion=params.remove(LUCENE_MATCH_VERSION_PARAM);
      params.put(LUCENE_MATCH_VERSION_PARAM,parseConfiguredVersion(configuredVersion,CharFilterFactory.class.getSimpleName()).toString());
      CharFilterFactory factory=loader.newInstance(className,CharFilterFactory.class,getDefaultPackages(),new Class[]{Map.class},new Object[]{params});
      factory.setExplicitLuceneMatchVersion(null != configuredVersion);
      return factory;
    }
    @Override protected void init(    CharFilterFactory plugin,    Node node) throws Exception {
      if (plugin != null) {
        charFilters.add(plugin);
      }
    }
    @Override protected CharFilterFactory register(    String name,    CharFilterFactory plugin){
      return null;
    }
  }
;
  charFilterLoader.load(loader,charFilterNodes);
  final ArrayList<TokenizerFactory> tokenizers=new ArrayList<>(1);
  AbstractPluginLoader<TokenizerFactory> tokenizerLoader=new AbstractPluginLoader<TokenizerFactory>("[schema.xml] analyzer/tokenizer",TokenizerFactory.class,false,false){
    @Override protected TokenizerFactory create(    SolrResourceLoader loader,    String name,    String className,    Node node) throws Exception {
      final Map<String,String> params=DOMUtil.toMap(node.getAttributes());
      String configuredVersion=params.remove(LUCENE_MATCH_VERSION_PARAM);
      params.put(LUCENE_MATCH_VERSION_PARAM,parseConfiguredVersion(configuredVersion,TokenizerFactory.class.getSimpleName()).toString());
      TokenizerFactory factory=loader.newInstance(className,TokenizerFactory.class,getDefaultPackages(),new Class[]{Map.class},new Object[]{params});
      factory.setExplicitLuceneMatchVersion(null != configuredVersion);
      return factory;
    }
    @Override protected void init(    TokenizerFactory plugin,    Node node) throws Exception {
      if (!tokenizers.isEmpty()) {
        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,"The schema defines multiple tokenizers for: " + node);
      }
      tokenizers.add(plugin);
    }
    @Override protected TokenizerFactory register(    String name,    TokenizerFactory plugin){
      return null;
    }
  }
;
  tokenizerLoader.load(loader,tokenizerNodes);
  if (tokenizers.isEmpty()) {
    throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,"analyzer without class or tokenizer");
  }
  final ArrayList<TokenFilterFactory> filters=new ArrayList<>();
  AbstractPluginLoader<TokenFilterFactory> filterLoader=new AbstractPluginLoader<TokenFilterFactory>("[schema.xml] analyzer/filter",TokenFilterFactory.class,false,false){
    @Override protected TokenFilterFactory create(    SolrResourceLoader loader,    String name,    String className,    Node node) throws Exception {
      final Map<String,String> params=DOMUtil.toMap(node.getAttributes());
      String configuredVersion=params.remove(LUCENE_MATCH_VERSION_PARAM);
      params.put(LUCENE_MATCH_VERSION_PARAM,parseConfiguredVersion(configuredVersion,TokenFilterFactory.class.getSimpleName()).toString());
      TokenFilterFactory factory=loader.newInstance(className,TokenFilterFactory.class,getDefaultPackages(),new Class[]{Map.class},new Object[]{params});
      factory.setExplicitLuceneMatchVersion(null != configuredVersion);
      return factory;
    }
    @Override protected void init(    TokenFilterFactory plugin,    Node node) throws Exception {
      if (plugin != null) {
        filters.add(plugin);
      }
    }
    @Override protected TokenFilterFactory register(    String name,    TokenFilterFactory plugin) throws Exception {
      return null;
    }
  }
;
  filterLoader.load(loader,tokenFilterNodes);
  return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),tokenizers.get(0),filters.toArray(new TokenFilterFactory[filters.size()]));
}
