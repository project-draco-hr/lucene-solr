import sys
import glob
import datetime
import tarfile
import re
try:
    sys.argv.remove('-verbose')
    VERBOSE = True
except ValueError:
    VERBOSE = False
try:
    sys.argv.remove('-docPerParagraph')
    docPerParagraph = True
except ValueError:
    docPerParagraph = False
reChapterOnly = re.compile('^<CHAPTER ID=.*?>$')
reTagOnly = re.compile('^<.*?>$')
reNumberOnly = re.compile('^\\d+\\.?$')
maxDoc = 0
didEnglish = False
dirIn = sys.argv[1]
fileOut = sys.argv[2]
fOut = open(fileOut, 'wb')
for fileName in glob.glob(('%s/??-??.tgz' % dirIn)):
    if fileName.endswith('.tgz'):
        print ('process %s; %d docs so far...' % (fileName, maxDoc))
        processTar(fileName, fOut)
print ('TOTAL: %s' % maxDoc)
"\n\n# Europarl V5 makes 76,917 docs, avg 38.6 KB per\npython -u europarl.py /x/lucene/data/europarl /x/lucene/data/europarl/tmp.lines.txt\nshuf /x/lucene/data/europarl/tmp.lines.txt > /x/lucene/data/europarl/full.lines.txt\nrm /x/lucene/data/europarl/tmp.lines.txt\n\n# Run again, this time each paragraph is a doc:\n# Europarl V5 makes 5,607,746 paragraphs (one paragraph per line), avg 620 bytes per:\npython -u europarl.py /x/lucene/data/europarl /x/lucene/data/europarl/tmp.lines.txt -docPerParagraph\nshuf /x/lucene/data/europarl/tmp.lines.txt > /x/lucene/data/europarl/para.lines.txt\nrm /x/lucene/data/europarl/tmp.lines.txt\n\n# ~5.5 MB gzip'd:\nhead -200 /x/lucene/data/europarl/full.lines.txt > tmp.txt\nhead -10000 /x/lucene/data/europarl/para.lines.txt >> tmp.txt\nshuf tmp.txt > europarl.subset.txt\nrm -f tmp.txt\ngzip --best europarl.subset.txt\n"
