{
  if (!tpv.hasOffsets()) {
    throw new IllegalArgumentException("Cannot create TokenStream from Terms without offsets");
  }
  if (!tokenPositionsGuaranteedContiguous && tpv.hasPositions()) {
    return new TokenStreamFromTermPositionVector(tpv);
  }
final class StoredTokenStream extends TokenStream {
    Token tokens[];
    int currentToken=0;
    CharTermAttribute termAtt;
    OffsetAttribute offsetAtt;
    PositionIncrementAttribute posincAtt;
    PayloadAttribute payloadAtt;
    StoredTokenStream(    Token tokens[]){
      this.tokens=tokens;
      termAtt=addAttribute(CharTermAttribute.class);
      offsetAtt=addAttribute(OffsetAttribute.class);
      posincAtt=addAttribute(PositionIncrementAttribute.class);
      payloadAtt=addAttribute(PayloadAttribute.class);
    }
    @Override public boolean incrementToken(){
      if (currentToken >= tokens.length) {
        return false;
      }
      Token token=tokens[currentToken++];
      clearAttributes();
      termAtt.setEmpty().append(token);
      offsetAtt.setOffset(token.startOffset(),token.endOffset());
      BytesRef payload=token.getPayload();
      if (payload != null) {
        payloadAtt.setPayload(payload);
      }
      posincAtt.setPositionIncrement(currentToken <= 1 || tokens[currentToken - 1].startOffset() > tokens[currentToken - 2].startOffset() ? 1 : 0);
      return true;
    }
  }
  boolean hasPayloads=tpv.hasPayloads();
  TermsEnum termsEnum=tpv.iterator(null);
  int totalTokens=0;
  while (termsEnum.next() != null) {
    totalTokens+=(int)termsEnum.totalTermFreq();
  }
  Token tokensInOriginalOrder[]=new Token[totalTokens];
  ArrayList<Token> unsortedTokens=null;
  termsEnum=tpv.iterator(null);
  BytesRef text;
  DocsAndPositionsEnum dpEnum=null;
  while ((text=termsEnum.next()) != null) {
    dpEnum=termsEnum.docsAndPositions(null,dpEnum);
    if (dpEnum == null) {
      throw new IllegalArgumentException("Required TermVector Offset information was not found");
    }
    final String term=text.utf8ToString();
    dpEnum.nextDoc();
    final int freq=dpEnum.freq();
    for (int posUpto=0; posUpto < freq; posUpto++) {
      final int pos=dpEnum.nextPosition();
      if (dpEnum.startOffset() < 0) {
        throw new IllegalArgumentException("Required TermVector Offset information was not found");
      }
      final Token token=new Token(term,dpEnum.startOffset(),dpEnum.endOffset());
      if (hasPayloads) {
        token.setPayload(BytesRef.deepCopyOf(dpEnum.getPayload()));
      }
      if (tokenPositionsGuaranteedContiguous && pos != -1) {
        tokensInOriginalOrder[pos]=token;
      }
 else {
        if (unsortedTokens == null) {
          unsortedTokens=new ArrayList<Token>();
        }
        unsortedTokens.add(token);
      }
    }
  }
  if (unsortedTokens != null) {
    tokensInOriginalOrder=unsortedTokens.toArray(new Token[unsortedTokens.size()]);
    ArrayUtil.timSort(tokensInOriginalOrder,new Comparator<Token>(){
      @Override public int compare(      Token t1,      Token t2){
        if (t1.startOffset() == t2.startOffset()) {
          return t1.endOffset() - t2.endOffset();
        }
 else {
          return t1.startOffset() - t2.startOffset();
        }
      }
    }
);
  }
  return new StoredTokenStream(tokensInOriginalOrder);
}
