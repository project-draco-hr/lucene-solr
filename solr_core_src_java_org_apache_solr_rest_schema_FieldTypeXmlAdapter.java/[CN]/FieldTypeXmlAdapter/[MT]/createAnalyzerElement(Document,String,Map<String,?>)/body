{
  Element analyzerElem=appendAttrs(doc.createElement("analyzer"),analyzer);
  if (type != null)   analyzerElem.setAttribute("type",type);
  List<Map<String,?>> charFilters=(List<Map<String,?>>)analyzer.get("charFilters");
  Map<String,?> tokenizer=(Map<String,?>)analyzer.get("tokenizer");
  List<Map<String,?>> filters=(List<Map<String,?>>)analyzer.get("filters");
  if (analyzer.get("class") == null) {
    if (charFilters != null)     appendFilterElements(doc,analyzerElem,"charFilter",charFilters);
    if (tokenizer == null)     throw new SolrException(ErrorCode.BAD_REQUEST,"Analyzer must define a tokenizer!");
    if (tokenizer.get("class") == null)     throw new SolrException(ErrorCode.BAD_REQUEST,"Every tokenizer must define a class property!");
    analyzerElem.appendChild(appendAttrs(doc.createElement("tokenizer"),tokenizer));
    if (filters != null)     appendFilterElements(doc,analyzerElem,"filter",filters);
  }
 else {
    if (charFilters != null)     throw new SolrException(ErrorCode.BAD_REQUEST,"An analyzer with a class property may not define any char filters!");
    if (tokenizer != null)     throw new SolrException(ErrorCode.BAD_REQUEST,"An analyzer with a class property may not define a tokenizer!");
    if (filters != null)     throw new SolrException(ErrorCode.BAD_REQUEST,"An analyzer with a class property may not define any filters!");
  }
  return analyzerElem;
}
