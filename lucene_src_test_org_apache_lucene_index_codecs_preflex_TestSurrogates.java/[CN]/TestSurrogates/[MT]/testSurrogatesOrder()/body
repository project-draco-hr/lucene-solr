{
  Random r=newRandom();
  Directory dir=new MockRAMDirectory();
  RandomIndexWriter w=new RandomIndexWriter(r,dir,newIndexWriterConfig(r,TEST_VERSION_CURRENT,new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));
  final int numField=_TestUtil.nextInt(r,2,5);
  int uniqueTermCount=0;
  int tc=0;
  List<Term> fieldTerms=new ArrayList<Term>();
  for (int f=0; f < numField; f++) {
    String field="f" + f;
    Term protoTerm=new Term(field);
    final int numTerms=10000 * _TestUtil.getRandomMultiplier();
    final Set<String> uniqueTerms=new HashSet<String>();
    for (int i=0; i < numTerms; i++) {
      String term=getRandomString(r) + "_ " + (tc++);
      uniqueTerms.add(term);
      fieldTerms.add(new Term(field,term));
      Document doc=new Document();
      doc.add(new Field(field,term,Field.Store.NO,Field.Index.NOT_ANALYZED));
      w.addDocument(doc);
    }
    uniqueTermCount+=uniqueTerms.size();
  }
  IndexReader reader=w.getReader();
  if (VERBOSE) {
    Collections.sort(fieldTerms,termAsUTF16Comparator);
    System.out.println("\nTEST: UTF16 order");
    for (    Term t : fieldTerms) {
      System.out.println("  " + toHexString(t));
    }
  }
  Collections.sort(fieldTerms);
  if (VERBOSE) {
    System.out.println("\nTEST: codepoint order");
    for (    Term t : fieldTerms) {
      System.out.println("  " + toHexString(t));
    }
  }
  Term[] fieldTermsArray=fieldTerms.toArray(new Term[fieldTerms.size()]);
  doTestStraightEnum(fieldTerms,reader,uniqueTermCount);
  doTestSeekExists(r,fieldTerms,reader);
  doTestSeekDoesNotExist(r,numField,fieldTerms,fieldTermsArray,reader);
  reader.close();
}
