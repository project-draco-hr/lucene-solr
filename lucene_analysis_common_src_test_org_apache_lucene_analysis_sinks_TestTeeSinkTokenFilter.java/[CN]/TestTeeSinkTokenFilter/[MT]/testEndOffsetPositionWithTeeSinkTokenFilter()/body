{
  Directory dir=newDirectory();
  Analyzer analyzer=new MockAnalyzer(random(),MockTokenizer.WHITESPACE,false);
  IndexWriter w=new IndexWriter(dir,newIndexWriterConfig(analyzer));
  Document doc=new Document();
  TokenStream tokenStream=analyzer.tokenStream("field","abcd   ");
  TeeSinkTokenFilter tee=new TeeSinkTokenFilter(tokenStream);
  TokenStream sink=tee.newSinkTokenStream();
  FieldType ft=new FieldType(TextField.TYPE_NOT_STORED);
  ft.setStoreTermVectors(true);
  ft.setStoreTermVectorOffsets(true);
  ft.setStoreTermVectorPositions(true);
  Field f1=new Field("field",tee,ft);
  Field f2=new Field("field",sink,ft);
  doc.add(f1);
  doc.add(f2);
  w.addDocument(doc);
  w.close();
  IndexReader r=DirectoryReader.open(dir);
  Terms vector=r.getTermVectors(0).terms("field");
  assertEquals(1,vector.size());
  TermsEnum termsEnum=vector.iterator(null);
  termsEnum.next();
  assertEquals(2,termsEnum.totalTermFreq());
  PostingsEnum positions=termsEnum.postings(null,null,PostingsEnum.ALL);
  assertTrue(positions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
  assertEquals(2,positions.freq());
  positions.nextPosition();
  assertEquals(0,positions.startOffset());
  assertEquals(4,positions.endOffset());
  positions.nextPosition();
  assertEquals(8,positions.startOffset());
  assertEquals(12,positions.endOffset());
  assertEquals(DocIdSetIterator.NO_MORE_DOCS,positions.nextDoc());
  r.close();
  dir.close();
  analyzer.close();
}
