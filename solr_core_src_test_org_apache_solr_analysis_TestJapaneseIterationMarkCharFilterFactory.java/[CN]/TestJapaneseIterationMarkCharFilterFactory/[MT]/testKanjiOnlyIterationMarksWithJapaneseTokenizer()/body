{
  JapaneseTokenizerFactory tokenizerFactory=new JapaneseTokenizerFactory();
  Map<String,String> tokenizerArgs=Collections.emptyMap();
  tokenizerFactory.init(tokenizerArgs);
  tokenizerFactory.inform(new SolrResourceLoader(null,null));
  JapaneseIterationMarkCharFilterFactory filterFactory=new JapaneseIterationMarkCharFilterFactory();
  Map<String,String> filterArgs=new HashMap<String,String>();
  filterArgs.put("normalizeKanji","true");
  filterArgs.put("normalizeKana","false");
  filterFactory.init(filterArgs);
  CharStream filter=filterFactory.create(CharReader.get(new StringReader("???????????????????????????????????????????????????")));
  TokenStream tokenStream=tokenizerFactory.create(filter);
  assertTokenStreamContents(tokenStream,new String[]{"??????","??????????????????","?????????","???","???","???","??????","???"});
}
