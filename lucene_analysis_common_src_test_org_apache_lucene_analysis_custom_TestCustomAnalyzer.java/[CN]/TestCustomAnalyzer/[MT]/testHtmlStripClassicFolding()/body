{
  CustomAnalyzer a=CustomAnalyzer.builder().withDefaultMatchVersion(Version.LUCENE_5_0_0).addCharFilter("htmlstrip").withTokenizer("classic").addTokenFilter("asciifolding","preserveOriginal","true").addTokenFilter("lowercase").withPositionIncrementGap(100).withOffsetGap(1000).build();
  assertSame(ClassicTokenizerFactory.class,a.getTokenizerFactory().getClass());
  List<CharFilterFactory> charFilters=a.getCharFilterFactories();
  assertEquals(1,charFilters.size());
  assertEquals(HTMLStripCharFilterFactory.class,charFilters.get(0).getClass());
  List<TokenFilterFactory> tokenFilters=a.getTokenFilterFactories();
  assertEquals(2,tokenFilters.size());
  assertSame(ASCIIFoldingFilterFactory.class,tokenFilters.get(0).getClass());
  assertSame(LowerCaseFilterFactory.class,tokenFilters.get(1).getClass());
  assertEquals(100,a.getPositionIncrementGap("dummy"));
  assertEquals(1000,a.getOffsetGap("dummy"));
  assertSame(Version.LUCENE_5_0_0,a.getVersion());
  assertAnalyzesTo(a,"<p>foo bar</p> FOO BAR",new String[]{"foo","bar","foo","bar"},new int[]{1,1,1,1});
  assertAnalyzesTo(a,"<p><b>f????</b> b??r     F???? BAR</p>",new String[]{"foo","f????","bar","b??r","foo","f????","bar"},new int[]{1,0,1,0,1,0,1});
  a.close();
}
