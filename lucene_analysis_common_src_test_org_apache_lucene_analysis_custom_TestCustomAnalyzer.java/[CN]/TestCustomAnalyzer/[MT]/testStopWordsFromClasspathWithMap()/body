{
  Map<String,String> stopConfig1=new HashMap<>();
  stopConfig1.put("ignoreCase","true");
  stopConfig1.put("words","org/apache/lucene/analysis/custom/teststop.txt");
  stopConfig1.put("format","wordset");
  Map<String,String> stopConfig2=new HashMap<>(stopConfig1);
  Map<String,String> stopConfigImmutable=Collections.unmodifiableMap(new HashMap<>(stopConfig1));
  CustomAnalyzer a=CustomAnalyzer.builder().withTokenizer("whitespace").addTokenFilter("stop",stopConfig1).build();
  assertTrue(stopConfig1.isEmpty());
  assertAnalyzesTo(a,"foo Foo Bar",new String[0]);
  a=CustomAnalyzer.builder().withTokenizer(WhitespaceTokenizerFactory.class).addTokenFilter(StopFilterFactory.class,stopConfig2).build();
  assertTrue(stopConfig2.isEmpty());
  assertAnalyzesTo(a,"foo Foo Bar",new String[0]);
  try {
    CustomAnalyzer.builder().withTokenizer("whitespace").addTokenFilter("stop",stopConfigImmutable).build();
    fail();
  }
 catch (  UnsupportedOperationException e) {
  }
  a.close();
}
