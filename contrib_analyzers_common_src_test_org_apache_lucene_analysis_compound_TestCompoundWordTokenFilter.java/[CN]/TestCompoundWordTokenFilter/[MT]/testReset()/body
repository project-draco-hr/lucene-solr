{
  String[] dict={"Rind","Fleisch","Draht","Schere","Gesetz","Aufgabe","??berwachung"};
  Tokenizer wsTokenizer=new WhitespaceTokenizer(Version.LUCENE_CURRENT,new StringReader("Rindfleisch??berwachungsgesetz"));
  DictionaryCompoundWordTokenFilter tf=new DictionaryCompoundWordTokenFilter(Version.LUCENE_CURRENT,wsTokenizer,dict,CompoundWordTokenFilterBase.DEFAULT_MIN_WORD_SIZE,CompoundWordTokenFilterBase.DEFAULT_MIN_SUBWORD_SIZE,CompoundWordTokenFilterBase.DEFAULT_MAX_SUBWORD_SIZE,false);
  TermAttribute termAtt=tf.getAttribute(TermAttribute.class);
  assertTrue(tf.incrementToken());
  assertEquals("Rindfleisch??berwachungsgesetz",termAtt.term());
  assertTrue(tf.incrementToken());
  assertEquals("Rind",termAtt.term());
  wsTokenizer.reset(new StringReader("Rindfleisch??berwachungsgesetz"));
  tf.reset();
  assertTrue(tf.incrementToken());
  assertEquals("Rindfleisch??berwachungsgesetz",termAtt.term());
}
