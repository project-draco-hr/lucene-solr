{
  IndexWriter writer=new IndexWriter(dir,newIndexWriterConfig(TEST_VERSION_CURRENT,new MockAnalyzer(random)));
  Document doc=new Document();
  doc.add(new Field("preanalyzed",new TokenStream(){
    private String[] tokens=new String[]{"term1","term2","term3","term2"};
    private int index=0;
    private CharTermAttribute termAtt=addAttribute(CharTermAttribute.class);
    @Override public boolean incrementToken() throws IOException {
      if (index == tokens.length) {
        return false;
      }
 else {
        clearAttributes();
        termAtt.setEmpty().append(tokens[index++]);
        return true;
      }
    }
  }
,TermVector.NO));
  writer.addDocument(doc);
  writer.commit();
  SegmentInfo info=writer.newestSegment();
  writer.close();
  SegmentReader reader=SegmentReader.get(true,info,IndexReader.DEFAULT_TERMS_INDEX_DIVISOR,newIOContext(random));
  DocsAndPositionsEnum termPositions=reader.fields().terms("preanalyzed").docsAndPositions(reader.getLiveDocs(),new BytesRef("term1"),null);
  assertTrue(termPositions.nextDoc() != termPositions.NO_MORE_DOCS);
  assertEquals(1,termPositions.freq());
  assertEquals(0,termPositions.nextPosition());
  termPositions=reader.fields().terms("preanalyzed").docsAndPositions(reader.getLiveDocs(),new BytesRef("term2"),null);
  assertTrue(termPositions.nextDoc() != termPositions.NO_MORE_DOCS);
  assertEquals(2,termPositions.freq());
  assertEquals(1,termPositions.nextPosition());
  assertEquals(3,termPositions.nextPosition());
  termPositions=reader.fields().terms("preanalyzed").docsAndPositions(reader.getLiveDocs(),new BytesRef("term3"),null);
  assertTrue(termPositions.nextDoc() != termPositions.NO_MORE_DOCS);
  assertEquals(1,termPositions.freq());
  assertEquals(2,termPositions.nextPosition());
  reader.close();
}
