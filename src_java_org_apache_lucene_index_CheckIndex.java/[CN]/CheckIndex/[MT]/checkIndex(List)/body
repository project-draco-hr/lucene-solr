{
  NumberFormat nf=NumberFormat.getInstance();
  SegmentInfos sis=new SegmentInfos();
  Status result=new Status();
  result.dir=dir;
  try {
    sis.read(dir);
  }
 catch (  Throwable t) {
    msg("ERROR: could not read any segments file in directory");
    result.missingSegments=true;
    if (infoStream != null)     t.printStackTrace(infoStream);
    return result;
  }
  final int numSegments=sis.size();
  final String segmentsFileName=sis.getCurrentSegmentFileName();
  IndexInput input=null;
  try {
    input=dir.openInput(segmentsFileName);
  }
 catch (  Throwable t) {
    msg("ERROR: could not open segments file in directory");
    if (infoStream != null)     t.printStackTrace(infoStream);
    result.cantOpenSegments=true;
    return result;
  }
  int format=0;
  try {
    format=input.readInt();
  }
 catch (  Throwable t) {
    msg("ERROR: could not read segment file version in directory");
    if (infoStream != null)     t.printStackTrace(infoStream);
    result.missingSegmentVersion=true;
    return result;
  }
 finally {
    if (input != null)     input.close();
  }
  String sFormat="";
  boolean skip=false;
  if (format == SegmentInfos.FORMAT)   sFormat="FORMAT [Lucene Pre-2.1]";
  if (format == SegmentInfos.FORMAT_LOCKLESS)   sFormat="FORMAT_LOCKLESS [Lucene 2.1]";
 else   if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)   sFormat="FORMAT_SINGLE_NORM_FILE [Lucene 2.2]";
 else   if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)   sFormat="FORMAT_SHARED_DOC_STORE [Lucene 2.3]";
 else {
    if (format == SegmentInfos.FORMAT_CHECKSUM)     sFormat="FORMAT_CHECKSUM [Lucene 2.4]";
 else     if (format == SegmentInfos.FORMAT_DEL_COUNT)     sFormat="FORMAT_DEL_COUNT [Lucene 2.4]";
 else     if (format == SegmentInfos.FORMAT_HAS_PROX)     sFormat="FORMAT_HAS_PROX [Lucene 2.4]";
 else     if (format == SegmentInfos.FORMAT_USER_DATA)     sFormat="FORMAT_USER_DATA [Lucene 2.9]";
 else     if (format < SegmentInfos.CURRENT_FORMAT) {
      sFormat="int=" + format + " [newer version of Lucene than this tool]";
      skip=true;
    }
 else {
      sFormat=format + " [Lucene 1.3 or prior]";
    }
  }
  msg("Segments file=" + segmentsFileName + " numSegments="+ numSegments+ " version="+ sFormat);
  result.segmentsFileName=segmentsFileName;
  result.numSegments=numSegments;
  result.segmentFormat=sFormat;
  if (onlySegments != null) {
    result.partial=true;
    if (infoStream != null)     infoStream.print("\nChecking only these segments:");
    Iterator it=onlySegments.iterator();
    while (it.hasNext()) {
      if (infoStream != null)       infoStream.print(" " + it.next());
    }
    result.segmentsChecked.addAll(onlySegments);
    msg(":");
  }
  if (skip) {
    msg("\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting");
    result.toolOutOfDate=true;
    return result;
  }
  result.newSegments=(SegmentInfos)sis.clone();
  result.newSegments.clear();
  for (int i=0; i < numSegments; i++) {
    final SegmentInfo info=sis.info(i);
    if (onlySegments != null && !onlySegments.contains(info.name))     continue;
    Status.SegmentInfoStatus segInfoStat=new Status.SegmentInfoStatus();
    result.segmentInfos.add(segInfoStat);
    msg("  " + (1 + i) + " of "+ numSegments+ ": name="+ info.name+ " docCount="+ info.docCount);
    segInfoStat.name=info.name;
    segInfoStat.docCount=info.docCount;
    int toLoseDocCount=info.docCount;
    SegmentReader reader=null;
    try {
      msg("    compound=" + info.getUseCompoundFile());
      segInfoStat.compound=info.getUseCompoundFile();
      msg("    hasProx=" + info.getHasProx());
      segInfoStat.hasProx=info.getHasProx();
      msg("    numFiles=" + info.files().size());
      segInfoStat.numFiles=info.files().size();
      msg("    size (MB)=" + nf.format(info.sizeInBytes() / (1024. * 1024.)));
      segInfoStat.sizeMB=info.sizeInBytes() / (1024. * 1024.);
      final int docStoreOffset=info.getDocStoreOffset();
      if (docStoreOffset != -1) {
        msg("    docStoreOffset=" + docStoreOffset);
        segInfoStat.docStoreOffset=docStoreOffset;
        msg("    docStoreSegment=" + info.getDocStoreSegment());
        segInfoStat.docStoreSegment=info.getDocStoreSegment();
        msg("    docStoreIsCompoundFile=" + info.getDocStoreIsCompoundFile());
        segInfoStat.docStoreCompoundFile=info.getDocStoreIsCompoundFile();
      }
      final String delFileName=info.getDelFileName();
      if (delFileName == null) {
        msg("    no deletions");
        segInfoStat.hasDeletions=false;
      }
 else {
        msg("    has deletions [delFileName=" + delFileName + "]");
        segInfoStat.hasDeletions=true;
        segInfoStat.deletionsFileName=delFileName;
      }
      if (infoStream != null)       infoStream.print("    test: open reader.........");
      reader=SegmentReader.get(info);
      segInfoStat.openReaderPassed=true;
      final int numDocs=reader.numDocs();
      toLoseDocCount=numDocs;
      if (reader.hasDeletions()) {
        if (reader.deletedDocs.count() != info.getDelCount()) {
          throw new RuntimeException("delete count mismatch: info=" + info.getDelCount() + " vs deletedDocs.count()="+ reader.deletedDocs.count());
        }
        if (reader.deletedDocs.count() > reader.maxDoc()) {
          throw new RuntimeException("too many deleted docs: maxDoc()=" + reader.maxDoc() + " vs deletedDocs.count()="+ reader.deletedDocs.count());
        }
        if (info.docCount - numDocs != info.getDelCount()) {
          throw new RuntimeException("delete count mismatch: info=" + info.getDelCount() + " vs reader="+ (info.docCount - numDocs));
        }
        segInfoStat.numDeleted=info.docCount - numDocs;
        msg("OK [" + (segInfoStat.numDeleted) + " deleted docs]");
      }
 else {
        if (info.getDelCount() != 0) {
          throw new RuntimeException("delete count mismatch: info=" + info.getDelCount() + " vs reader="+ (info.docCount - numDocs));
        }
        msg("OK");
      }
      if (reader.maxDoc() != info.docCount)       throw new RuntimeException("SegmentReader.maxDoc() " + reader.maxDoc() + " != SegmentInfos.docCount "+ info.docCount);
      if (infoStream != null)       infoStream.print("    test: fields, norms.......");
      Collection fieldNames=reader.getFieldNames(IndexReader.FieldOption.ALL);
      Iterator it=fieldNames.iterator();
      final byte[] b=new byte[reader.maxDoc()];
      while (it.hasNext()) {
        final String fieldName=(String)it.next();
        reader.norms(fieldName,b,0);
      }
      msg("OK [" + fieldNames.size() + " fields]");
      segInfoStat.numFields=fieldNames.size();
      if (infoStream != null)       infoStream.print("    test: terms, freq, prox...");
      final TermEnum termEnum=reader.terms();
      final TermPositions termPositions=reader.termPositions();
      final MySegmentTermDocs myTermDocs=new MySegmentTermDocs(reader);
      long termCount=0;
      long totFreq=0;
      long totPos=0;
      final int maxDoc=reader.maxDoc();
      while (termEnum.next()) {
        termCount++;
        final Term term=termEnum.term();
        final int docFreq=termEnum.docFreq();
        termPositions.seek(term);
        int lastDoc=-1;
        int freq0=0;
        totFreq+=docFreq;
        while (termPositions.next()) {
          freq0++;
          final int doc=termPositions.doc();
          final int freq=termPositions.freq();
          if (doc <= lastDoc)           throw new RuntimeException("term " + term + ": doc "+ doc+ " <= lastDoc "+ lastDoc);
          if (doc >= maxDoc)           throw new RuntimeException("term " + term + ": doc "+ doc+ " >= maxDoc "+ maxDoc);
          lastDoc=doc;
          if (freq <= 0)           throw new RuntimeException("term " + term + ": doc "+ doc+ ": freq "+ freq+ " is out of bounds");
          int lastPos=-1;
          totPos+=freq;
          for (int j=0; j < freq; j++) {
            final int pos=termPositions.nextPosition();
            if (pos < -1)             throw new RuntimeException("term " + term + ": doc "+ doc+ ": pos "+ pos+ " is out of bounds");
            if (pos < lastPos)             throw new RuntimeException("term " + term + ": doc "+ doc+ ": pos "+ pos+ " < lastPos "+ lastPos);
          }
        }
        final int delCount;
        if (reader.hasDeletions()) {
          myTermDocs.seek(term);
          while (myTermDocs.next()) {
          }
          delCount=myTermDocs.delCount;
        }
 else         delCount=0;
        if (freq0 + delCount != docFreq)         throw new RuntimeException("term " + term + " docFreq="+ docFreq+ " != num docs seen "+ freq0+ " + num docs deleted "+ delCount);
      }
      msg("OK [" + termCount + " terms; "+ totFreq+ " terms/docs pairs; "+ totPos+ " tokens]");
      if (infoStream != null)       infoStream.print("    test: stored fields.......");
      int docCount=0;
      long totFields=0;
      for (int j=0; j < info.docCount; j++)       if (!reader.isDeleted(j)) {
        docCount++;
        Document doc=reader.document(j);
        totFields+=doc.getFields().size();
      }
      if (docCount != reader.numDocs())       throw new RuntimeException("docCount=" + docCount + " but saw "+ docCount+ " undeleted docs");
      msg("OK [" + totFields + " total field count; avg "+ nf.format((((float)totFields) / docCount))+ " fields per doc]");
      if (infoStream != null)       infoStream.print("    test: term vectors........");
      int totVectors=0;
      for (int j=0; j < info.docCount; j++)       if (!reader.isDeleted(j)) {
        TermFreqVector[] tfv=reader.getTermFreqVectors(j);
        if (tfv != null)         totVectors+=tfv.length;
      }
      msg("OK [" + totVectors + " total vector count; avg "+ nf.format((((float)totVectors) / docCount))+ " term/freq vector fields per doc]");
      msg("");
    }
 catch (    Throwable t) {
      msg("FAILED");
      String comment;
      comment="fixIndex() would remove reference to this segment";
      msg("    WARNING: " + comment + "; full exception:");
      if (infoStream != null)       t.printStackTrace(infoStream);
      msg("");
      result.totLoseDocCount+=toLoseDocCount;
      result.numBadSegments++;
      continue;
    }
 finally {
      if (reader != null)       reader.close();
    }
    result.newSegments.add(info.clone());
  }
  if (0 == result.numBadSegments) {
    result.clean=true;
    msg("No problems were detected with this index.\n");
  }
 else   msg("WARNING: " + result.numBadSegments + " broken segments (containing "+ result.totLoseDocCount+ " documents) detected");
  return result;
}
