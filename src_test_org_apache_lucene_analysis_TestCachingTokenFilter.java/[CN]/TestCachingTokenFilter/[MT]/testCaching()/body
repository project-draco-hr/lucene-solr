{
  Directory dir=new RAMDirectory();
  IndexWriter writer=new IndexWriter(dir,new SimpleAnalyzer(),IndexWriter.MaxFieldLength.LIMITED);
  Document doc=new Document();
  TokenStream stream=new TokenStream(){
    private int index=0;
    private TermAttribute termAtt=(TermAttribute)addAttribute(TermAttribute.class);
    private OffsetAttribute offsetAtt=(OffsetAttribute)addAttribute(OffsetAttribute.class);
    public boolean incrementToken() throws IOException {
      if (index == tokens.length) {
        return false;
      }
 else {
        termAtt.setTermBuffer(tokens[index++]);
        offsetAtt.setOffset(0,0);
        return true;
      }
    }
  }
;
  stream=new CachingTokenFilter(stream);
  doc.add(new Field("preanalyzed",stream,TermVector.NO));
  checkTokens(stream);
  stream.reset();
  checkTokens(stream);
  writer.addDocument(doc);
  writer.close();
  IndexReader reader=IndexReader.open(dir);
  TermPositions termPositions=reader.termPositions(new Term("preanalyzed","term1"));
  assertTrue(termPositions.next());
  assertEquals(1,termPositions.freq());
  assertEquals(0,termPositions.nextPosition());
  termPositions.seek(new Term("preanalyzed","term2"));
  assertTrue(termPositions.next());
  assertEquals(2,termPositions.freq());
  assertEquals(1,termPositions.nextPosition());
  assertEquals(3,termPositions.nextPosition());
  termPositions.seek(new Term("preanalyzed","term3"));
  assertTrue(termPositions.next());
  assertEquals(1,termPositions.freq());
  assertEquals(2,termPositions.nextPosition());
  reader.close();
  stream.reset();
  checkTokens(stream);
}
