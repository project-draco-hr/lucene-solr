{
  String analyzed=null;
  TokenStream stream=null;
  try {
    stream=getAnalyzer().tokenStream(field,chunk);
    stream.reset();
    CharTermAttribute termAtt=stream.getAttribute(CharTermAttribute.class);
    if (stream.incrementToken()) {
      analyzed=termAtt.toString();
      StringBuilder multipleOutputs=null;
      while (stream.incrementToken()) {
        if (null == multipleOutputs) {
          multipleOutputs=new StringBuilder();
          multipleOutputs.append('"');
          multipleOutputs.append(analyzed);
          multipleOutputs.append('"');
        }
        multipleOutputs.append(',');
        multipleOutputs.append('"');
        multipleOutputs.append(termAtt.toString());
        multipleOutputs.append('"');
      }
      stream.end();
      stream.close();
      if (null != multipleOutputs) {
        throw new ParseException(String.format(getLocale(),"Analyzer created multiple terms for \"%s\": %s",chunk,multipleOutputs.toString()));
      }
    }
 else {
      stream.end();
      stream.close();
      throw new ParseException(String.format(getLocale(),"Analyzer returned nothing for \"%s\"",chunk));
    }
  }
 catch (  IOException e) {
    throw new ParseException(String.format(getLocale(),"IO error while trying to analyze single term: \"%s\"",termStr));
  }
  return analyzed;
}
