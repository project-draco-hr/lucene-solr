{
  CollectionAdminRequest.createCollection("modelCollection","ml",2,1).process(cluster.getSolrClient());
  AbstractDistribZkTestBase.waitForRecoveriesToFinish("modelCollection",cluster.getSolrClient().getZkStateReader(),false,true,TIMEOUT);
  CollectionAdminRequest.createCollection("uknownCollection","ml",2,1).process(cluster.getSolrClient());
  AbstractDistribZkTestBase.waitForRecoveriesToFinish("uknownCollection",cluster.getSolrClient().getZkStateReader(),false,true,TIMEOUT);
  CollectionAdminRequest.createCollection("checkpointCollection","ml",2,1).process(cluster.getSolrClient());
  AbstractDistribZkTestBase.waitForRecoveriesToFinish("checkpointCollection",cluster.getSolrClient().getZkStateReader(),false,true,TIMEOUT);
  UpdateRequest updateRequest=new UpdateRequest();
  for (int i=0; i < 500; i+=2) {
    updateRequest.add(id,String.valueOf(i),"tv_text","a b c c d","out_i","1");
    updateRequest.add(id,String.valueOf(i + 1),"tv_text","a b e e f","out_i","0");
  }
  updateRequest.commit(cluster.getSolrClient(),COLLECTION);
  updateRequest=new UpdateRequest();
  updateRequest.add(id,String.valueOf(0),"text_s","a b c c d");
  updateRequest.add(id,String.valueOf(1),"text_s","a b e e f");
  updateRequest.commit(cluster.getSolrClient(),"uknownCollection");
  String url=cluster.getJettySolrRunners().get(0).getBaseUrl().toString() + "/" + COLLECTION;
  TupleStream updateTrainModelStream;
  ModifiableSolrParams paramsLoc;
  StreamFactory factory=new StreamFactory().withCollectionZkHost("collection1",cluster.getZkServer().getZkAddress()).withCollectionZkHost("modelCollection",cluster.getZkServer().getZkAddress()).withCollectionZkHost("uknownCollection",cluster.getZkServer().getZkAddress()).withFunctionName("features",FeaturesSelectionStream.class).withFunctionName("train",TextLogitStream.class).withFunctionName("search",CloudSolrStream.class).withFunctionName("update",UpdateStream.class);
  String textLogitExpression="train(" + "collection1, " + "features(collection1, q=\"*:*\", featureSet=\"first\", field=\"tv_text\", outcome=\"out_i\", numTerms=4),"+ "q=\"*:*\", "+ "name=\"model\", "+ "field=\"tv_text\", "+ "outcome=\"out_i\", "+ "maxIterations=100)";
  updateTrainModelStream=factory.constructStream("update(modelCollection, batchSize=5, " + textLogitExpression + ")");
  getTuples(updateTrainModelStream);
  cluster.getSolrClient().commit("modelCollection");
  String expr="classify(" + "model(modelCollection, id=\"model\", cacheMillis=5000)," + "topic(checkpointCollection, uknownCollection, q=\"*:*\", fl=\"text_s, id\", id=\"1000000\", initialCheckpoint=\"0\"),"+ "field=\"text_s\","+ "analyzerField=\"tv_text\")";
  paramsLoc=new ModifiableSolrParams();
  paramsLoc.set("expr",expr);
  paramsLoc.set("qt","/stream");
  SolrStream classifyStream=new SolrStream(url,paramsLoc);
  Map<String,Double> idToLabel=getIdToLabel(classifyStream,"probability_d");
  assertEquals(idToLabel.size(),2);
  assertEquals(1.0,idToLabel.get("0"),0.001);
  assertEquals(0,idToLabel.get("1"),0.001);
  updateRequest=new UpdateRequest();
  updateRequest.add(id,String.valueOf(2),"text_s","a b c c d");
  updateRequest.add(id,String.valueOf(3),"text_s","a b e e f");
  updateRequest.commit(cluster.getSolrClient(),"uknownCollection");
  classifyStream=new SolrStream(url,paramsLoc);
  idToLabel=getIdToLabel(classifyStream,"probability_d");
  assertEquals(idToLabel.size(),2);
  assertEquals(1.0,idToLabel.get("2"),0.001);
  assertEquals(0,idToLabel.get("3"),0.001);
  updateRequest=new UpdateRequest();
  updateRequest.deleteByQuery("*:*");
  updateRequest.commit(cluster.getSolrClient(),COLLECTION);
  updateRequest=new UpdateRequest();
  for (int i=0; i < 500; i+=2) {
    updateRequest.add(id,String.valueOf(i),"tv_text","a b c c d","out_i","0");
    updateRequest.add(id,String.valueOf(i + 1),"tv_text","a b e e f","out_i","1");
  }
  updateRequest.commit(cluster.getSolrClient(),COLLECTION);
  updateTrainModelStream=factory.constructStream("update(modelCollection, batchSize=5, " + textLogitExpression + ")");
  getTuples(updateTrainModelStream);
  cluster.getSolrClient().commit("modelCollection");
  updateRequest=new UpdateRequest();
  updateRequest.add(id,String.valueOf(4),"text_s","a b c c d");
  updateRequest.add(id,String.valueOf(5),"text_s","a b e e f");
  updateRequest.commit(cluster.getSolrClient(),"uknownCollection");
  Thread.sleep(5100);
  classifyStream=new SolrStream(url,paramsLoc);
  idToLabel=getIdToLabel(classifyStream,"probability_d");
  assertEquals(idToLabel.size(),2);
  assertEquals(0,idToLabel.get("4"),0.001);
  assertEquals(1.0,idToLabel.get("5"),0.001);
  expr="parallel(collection1, workers=2, sort=\"_version_ asc\", classify(" + "model(modelCollection, id=\"model\")," + "topic(checkpointCollection, uknownCollection, q=\"id:(4 5)\", fl=\"text_s, id, _version_\", id=\"2000000\", partitionKeys=\"id\", initialCheckpoint=\"0\"),"+ "field=\"text_s\","+ "analyzerField=\"tv_text\"))";
  paramsLoc.set("expr",expr);
  classifyStream=new SolrStream(url,paramsLoc);
  idToLabel=getIdToLabel(classifyStream,"probability_d");
  assertEquals(idToLabel.size(),2);
  assertEquals(0,idToLabel.get("4"),0.001);
  assertEquals(1.0,idToLabel.get("5"),0.001);
  CollectionAdminRequest.deleteCollection("modelCollection").process(cluster.getSolrClient());
  CollectionAdminRequest.deleteCollection("uknownCollection").process(cluster.getSolrClient());
  CollectionAdminRequest.deleteCollection("checkpointCollection").process(cluster.getSolrClient());
}
