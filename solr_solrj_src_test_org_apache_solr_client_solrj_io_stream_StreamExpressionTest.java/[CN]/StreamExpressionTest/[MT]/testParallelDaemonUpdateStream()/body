{
  CollectionAdminRequest.createCollection("parallelDestinationCollection1","conf",2,1).process(cluster.getSolrClient());
  AbstractDistribZkTestBase.waitForRecoveriesToFinish("parallelDestinationCollection1",cluster.getSolrClient().getZkStateReader(),false,true,TIMEOUT);
  new UpdateRequest().add(id,"0","a_s","hello0","a_i","0","a_f","0","s_multi","aaaa","s_multi","bbbb","i_multi","4","i_multi","7").add(id,"2","a_s","hello2","a_i","2","a_f","0","s_multi","aaaa1","s_multi","bbbb1","i_multi","44","i_multi","77").add(id,"3","a_s","hello3","a_i","3","a_f","3","s_multi","aaaa2","s_multi","bbbb2","i_multi","444","i_multi","777").add(id,"4","a_s","hello4","a_i","4","a_f","4","s_multi","aaaa3","s_multi","bbbb3","i_multi","4444","i_multi","7777").add(id,"1","a_s","hello1","a_i","1","a_f","1","s_multi","aaaa4","s_multi","bbbb4","i_multi","44444","i_multi","77777").commit(cluster.getSolrClient(),"collection1");
  StreamExpression expression;
  TupleStream stream;
  Tuple t;
  String zkHost=cluster.getZkServer().getZkAddress();
  StreamFactory factory=new StreamFactory().withCollectionZkHost("collection1",cluster.getZkServer().getZkAddress()).withCollectionZkHost("parallelDestinationCollection1",cluster.getZkServer().getZkAddress()).withFunctionName("search",CloudSolrStream.class).withFunctionName("update",UpdateStream.class).withFunctionName("parallel",ParallelStream.class).withFunctionName("daemon",DaemonStream.class);
  String updateExpression="daemon(update(parallelDestinationCollection1, batchSize=2, search(collection1, q=*:*, fl=\"id,a_s,a_i,a_f,s_multi,i_multi\", sort=\"a_f asc, a_i asc\", partitionKeys=\"a_f\")), runInterval=\"1000\", id=\"test\")";
  TupleStream parallelUpdateStream=factory.constructStream("parallel(collection1, " + updateExpression + ", workers=\"2\", zkHost=\""+ zkHost+ "\", sort=\"batchNumber asc\")");
  List<Tuple> tuples=getTuples(parallelUpdateStream);
  assert(tuples.size() == 2);
  Map params=new HashMap();
  params.put(CommonParams.QT,"/stream");
  params.put("action","list");
  int workersComplete=0;
  for (  JettySolrRunner jetty : cluster.getJettySolrRunners()) {
    int iterations=0;
    INNER:     while (iterations == 0) {
      SolrStream solrStream=new SolrStream(jetty.getBaseUrl().toString() + "/collection1",params);
      solrStream.open();
      Tuple tupleResponse=solrStream.read();
      if (tupleResponse.EOF) {
        solrStream.close();
        break INNER;
      }
 else {
        long l=tupleResponse.getLong("iterations");
        if (l > 0) {
          ++workersComplete;
        }
 else {
          try {
            Thread.sleep(1000);
          }
 catch (          Exception e) {
          }
        }
        iterations=(int)l;
        solrStream.close();
      }
    }
  }
  assertEquals(cluster.getJettySolrRunners().size(),workersComplete);
  cluster.getSolrClient().commit("parallelDestinationCollection1");
  params=new HashMap();
  params.put(CommonParams.QT,"/stream");
  params.put("action","stop");
  params.put("id","test");
  for (  JettySolrRunner jetty : cluster.getJettySolrRunners()) {
    SolrStream solrStream=new SolrStream(jetty.getBaseUrl() + "/collection1",params);
    solrStream.open();
    Tuple tupleResponse=solrStream.read();
    solrStream.close();
  }
  params=new HashMap();
  params.put(CommonParams.QT,"/stream");
  params.put("action","list");
  workersComplete=0;
  for (  JettySolrRunner jetty : cluster.getJettySolrRunners()) {
    long stopTime=0;
    INNER:     while (stopTime == 0) {
      SolrStream solrStream=new SolrStream(jetty.getBaseUrl() + "/collection1",params);
      solrStream.open();
      Tuple tupleResponse=solrStream.read();
      if (tupleResponse.EOF) {
        solrStream.close();
        break INNER;
      }
 else {
        stopTime=tupleResponse.getLong("stopTime");
        if (stopTime > 0) {
          ++workersComplete;
        }
 else {
          try {
            Thread.sleep(1000);
          }
 catch (          Exception e) {
          }
        }
        solrStream.close();
      }
    }
  }
  assertEquals(cluster.getJettySolrRunners().size(),workersComplete);
  expression=StreamExpressionParser.parse("search(parallelDestinationCollection1, q=*:*, fl=\"id,a_s,a_i,a_f,s_multi,i_multi\", sort=\"a_i asc\")");
  stream=new CloudSolrStream(expression,factory);
  tuples=getTuples(stream);
  assertEquals(5,tuples.size());
  Tuple tuple=tuples.get(0);
  assert(tuple.getLong("id") == 0);
  assert(tuple.get("a_s").equals("hello0"));
  assert(tuple.getLong("a_i") == 0);
  assert(tuple.getDouble("a_f") == 0.0);
  assertList(tuple.getStrings("s_multi"),"aaaa","bbbb");
  assertList(tuple.getLongs("i_multi"),Long.parseLong("4"),Long.parseLong("7"));
  tuple=tuples.get(1);
  assert(tuple.getLong("id") == 1);
  assert(tuple.get("a_s").equals("hello1"));
  assert(tuple.getLong("a_i") == 1);
  assert(tuple.getDouble("a_f") == 1.0);
  assertList(tuple.getStrings("s_multi"),"aaaa4","bbbb4");
  assertList(tuple.getLongs("i_multi"),Long.parseLong("44444"),Long.parseLong("77777"));
  tuple=tuples.get(2);
  assert(tuple.getLong("id") == 2);
  assert(tuple.get("a_s").equals("hello2"));
  assert(tuple.getLong("a_i") == 2);
  assert(tuple.getDouble("a_f") == 0.0);
  assertList(tuple.getStrings("s_multi"),"aaaa1","bbbb1");
  assertList(tuple.getLongs("i_multi"),Long.parseLong("44"),Long.parseLong("77"));
  tuple=tuples.get(3);
  assert(tuple.getLong("id") == 3);
  assert(tuple.get("a_s").equals("hello3"));
  assert(tuple.getLong("a_i") == 3);
  assert(tuple.getDouble("a_f") == 3.0);
  assertList(tuple.getStrings("s_multi"),"aaaa2","bbbb2");
  assertList(tuple.getLongs("i_multi"),Long.parseLong("444"),Long.parseLong("777"));
  tuple=tuples.get(4);
  assert(tuple.getLong("id") == 4);
  assert(tuple.get("a_s").equals("hello4"));
  assert(tuple.getLong("a_i") == 4);
  assert(tuple.getDouble("a_f") == 4.0);
  assertList(tuple.getStrings("s_multi"),"aaaa3","bbbb3");
  assertList(tuple.getLongs("i_multi"),Long.parseLong("4444"),Long.parseLong("7777"));
}
