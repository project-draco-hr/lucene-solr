{
  new UpdateRequest().add(id,"0","a_s","hello0","a_i","0","a_f","0").add(id,"2","a_s","hello2","a_i","2","a_f","0").add(id,"3","a_s","hello3","a_i","3","a_f","3").add(id,"4","a_s","hello4","a_i","4","a_f","4").add(id,"1","a_s","hello1","a_i","1","a_f","1").add(id,"5","a_s","hello1","a_i","10","a_f","1").add(id,"6","a_s","hello1","a_i","11","a_f","5").add(id,"7","a_s","hello1","a_i","12","a_f","5").add(id,"8","a_s","hello1","a_i","13","a_f","4").commit(cluster.getSolrClient(),COLLECTION);
  String zkHost=cluster.getZkServer().getZkAddress();
  StreamFactory streamFactory=new StreamFactory().withCollectionZkHost(COLLECTION,zkHost).withFunctionName("search",CloudSolrStream.class).withFunctionName("unique",UniqueStream.class).withFunctionName("top",RankStream.class).withFunctionName("group",ReducerStream.class).withFunctionName("parallel",ParallelStream.class);
  ParallelStream pstream=(ParallelStream)streamFactory.constructStream("parallel(" + COLLECTION + ", unique(search(collection1, q=*:*, fl=\"id,a_s,a_i,a_f\", sort=\"a_f asc, a_i asc\", partitionKeys=\"a_f\"), over=\"a_f\"), workers=\"2\", zkHost=\""+ zkHost+ "\", sort=\"a_f asc\")");
  List<Tuple> tuples=getTuples(pstream);
  assert(tuples.size() == 5);
  assertOrder(tuples,0,1,3,4,6);
  Map<String,Tuple> eofTuples=pstream.getEofTuples();
  assert(eofTuples.size() == 2);
}
