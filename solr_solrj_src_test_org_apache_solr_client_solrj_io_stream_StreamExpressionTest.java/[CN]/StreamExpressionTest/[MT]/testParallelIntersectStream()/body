{
  new UpdateRequest().add(id,"0","a_s","setA","a_i","0").add(id,"2","a_s","setA","a_i","1").add(id,"3","a_s","setA","a_i","2").add(id,"4","a_s","setA","a_i","3").add(id,"5","a_s","setB","a_i","2").add(id,"6","a_s","setB","a_i","3").add(id,"7","a_s","setAB","a_i","0").add(id,"8","a_s","setAB","a_i","6").commit(cluster.getSolrClient(),COLLECTION);
  StreamFactory streamFactory=new StreamFactory().withCollectionZkHost("collection1",cluster.getZkServer().getZkAddress()).withFunctionName("search",CloudSolrStream.class).withFunctionName("intersect",IntersectStream.class).withFunctionName("parallel",ParallelStream.class);
  String zkHost=cluster.getZkServer().getZkAddress();
  final TupleStream stream=streamFactory.constructStream("parallel(" + "collection1, " + "intersect("+ "search(collection1, q=a_s:(setA || setAB), fl=\"id,a_s,a_i\", sort=\"a_i asc, a_s asc\", partitionKeys=\"a_i\"),"+ "search(collection1, q=a_s:(setB || setAB), fl=\"id,a_s,a_i\", sort=\"a_i asc\", partitionKeys=\"a_i\"),"+ "on=\"a_i\"),"+ "workers=\"2\", zkHost=\"" + zkHost + "\", sort=\"a_i asc\")");
  final List<Tuple> tuples=getTuples(stream);
  assert(tuples.size() == 5);
  assertOrder(tuples,0,7,3,4,8);
}
