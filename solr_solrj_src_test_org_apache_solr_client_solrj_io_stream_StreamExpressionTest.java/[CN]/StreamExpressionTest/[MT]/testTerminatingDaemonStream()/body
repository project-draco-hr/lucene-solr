{
  new UpdateRequest().add(id,"0","a_s","hello","a_i","0","a_f","1").add(id,"2","a_s","hello","a_i","2","a_f","2").add(id,"3","a_s","hello","a_i","3","a_f","3").add(id,"4","a_s","hello","a_i","4","a_f","4").add(id,"1","a_s","hello","a_i","1","a_f","5").add(id,"5","a_s","hello","a_i","10","a_f","6").add(id,"6","a_s","hello","a_i","11","a_f","7").add(id,"7","a_s","hello","a_i","12","a_f","8").add(id,"8","a_s","hello","a_i","13","a_f","9").add(id,"9","a_s","hello","a_i","14","a_f","10").commit(cluster.getSolrClient(),COLLECTION);
  StreamFactory factory=new StreamFactory().withCollectionZkHost(COLLECTION,cluster.getZkServer().getZkAddress()).withFunctionName("topic",TopicStream.class).withFunctionName("daemon",DaemonStream.class);
  StreamExpression expression;
  DaemonStream daemonStream;
  SolrClientCache cache=new SolrClientCache();
  StreamContext context=new StreamContext();
  context.setSolrClientCache(cache);
  expression=StreamExpressionParser.parse("daemon(topic(" + COLLECTION + ","+ COLLECTION+ ", q=\"a_s:hello\", initialCheckpoint=0, id=\"topic1\", rows=2, fl=\"id\""+ "), id=test, runInterval=1000, terminate=true, queueSize=50)");
  daemonStream=(DaemonStream)factory.constructStream(expression);
  daemonStream.setStreamContext(context);
  List<Tuple> tuples=getTuples(daemonStream);
  assertTrue(tuples.size() == 10);
  cache.close();
}
