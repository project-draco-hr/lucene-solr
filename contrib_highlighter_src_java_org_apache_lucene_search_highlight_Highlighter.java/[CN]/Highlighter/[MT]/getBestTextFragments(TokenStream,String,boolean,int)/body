{
  ArrayList docFrags=new ArrayList();
  StringBuffer newText=new StringBuffer();
  TermAttribute termAtt=tokenStream.addAttribute(TermAttribute.class);
  OffsetAttribute offsetAtt=tokenStream.addAttribute(OffsetAttribute.class);
  tokenStream.addAttribute(PositionIncrementAttribute.class);
  tokenStream.reset();
  TextFragment currentFrag=new TextFragment(newText,newText.length(),docFrags.size());
  TokenStream newStream=fragmentScorer.init(tokenStream);
  if (newStream != null) {
    tokenStream=newStream;
  }
  fragmentScorer.startFragment(currentFrag);
  docFrags.add(currentFrag);
  FragmentQueue fragQueue=new FragmentQueue(maxNumFragments);
  try {
    String tokenText;
    int startOffset;
    int endOffset;
    int lastEndOffset=0;
    textFragmenter.start(text,tokenStream);
    TokenGroup tokenGroup=new TokenGroup(tokenStream);
    for (boolean next=tokenStream.incrementToken(); next && (offsetAtt.startOffset() < maxDocCharsToAnalyze); next=tokenStream.incrementToken()) {
      if ((offsetAtt.endOffset() > text.length()) || (offsetAtt.startOffset() > text.length())) {
        throw new InvalidTokenOffsetsException("Token " + termAtt.term() + " exceeds length of provided text sized "+ text.length());
      }
      if ((tokenGroup.numTokens > 0) && (tokenGroup.isDistinct())) {
        startOffset=tokenGroup.matchStartOffset;
        endOffset=tokenGroup.matchEndOffset;
        tokenText=text.substring(startOffset,endOffset);
        String markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText),tokenGroup);
        if (startOffset > lastEndOffset)         newText.append(encoder.encodeText(text.substring(lastEndOffset,startOffset)));
        newText.append(markedUpText);
        lastEndOffset=Math.max(endOffset,lastEndOffset);
        tokenGroup.clear();
        if (textFragmenter.isNewFragment()) {
          currentFrag.setScore(fragmentScorer.getFragmentScore());
          currentFrag.textEndPos=newText.length();
          currentFrag=new TextFragment(newText,newText.length(),docFrags.size());
          fragmentScorer.startFragment(currentFrag);
          docFrags.add(currentFrag);
        }
      }
      tokenGroup.addToken(fragmentScorer.getTokenScore());
    }
    currentFrag.setScore(fragmentScorer.getFragmentScore());
    if (tokenGroup.numTokens > 0) {
      startOffset=tokenGroup.matchStartOffset;
      endOffset=tokenGroup.matchEndOffset;
      tokenText=text.substring(startOffset,endOffset);
      String markedUpText=formatter.highlightTerm(encoder.encodeText(tokenText),tokenGroup);
      if (startOffset > lastEndOffset)       newText.append(encoder.encodeText(text.substring(lastEndOffset,startOffset)));
      newText.append(markedUpText);
      lastEndOffset=Math.max(lastEndOffset,endOffset);
    }
    if ((lastEndOffset < text.length()) && (text.length() <= maxDocCharsToAnalyze)) {
      newText.append(encoder.encodeText(text.substring(lastEndOffset)));
    }
    currentFrag.textEndPos=newText.length();
    for (Iterator i=docFrags.iterator(); i.hasNext(); ) {
      currentFrag=(TextFragment)i.next();
      fragQueue.insertWithOverflow(currentFrag);
    }
    TextFragment frag[]=new TextFragment[fragQueue.size()];
    for (int i=frag.length - 1; i >= 0; i--) {
      frag[i]=(TextFragment)fragQueue.pop();
    }
    if (mergeContiguousFragments) {
      mergeContiguousFragments(frag);
      ArrayList fragTexts=new ArrayList();
      for (int i=0; i < frag.length; i++) {
        if ((frag[i] != null) && (frag[i].getScore() > 0)) {
          fragTexts.add(frag[i]);
        }
      }
      frag=(TextFragment[])fragTexts.toArray(new TextFragment[0]);
    }
    return frag;
  }
  finally {
    if (tokenStream != null) {
      try {
        tokenStream.close();
      }
 catch (      Exception e) {
      }
    }
  }
}
