{
  TokenStream ts=analyzer.tokenStream(fieldName,r);
  org.apache.lucene.analysis.Token token;
  int tokenCount=0;
  while ((token=ts.next()) != null) {
    String word=token.termText();
    tokenCount++;
    if (tokenCount > maxNumTokensParsed) {
      break;
    }
    if (isNoiseWord(word)) {
      continue;
    }
    Int cnt=(Int)termFreqMap.get(word);
    if (cnt == null) {
      termFreqMap.put(word,new Int());
    }
 else {
      cnt.x++;
    }
  }
}
