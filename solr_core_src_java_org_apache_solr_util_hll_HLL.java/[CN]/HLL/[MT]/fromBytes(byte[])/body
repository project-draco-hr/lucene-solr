{
  final ISchemaVersion schemaVersion=SerializationUtil.getSchemaVersion(bytes);
  final IHLLMetadata metadata=schemaVersion.readMetadata(bytes);
  final HLLType type=metadata.HLLType();
  final int regwidth=metadata.registerWidth();
  final int log2m=metadata.registerCountLog2();
  final boolean sparseon=metadata.sparseEnabled();
  final int expthresh;
  if (metadata.explicitAuto()) {
    expthresh=-1;
  }
 else   if (metadata.explicitOff()) {
    expthresh=0;
  }
 else {
    expthresh=metadata.log2ExplicitCutoff() + 1;
  }
  final HLL hll=new HLL(log2m,regwidth,expthresh,sparseon,type);
  if (HLLType.EMPTY.equals(type)) {
    return hll;
  }
  final int wordLength;
switch (type) {
case EXPLICIT:
    wordLength=Long.SIZE;
  break;
case SPARSE:
wordLength=hll.shortWordLength;
break;
case FULL:
wordLength=hll.regwidth;
break;
default :
throw new RuntimeException("Unsupported HLL type " + type);
}
final IWordDeserializer deserializer=schemaVersion.getDeserializer(type,wordLength,bytes);
switch (type) {
case EXPLICIT:
for (int i=0; i < deserializer.totalWordCount(); i++) {
hll.explicitStorage.add(deserializer.readWord());
}
break;
case SPARSE:
for (int i=0; i < deserializer.totalWordCount(); i++) {
final long shortWord=deserializer.readWord();
final byte registerValue=(byte)(shortWord & hll.valueMask);
if (registerValue != 0) {
hll.sparseProbabilisticStorage.put((int)(shortWord >>> hll.regwidth),registerValue);
}
}
break;
case FULL:
for (long i=0; i < hll.m; i++) {
hll.probabilisticStorage.setRegister(i,deserializer.readWord());
}
break;
default :
throw new RuntimeException("Unsupported HLL type " + type);
}
return hll;
}
