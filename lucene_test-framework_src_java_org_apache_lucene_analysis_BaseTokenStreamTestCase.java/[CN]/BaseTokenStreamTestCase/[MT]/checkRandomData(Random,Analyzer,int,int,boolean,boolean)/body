{
  for (int i=0; i < iterations; i++) {
    String text;
    if (simple) {
      text=random.nextBoolean() ? _TestUtil.randomSimpleString(random) : _TestUtil.randomHtmlishString(random,maxWordLength);
    }
 else {
switch (_TestUtil.nextInt(random,0,4)) {
case 0:
        text=_TestUtil.randomSimpleString(random);
      break;
case 1:
    text=_TestUtil.randomRealisticUnicodeString(random,maxWordLength);
  break;
case 2:
text=_TestUtil.randomHtmlishString(random,maxWordLength);
break;
default :
text=_TestUtil.randomUnicodeString(random,maxWordLength);
}
}
if (VERBOSE) {
System.out.println(Thread.currentThread().getName() + ": NOTE: BaseTokenStreamTestCase: get first token stream now text=" + text);
}
int remainder=random.nextInt(10);
Reader reader=new StringReader(text);
TokenStream ts=a.tokenStream("dummy",useCharFilter ? new MockCharFilter(reader,remainder) : reader);
assertTrue("has no CharTermAttribute",ts.hasAttribute(CharTermAttribute.class));
CharTermAttribute termAtt=ts.getAttribute(CharTermAttribute.class);
OffsetAttribute offsetAtt=ts.hasAttribute(OffsetAttribute.class) ? ts.getAttribute(OffsetAttribute.class) : null;
PositionIncrementAttribute posIncAtt=ts.hasAttribute(PositionIncrementAttribute.class) ? ts.getAttribute(PositionIncrementAttribute.class) : null;
PositionLengthAttribute posLengthAtt=ts.hasAttribute(PositionLengthAttribute.class) ? ts.getAttribute(PositionLengthAttribute.class) : null;
TypeAttribute typeAtt=ts.hasAttribute(TypeAttribute.class) ? ts.getAttribute(TypeAttribute.class) : null;
List<String> tokens=new ArrayList<String>();
List<String> types=new ArrayList<String>();
List<Integer> positions=new ArrayList<Integer>();
List<Integer> positionLengths=new ArrayList<Integer>();
List<Integer> startOffsets=new ArrayList<Integer>();
List<Integer> endOffsets=new ArrayList<Integer>();
ts.reset();
while (ts.incrementToken()) {
tokens.add(termAtt.toString());
if (typeAtt != null) types.add(typeAtt.type());
if (posIncAtt != null) positions.add(posIncAtt.getPositionIncrement());
if (posLengthAtt != null) positionLengths.add(posLengthAtt.getPositionLength());
if (offsetAtt != null) {
startOffsets.add(offsetAtt.startOffset());
endOffsets.add(offsetAtt.endOffset());
}
}
ts.end();
ts.close();
if (!tokens.isEmpty()) {
if (VERBOSE) {
System.out.println(Thread.currentThread().getName() + ": NOTE: BaseTokenStreamTestCase: re-run analysis; " + tokens.size()+ " tokens");
}
reader=new StringReader(text);
ts=a.tokenStream("dummy",useCharFilter ? new MockCharFilter(reader,remainder) : reader);
if (typeAtt != null && posIncAtt != null && posLengthAtt != null && offsetAtt != null) {
assertTokenStreamContents(ts,tokens.toArray(new String[tokens.size()]),toIntArray(startOffsets),toIntArray(endOffsets),types.toArray(new String[types.size()]),toIntArray(positions),toIntArray(positionLengths),text.length());
}
 else if (typeAtt != null && posIncAtt != null && offsetAtt != null) {
assertTokenStreamContents(ts,tokens.toArray(new String[tokens.size()]),toIntArray(startOffsets),toIntArray(endOffsets),types.toArray(new String[types.size()]),toIntArray(positions),null,text.length());
}
 else if (posIncAtt != null && posLengthAtt != null && offsetAtt != null) {
assertTokenStreamContents(ts,tokens.toArray(new String[tokens.size()]),toIntArray(startOffsets),toIntArray(endOffsets),null,toIntArray(positions),toIntArray(positionLengths),text.length());
}
 else if (posIncAtt != null && offsetAtt != null) {
assertTokenStreamContents(ts,tokens.toArray(new String[tokens.size()]),toIntArray(startOffsets),toIntArray(endOffsets),null,toIntArray(positions),null,text.length());
}
 else if (offsetAtt != null) {
assertTokenStreamContents(ts,tokens.toArray(new String[tokens.size()]),toIntArray(startOffsets),toIntArray(endOffsets),null,null,null,text.length());
}
 else {
assertTokenStreamContents(ts,tokens.toArray(new String[tokens.size()]));
}
}
}
}
