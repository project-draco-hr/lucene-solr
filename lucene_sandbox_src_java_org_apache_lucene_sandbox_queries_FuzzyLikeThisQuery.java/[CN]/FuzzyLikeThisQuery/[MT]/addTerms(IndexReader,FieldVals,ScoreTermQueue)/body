{
  if (f.queryString == null)   return;
  final Terms terms=MultiFields.getTerms(reader,f.fieldName);
  if (terms == null) {
    return;
  }
  try (TokenStream ts=analyzer.tokenStream(f.fieldName,f.queryString)){
    CharTermAttribute termAtt=ts.addAttribute(CharTermAttribute.class);
    int corpusNumDocs=reader.numDocs();
    HashSet<String> processedTerms=new HashSet<>();
    ts.reset();
    while (ts.incrementToken()) {
      String term=termAtt.toString();
      if (!processedTerms.contains(term)) {
        processedTerms.add(term);
        ScoreTermQueue variantsQ=new ScoreTermQueue(MAX_VARIANTS_PER_TERM);
        float minScore=0;
        Term startTerm=new Term(f.fieldName,term);
        AttributeSource atts=new AttributeSource();
        MaxNonCompetitiveBoostAttribute maxBoostAtt=atts.addAttribute(MaxNonCompetitiveBoostAttribute.class);
        SlowFuzzyTermsEnum fe=new SlowFuzzyTermsEnum(terms,atts,startTerm,f.minSimilarity,f.prefixLength);
        int df=reader.docFreq(startTerm);
        int numVariants=0;
        int totalVariantDocFreqs=0;
        BytesRef possibleMatch;
        BoostAttribute boostAtt=fe.attributes().addAttribute(BoostAttribute.class);
        while ((possibleMatch=fe.next()) != null) {
          numVariants++;
          totalVariantDocFreqs+=fe.docFreq();
          float score=boostAtt.getBoost();
          if (variantsQ.size() < MAX_VARIANTS_PER_TERM || score > minScore) {
            ScoreTerm st=new ScoreTerm(new Term(startTerm.field(),BytesRef.deepCopyOf(possibleMatch)),score,startTerm);
            variantsQ.insertWithOverflow(st);
            minScore=variantsQ.top().score;
          }
          maxBoostAtt.setMaxNonCompetitiveBoost(variantsQ.size() >= MAX_VARIANTS_PER_TERM ? minScore : Float.NEGATIVE_INFINITY);
        }
        if (numVariants > 0) {
          int avgDf=totalVariantDocFreqs / numVariants;
          if (df == 0) {
            df=avgDf;
          }
          int size=variantsQ.size();
          for (int i=0; i < size; i++) {
            ScoreTerm st=variantsQ.pop();
            st.score=(st.score * st.score) * sim.idf(df,corpusNumDocs);
            q.insertWithOverflow(st);
          }
        }
      }
    }
    ts.end();
  }
 }
