{
  String testText="I borrowed $5,400.00 at 25% interest-rate";
  ResourceLoader loader=new SolrResourceLoader("solr/collection1");
  Map<String,String> args=new HashMap<>();
  args.put("luceneMatchVersion",Version.LATEST.toString());
  args.put("generateWordParts","1");
  args.put("generateNumberParts","1");
  args.put("catenateWords","1");
  args.put("catenateNumbers","1");
  args.put("catenateAll","0");
  args.put("splitOnCaseChange","1");
  WordDelimiterFilterFactory factoryDefault=new WordDelimiterFilterFactory(args);
  factoryDefault.inform(loader);
  TokenStream ts=factoryDefault.create(whitespaceMockTokenizer(testText));
  BaseTokenStreamTestCase.assertTokenStreamContents(ts,new String[]{"I","borrowed","5","540000","400","00","at","25","interest","interestrate","rate"});
  ts=factoryDefault.create(whitespaceMockTokenizer("foo\u200Dbar"));
  BaseTokenStreamTestCase.assertTokenStreamContents(ts,new String[]{"foo","foobar","bar"});
  args=new HashMap<>();
  args.put("luceneMatchVersion",Version.LATEST.toString());
  args.put("generateWordParts","1");
  args.put("generateNumberParts","1");
  args.put("catenateWords","1");
  args.put("catenateNumbers","1");
  args.put("catenateAll","0");
  args.put("splitOnCaseChange","1");
  args.put("types","wdftypes.txt");
  WordDelimiterFilterFactory factoryCustom=new WordDelimiterFilterFactory(args);
  factoryCustom.inform(loader);
  ts=factoryCustom.create(whitespaceMockTokenizer(testText));
  BaseTokenStreamTestCase.assertTokenStreamContents(ts,new String[]{"I","borrowed","$5,400.00","at","25%","interest","interestrate","rate"});
  ts=factoryCustom.create(whitespaceMockTokenizer("foo\u200Dbar"));
  BaseTokenStreamTestCase.assertTokenStreamContents(ts,new String[]{"foo\u200Dbar"});
}
