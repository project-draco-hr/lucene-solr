{
  final Tokenizer source=new StandardTokenizer(matchVersion);
  TokenStream result=new LowerCaseFilter(matchVersion,source);
  result=new StopFilter(matchVersion,result,stopwords);
  result=new ArabicNormalizationFilter(result);
  if (!stemExclusionSet.isEmpty()) {
    result=new SetKeywordMarkerFilter(result,stemExclusionSet);
  }
  return new TokenStreamComponents(source,new ArabicStemFilter(result));
}
