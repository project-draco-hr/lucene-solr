{
  final Tokenizer source=new StandardTokenizer();
  TokenStream result=new LowerCaseFilter(source);
  result=new StopFilter(result,stopwords);
  result=new ArabicNormalizationFilter(result);
  if (!stemExclusionSet.isEmpty()) {
    result=new SetKeywordMarkerFilter(result,stemExclusionSet);
  }
  return new TokenStreamComponents(source,new ArabicStemFilter(result));
}
