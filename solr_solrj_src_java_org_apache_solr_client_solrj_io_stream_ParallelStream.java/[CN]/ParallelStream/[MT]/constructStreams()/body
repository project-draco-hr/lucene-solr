{
  try {
    Object pushStream=((Expressible)tupleStream).toExpression(streamFactory);
    ZkStateReader zkStateReader=cloudSolrClient.getZkStateReader();
    ClusterState clusterState=zkStateReader.getClusterState();
    Collection<Slice> slices=clusterState.getActiveSlices(this.collection);
    List<Replica> shuffler=new ArrayList();
    for (    Slice slice : slices) {
      Collection<Replica> replicas=slice.getReplicas();
      for (      Replica replica : replicas) {
        shuffler.add(replica);
      }
    }
    if (workers > shuffler.size()) {
      throw new IOException("Number of workers exceeds nodes in the worker collection");
    }
    Collections.shuffle(shuffler,new Random());
    for (int w=0; w < workers; w++) {
      HashMap params=new HashMap();
      params.put("distrib","false");
      params.put("numWorkers",workers);
      params.put("workerID",w);
      params.put("stream",pushStream);
      params.put("qt","/stream");
      Replica rep=shuffler.get(w);
      ZkCoreNodeProps zkProps=new ZkCoreNodeProps(rep);
      String url=zkProps.getCoreUrl();
      SolrStream solrStream=new SolrStream(url,params);
      solrStreams.add(solrStream);
    }
    assert(solrStreams.size() == workers);
  }
 catch (  Exception e) {
    throw new IOException(e);
  }
}
