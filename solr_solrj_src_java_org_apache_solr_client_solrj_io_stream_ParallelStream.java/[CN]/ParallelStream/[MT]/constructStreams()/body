{
  try {
    Object pushStream=((Expressible)tupleStream).toExpression(streamFactory);
    ZkStateReader zkStateReader=cloudSolrClient.getZkStateReader();
    ClusterState clusterState=zkStateReader.getClusterState();
    Set<String> liveNodes=clusterState.getLiveNodes();
    Collection<Slice> slices=clusterState.getActiveSlices(this.collection);
    List<Replica> shuffler=new ArrayList();
    for (    Slice slice : slices) {
      Collection<Replica> replicas=slice.getReplicas();
      for (      Replica replica : replicas) {
        if (replica.getState() == Replica.State.ACTIVE && liveNodes.contains(replica.getNodeName()))         shuffler.add(replica);
      }
    }
    if (workers > shuffler.size()) {
      throw new IOException("Number of workers exceeds nodes in the worker collection");
    }
    Collections.shuffle(shuffler,new Random());
    for (int w=0; w < workers; w++) {
      ModifiableSolrParams paramsLoc=new ModifiableSolrParams();
      paramsLoc.set("distrib","false");
      paramsLoc.set("numWorkers",workers);
      paramsLoc.set("workerID",w);
      paramsLoc.set("expr",pushStream.toString());
      paramsLoc.set("qt","/stream");
      Replica rep=shuffler.get(w);
      ZkCoreNodeProps zkProps=new ZkCoreNodeProps(rep);
      String url=zkProps.getCoreUrl();
      SolrStream solrStream=new SolrStream(url,paramsLoc);
      solrStreams.add(solrStream);
    }
    assert(solrStreams.size() == workers);
  }
 catch (  Exception e) {
    throw new IOException(e);
  }
}
