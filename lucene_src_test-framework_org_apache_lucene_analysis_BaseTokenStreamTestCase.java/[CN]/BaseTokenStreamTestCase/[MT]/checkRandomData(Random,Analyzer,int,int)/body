{
  for (int i=0; i < iterations; i++) {
    String text;
switch (_TestUtil.nextInt(random,0,3)) {
case 0:
      text=_TestUtil.randomSimpleString(random);
    break;
case 1:
  text=_TestUtil.randomRealisticUnicodeString(random,maxWordLength);
break;
default :
text=_TestUtil.randomUnicodeString(random,maxWordLength);
}
if (VERBOSE) {
System.out.println("NOTE: BaseTokenStreamTestCase: get first token stream now text=" + text);
}
TokenStream ts=a.tokenStream("dummy",new StringReader(text));
assertTrue("has no CharTermAttribute",ts.hasAttribute(CharTermAttribute.class));
CharTermAttribute termAtt=ts.getAttribute(CharTermAttribute.class);
OffsetAttribute offsetAtt=ts.hasAttribute(OffsetAttribute.class) ? ts.getAttribute(OffsetAttribute.class) : null;
PositionIncrementAttribute posIncAtt=ts.hasAttribute(PositionIncrementAttribute.class) ? ts.getAttribute(PositionIncrementAttribute.class) : null;
TypeAttribute typeAtt=ts.hasAttribute(TypeAttribute.class) ? ts.getAttribute(TypeAttribute.class) : null;
List<String> tokens=new ArrayList<String>();
List<String> types=new ArrayList<String>();
List<Integer> positions=new ArrayList<Integer>();
List<Integer> startOffsets=new ArrayList<Integer>();
List<Integer> endOffsets=new ArrayList<Integer>();
ts.reset();
while (ts.incrementToken()) {
tokens.add(termAtt.toString());
if (typeAtt != null) types.add(typeAtt.type());
if (posIncAtt != null) positions.add(posIncAtt.getPositionIncrement());
if (offsetAtt != null) {
startOffsets.add(offsetAtt.startOffset());
endOffsets.add(offsetAtt.endOffset());
}
}
ts.end();
ts.close();
if (!tokens.isEmpty()) {
if (VERBOSE) {
System.out.println("NOTE: BaseTokenStreamTestCase: re-run analysis");
}
if (typeAtt != null && posIncAtt != null && offsetAtt != null) {
assertAnalyzesToReuse(a,text,tokens.toArray(new String[tokens.size()]),toIntArray(startOffsets),toIntArray(endOffsets),types.toArray(new String[types.size()]),toIntArray(positions));
}
 else if (posIncAtt != null && offsetAtt != null) {
assertAnalyzesToReuse(a,text,tokens.toArray(new String[tokens.size()]),toIntArray(startOffsets),toIntArray(endOffsets),toIntArray(positions));
}
 else if (offsetAtt != null) {
assertAnalyzesToReuse(a,text,tokens.toArray(new String[tokens.size()]),toIntArray(startOffsets),toIntArray(endOffsets));
}
 else {
assertAnalyzesToReuse(a,text,tokens.toArray(new String[tokens.size()]));
}
}
}
}
