{
  final RepeatingTokenStream ts=new RepeatingTokenStream(val);
  Analyzer analyzer=new Analyzer(){
    @Override public TokenStream tokenStream(    String fieldName,    Reader reader){
      if (random.nextFloat() < percentDocs)       ts.num=random.nextInt(maxTF) + 1;
 else       ts.num=0;
      return ts;
    }
  }
;
  Document doc=new Document();
  doc.add(newField(field,val,Field.Store.NO,Field.Index.NOT_ANALYZED_NO_NORMS));
  IndexWriter writer=new IndexWriter(dir,newIndexWriterConfig(TEST_VERSION_CURRENT,analyzer).setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(100));
  ((LogMergePolicy)writer.getConfig().getMergePolicy()).setMergeFactor(100);
  for (int i=0; i < ndocs; i++) {
    writer.addDocument(doc);
  }
  writer.optimize();
  writer.close();
}
