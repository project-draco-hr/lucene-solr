{
  Directory dir=newDirectory();
  IndexWriterConfig conf=newIndexWriterConfig(TEST_VERSION_CURRENT,new Analyzer(){
    @Override public TokenStream tokenStream(    String fieldName,    Reader reader){
      MockTokenizer tokenizer=new MockTokenizer(reader,MockTokenizer.SIMPLE,true);
      tokenizer.setEnableChecks(false);
      return new TokenFilter(tokenizer){
        private int count=0;
        @Override public boolean incrementToken() throws IOException {
          if (count++ == 5) {
            throw new IOException();
          }
          return input.incrementToken();
        }
      }
;
    }
  }
);
  conf.setMaxBufferedDocs(Math.max(3,conf.getMaxBufferedDocs()));
  IndexWriter writer=new IndexWriter(dir,conf);
  Document doc=new Document();
  String contents="aa bb cc dd ee ff gg hh ii jj kk";
  doc.add(newField("content",contents,Field.Store.NO,Field.Index.ANALYZED));
  try {
    writer.addDocument(doc);
    fail("did not hit expected exception");
  }
 catch (  Exception e) {
  }
  doc=new Document();
  doc.add(newField("content","aa bb cc dd",Field.Store.NO,Field.Index.ANALYZED));
  writer.addDocument(doc);
  doc=new Document();
  doc.add(newField("content","aa bb cc dd",Field.Store.NO,Field.Index.ANALYZED));
  writer.addDocument(doc);
  writer.close();
  IndexReader reader=IndexReader.open(dir,true);
  final Term t=new Term("content","aa");
  assertEquals(3,reader.docFreq(t));
  DocsEnum tdocs=MultiFields.getTermDocsEnum(reader,MultiFields.getDeletedDocs(reader),t.field(),new BytesRef(t.text()));
  int count=0;
  while (tdocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
    count++;
  }
  assertEquals(2,count);
  assertEquals(reader.docFreq(new Term("content","gg")),0);
  reader.close();
  dir.close();
}
