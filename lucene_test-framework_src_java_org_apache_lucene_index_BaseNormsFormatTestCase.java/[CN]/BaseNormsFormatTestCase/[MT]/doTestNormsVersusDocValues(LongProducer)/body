{
  int numDocs=atLeast(500);
  long norms[]=new long[numDocs];
  for (int i=0; i < numDocs; i++) {
    norms[i]=longs.next();
  }
  Directory dir=newDirectory();
  Analyzer analyzer=new MockAnalyzer(random(),MockTokenizer.KEYWORD,false);
  IndexWriterConfig conf=newIndexWriterConfig(analyzer);
  conf.setSimilarity(new CannedNormSimilarity(norms));
  RandomIndexWriter writer=new RandomIndexWriter(random(),dir,conf);
  Document doc=new Document();
  Field idField=new StringField("id","",Field.Store.NO);
  Field indexedField=new TextField("indexed","",Field.Store.NO);
  Field dvField=new NumericDocValuesField("dv",0);
  doc.add(idField);
  doc.add(indexedField);
  doc.add(dvField);
  for (int i=0; i < numDocs; i++) {
    idField.setStringValue(Integer.toString(i));
    long value=norms[i];
    dvField.setLongValue(value);
    indexedField.setStringValue(Long.toString(value));
    writer.addDocument(doc);
    if (random().nextInt(31) == 0) {
      writer.commit();
    }
  }
  int numDeletions=random().nextInt(numDocs / 20);
  for (int i=0; i < numDeletions; i++) {
    int id=random().nextInt(numDocs);
    writer.deleteDocuments(new Term("id",Integer.toString(id)));
  }
  writer.commit();
  DirectoryReader ir=DirectoryReader.open(dir);
  for (  LeafReaderContext context : ir.leaves()) {
    LeafReader r=context.reader();
    NumericDocValues expected=r.getNumericDocValues("dv");
    NumericDocValues actual=r.getNormValues("indexed");
    for (int i=0; i < r.maxDoc(); i++) {
      assertEquals("doc " + i,expected.get(i),actual.get(i));
    }
  }
  ir.close();
  writer.forceMerge(1);
  ir=DirectoryReader.open(dir);
  for (  LeafReaderContext context : ir.leaves()) {
    LeafReader r=context.reader();
    NumericDocValues expected=r.getNumericDocValues("dv");
    NumericDocValues actual=r.getNormValues("indexed");
    for (int i=0; i < r.maxDoc(); i++) {
      assertEquals("doc " + i,expected.get(i),actual.get(i));
    }
  }
  writer.close();
  ir.close();
  dir.close();
}
