{
  if (f.queryString == null)   return;
  TokenStream ts=analyzer.tokenStream(f.fieldName,new StringReader(f.queryString));
  Token token=ts.next();
  int corpusNumDocs=reader.numDocs();
  Term internSavingTemplateTerm=new Term(f.fieldName,"");
  HashSet processedTerms=new HashSet();
  while (token != null) {
    if (!processedTerms.contains(token.termText())) {
      processedTerms.add(token.termText());
      ScoreTermQueue variantsQ=new ScoreTermQueue(MAX_VARIANTS_PER_TERM);
      float minScore=0;
      Term startTerm=internSavingTemplateTerm.createTerm(token.termText());
      FuzzyTermEnum fe=new FuzzyTermEnum(reader,startTerm,f.minSimilarity,f.prefixLength);
      TermEnum origEnum=reader.terms(startTerm);
      int df=0;
      if (startTerm.equals(origEnum.term())) {
        df=origEnum.docFreq();
      }
      int numVariants=0;
      int totalVariantDocFreqs=0;
      do {
        Term possibleMatch=fe.term();
        if (possibleMatch != null) {
          numVariants++;
          totalVariantDocFreqs+=fe.docFreq();
          float score=fe.difference();
          if (variantsQ.size() < MAX_VARIANTS_PER_TERM || score > minScore) {
            ScoreTerm st=new ScoreTerm(possibleMatch,score,startTerm);
            variantsQ.insert(st);
            minScore=((ScoreTerm)variantsQ.top()).score;
          }
        }
      }
 while (fe.next());
      if (numVariants == 0) {
        break;
      }
      int avgDf=totalVariantDocFreqs / numVariants;
      if (df == 0) {
        df=avgDf;
      }
      int size=variantsQ.size();
      for (int i=0; i < size; i++) {
        ScoreTerm st=(ScoreTerm)variantsQ.pop();
        st.score=(st.score * st.score) * sim.idf(df,corpusNumDocs);
        q.insert(st);
      }
    }
    token=ts.next();
  }
}
