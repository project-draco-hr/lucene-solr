{
  Directory dir=new MockRAMDirectory();
  for (int iter=0; iter < 4; iter++) {
    final boolean autoCommit=1 == iter / 2;
    IndexWriter writer=new IndexWriter(dir,autoCommit,new StandardAnalyzer());
    writer.setMaxBufferedDocs(2);
    writer.setRAMBufferSizeMB(IndexWriter.DISABLE_AUTO_FLUSH);
    writer.setMergeScheduler(new SerialMergeScheduler());
    writer.setMergePolicy(new LogDocMergePolicy(writer));
    Document document=new Document();
    Field storedField=new Field("stored","stored",Field.Store.YES,Field.Index.NO);
    document.add(storedField);
    writer.addDocument(document);
    writer.addDocument(document);
    document=new Document();
    document.add(storedField);
    Field termVectorField=new Field("termVector","termVector",Field.Store.NO,Field.Index.NOT_ANALYZED,Field.TermVector.WITH_POSITIONS_OFFSETS);
    document.add(termVectorField);
    writer.addDocument(document);
    writer.optimize();
    writer.close();
    IndexReader reader=IndexReader.open(dir);
    for (int i=0; i < reader.numDocs(); i++) {
      reader.document(i);
      reader.getTermFreqVectors(i);
    }
    reader.close();
    writer=new IndexWriter(dir,autoCommit,new StandardAnalyzer());
    writer.setMaxBufferedDocs(2);
    writer.setRAMBufferSizeMB(IndexWriter.DISABLE_AUTO_FLUSH);
    writer.setMergeScheduler(new SerialMergeScheduler());
    writer.setMergePolicy(new LogDocMergePolicy(writer));
    Directory[] indexDirs={new MockRAMDirectory(dir)};
    writer.addIndexes(indexDirs);
    writer.close();
  }
  dir.close();
}
