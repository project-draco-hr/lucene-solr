{
  if (f.queryString == null)   return;
  TokenStream ts=analyzer.tokenStream(f.fieldName,new StringReader(f.queryString));
  CharTermAttribute termAtt=ts.addAttribute(CharTermAttribute.class);
  int corpusNumDocs=reader.numDocs();
  Term internSavingTemplateTerm=new Term(f.fieldName);
  HashSet<String> processedTerms=new HashSet<String>();
  while (ts.incrementToken()) {
    String term=termAtt.toString();
    if (!processedTerms.contains(term)) {
      processedTerms.add(term);
      ScoreTermQueue variantsQ=new ScoreTermQueue(MAX_VARIANTS_PER_TERM);
      float minScore=0;
      Term startTerm=internSavingTemplateTerm.createTerm(term);
      FuzzyTermsEnum fe=new FuzzyTermsEnum(reader,startTerm,f.minSimilarity,f.prefixLength);
      int df=reader.docFreq(startTerm);
      int numVariants=0;
      int totalVariantDocFreqs=0;
      BytesRef possibleMatch;
      MultiTermQuery.BoostAttribute boostAtt=fe.attributes().addAttribute(MultiTermQuery.BoostAttribute.class);
      while ((possibleMatch=fe.next()) != null) {
        if (possibleMatch != null) {
          numVariants++;
          totalVariantDocFreqs+=fe.docFreq();
          float score=boostAtt.getBoost();
          if (variantsQ.size() < MAX_VARIANTS_PER_TERM || score > minScore) {
            ScoreTerm st=new ScoreTerm(new Term(startTerm.field(),new BytesRef(possibleMatch)),score,startTerm);
            variantsQ.insertWithOverflow(st);
            minScore=variantsQ.top().score;
          }
          boostAtt.setMaxNonCompetitiveBoost(variantsQ.size() >= MAX_VARIANTS_PER_TERM ? minScore : Float.NEGATIVE_INFINITY);
        }
      }
      if (numVariants > 0) {
        int avgDf=totalVariantDocFreqs / numVariants;
        if (df == 0) {
          df=avgDf;
        }
        int size=variantsQ.size();
        for (int i=0; i < size; i++) {
          ScoreTerm st=variantsQ.pop();
          st.score=(st.score * st.score) * sim.idf(df,corpusNumDocs);
          q.insertWithOverflow(st);
        }
      }
    }
  }
}
