{
  RussianAnalyzer ra=new RussianAnalyzer(RussianCharsets.UnicodeRussian);
  inWords=new InputStreamReader(new FileInputStream(new File(dataDir,"/org/apache/lucene/analysis/ru/testUnicode.txt")),"Unicode");
  sampleUnicode=new InputStreamReader(new FileInputStream(new File(dataDir,"/org/apache/lucene/analysis/ru/resUnicode.htm")),"Unicode");
  TokenStream in=ra.tokenStream("all",inWords);
  RussianLetterTokenizer sample=new RussianLetterTokenizer(sampleUnicode,RussianCharsets.UnicodeRussian);
  final Token reusableToken=new Token();
  final Token reusableSampleToken=new Token();
  Token nextToken;
  Token nextSampleToken;
  for (; ; ) {
    nextToken=in.next(reusableToken);
    if (nextToken == null) {
      break;
    }
    nextSampleToken=sample.next(reusableSampleToken);
    assertEquals("Unicode",nextToken.term(),nextSampleToken == null ? null : nextSampleToken.term());
  }
  inWords.close();
  sampleUnicode.close();
}
