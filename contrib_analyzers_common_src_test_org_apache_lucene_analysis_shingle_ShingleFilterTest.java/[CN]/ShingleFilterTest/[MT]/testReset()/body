{
  Tokenizer wsTokenizer=new WhitespaceTokenizer(TEST_VERSION_CURRENT,new StringReader("please divide this sentence"));
  TokenStream filter=new ShingleFilter(wsTokenizer,2);
  assertTokenStreamContents(filter,new String[]{"please","please divide","divide","divide this","this","this sentence","sentence"},new int[]{0,0,7,7,14,14,19},new int[]{6,13,13,18,18,27,27},new String[]{TypeAttributeImpl.DEFAULT_TYPE,"shingle",TypeAttributeImpl.DEFAULT_TYPE,"shingle",TypeAttributeImpl.DEFAULT_TYPE,"shingle",TypeAttributeImpl.DEFAULT_TYPE},new int[]{1,0,1,0,1,0,1});
  wsTokenizer.reset(new StringReader("please divide this sentence"));
  assertTokenStreamContents(filter,new String[]{"please","please divide","divide","divide this","this","this sentence","sentence"},new int[]{0,0,7,7,14,14,19},new int[]{6,13,13,18,18,27,27},new String[]{TypeAttributeImpl.DEFAULT_TYPE,"shingle",TypeAttributeImpl.DEFAULT_TYPE,"shingle",TypeAttributeImpl.DEFAULT_TYPE,"shingle",TypeAttributeImpl.DEFAULT_TYPE},new int[]{1,0,1,0,1,0,1});
}
